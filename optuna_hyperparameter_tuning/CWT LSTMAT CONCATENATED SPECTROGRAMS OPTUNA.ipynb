{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "626d84bd",
   "metadata": {
    "id": "626d84bd"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ad51f8",
   "metadata": {
    "id": "29ad51f8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define the folder path\n",
    "folder_path = r\"D:\\PYTHONIG\\newwindow\\NOTEBOOKS_2025\\aprilmay2025\\data\\numpy\\optunadata\\cwt\"\n",
    "\n",
    "# Load the numpy files into the respective arrays with the correct capitalized naming\n",
    "eeg_fold_1 = np.load(os.path.join(folder_path, 'CWT_DATA_FOLD_fold_1.npy'))\n",
    "labels_fold_1 = np.load(os.path.join(folder_path, 'CWT_LABELS_FOLD_fold_1.npy'))\n",
    "patients_fold_1 = np.load(os.path.join(folder_path, 'CWT_PATIENTS_FOLD_fold_1.npy'))\n",
    "\n",
    "eeg_fold_2 = np.load(os.path.join(folder_path, 'CWT_DATA_FOLD_fold_2.npy'))\n",
    "labels_fold_2 = np.load(os.path.join(folder_path, 'CWT_LABELS_FOLD_fold_2.npy'))\n",
    "patients_fold_2 = np.load(os.path.join(folder_path, 'CWT_PATIENTS_FOLD_fold_2.npy'))\n",
    "\n",
    "eeg_fold_3 = np.load(os.path.join(folder_path, 'CWT_DATA_FOLD_fold_3.npy'))\n",
    "labels_fold_3 = np.load(os.path.join(folder_path, 'CWT_LABELS_FOLD_fold_3.npy'))\n",
    "patients_fold_3 = np.load(os.path.join(folder_path, 'CWT_PATIENTS_FOLD_fold_3.npy'))\n",
    "\n",
    "eeg_fold_4 = np.load(os.path.join(folder_path, 'CWT_DATA_FOLD_fold_4.npy'))\n",
    "labels_fold_4 = np.load(os.path.join(folder_path, 'CWT_LABELS_FOLD_fold_4.npy'))\n",
    "patients_fold_4 = np.load(os.path.join(folder_path, 'CWT_PATIENTS_FOLD_fold_4.npy'))\n",
    "\n",
    "eeg_fold_5 = np.load(os.path.join(folder_path, 'CWT_DATA_FOLD_fold_5.npy'))\n",
    "labels_fold_5 = np.load(os.path.join(folder_path, 'CWT_LABELS_FOLD_fold_5.npy'))\n",
    "patients_fold_5 = np.load(os.path.join(folder_path, 'CWT_PATIENTS_FOLD_fold_5.npy'))\n",
    "\n",
    "eeg_folds = [eeg_fold_1, eeg_fold_2, eeg_fold_3, eeg_fold_4, eeg_fold_5]\n",
    "labels_folds = [labels_fold_1, labels_fold_2, labels_fold_3, labels_fold_4, labels_fold_5]\n",
    "patients_folds = [patients_fold_1, patients_fold_2, patients_fold_3, patients_fold_4, patients_fold_5]\n",
    "\n",
    "for i in range(len(eeg_folds)):\n",
    "    eeg_folds[i] = eeg_folds[i].astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9831e02",
   "metadata": {
    "id": "f9831e02"
   },
   "outputs": [],
   "source": [
    "def data_balancer(data, labels, factor):\n",
    "    # Count the number of samples in each class\n",
    "    num_class_0 = np.sum(labels == 0)\n",
    "    num_class_1 = np.sum(labels == 1)\n",
    "    num_class_2 = np.sum(labels == 2)\n",
    "\n",
    "    # Find the minimum number of samples across all classes\n",
    "    min_samples = min(num_class_0, num_class_1, num_class_2)\n",
    "\n",
    "    # Calculate the number of samples to take from each class\n",
    "    samples_per_class = min_samples // factor\n",
    "\n",
    "    # Randomly sample 'samples_per_class' from each class\n",
    "    class_0_indices = np.random.choice(np.where(labels == 0)[0], samples_per_class, replace=False)\n",
    "    class_1_indices = np.random.choice(np.where(labels == 1)[0], samples_per_class, replace=False)\n",
    "    class_2_indices = np.random.choice(np.where(labels == 2)[0], samples_per_class, replace=False)\n",
    "\n",
    "    # Combine balanced indices\n",
    "    balanced_indices = np.concatenate((class_0_indices, class_1_indices, class_2_indices))\n",
    "\n",
    "    # Shuffle the balanced indices\n",
    "    np.random.shuffle(balanced_indices)\n",
    "\n",
    "    # Create balanced training data and labels\n",
    "    balanced_data = data[balanced_indices]\n",
    "    balanced_labels = labels[balanced_indices]\n",
    "\n",
    "    return balanced_data, balanced_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0497bd4e",
   "metadata": {
    "id": "0497bd4e"
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5):\n",
    "        \"\"\"\n",
    "        Initializes the early stopping mechanism based on divergence detection.\n",
    "\n",
    "        Args:\n",
    "            patience (int): Number of consecutive epochs with increasing validation loss\n",
    "                            before stopping.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "        self.best_model_state = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        \"\"\"\n",
    "        Checks if the validation loss is diverging and updates the state accordingly.\n",
    "\n",
    "        Args:\n",
    "            val_loss (float): Current epoch's validation loss.\n",
    "            model (torch.nn.Module): The model being trained.\n",
    "        \"\"\"\n",
    "        if self.best_loss is None or val_loss < self.best_loss:\n",
    "            # Improvement detected\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model_state = model.state_dict()\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            # Validation loss increased\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                print(f\"Divergence detected. Stopping training after {self.counter} epochs.\")\n",
    "                self.early_stop = True\n",
    "\n",
    "    def load_best_model(self, model):\n",
    "        \"\"\"\n",
    "        Restores the model to the state with the lowest validation loss.\n",
    "\n",
    "        Args:\n",
    "            model (torch.nn.Module): The model to restore.\n",
    "        \"\"\"\n",
    "        model.load_state_dict(self.best_model_state)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04c9bba8",
   "metadata": {
    "id": "04c9bba8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "debug_mode_flag = False\n",
    "# Set the device to GPU if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "debug_mode_flag = False\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LstmAttention(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout=0.3):\n",
    "        super(LstmAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=hidden_size * 2, num_heads=2, batch_first=True)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "        self.act = nn.Sigmoid() if num_classes == 1 else nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, input_size)\n",
    "        lstm_out, _ = self.lstm(x)  # (batch, seq, hidden*2)\n",
    "\n",
    "        # Apply attention: Q=K=V=lstm_out\n",
    "        attn_out, _ = self.attention(lstm_out, lstm_out, lstm_out)  # (batch, seq, hidden*2)\n",
    "\n",
    "        # Aggregate via mean pooling or use only last time step\n",
    "        pooled = attn_out.mean(dim=1)  # (batch, hidden*2)\n",
    "\n",
    "        out = self.dropout(pooled)\n",
    "        out = self.fc(out)\n",
    "        return self.act(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb53c211",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 118,
     "status": "ok",
     "timestamp": 1747776598293,
     "user": {
      "displayName": "Ryan Gabriel",
      "userId": "15533354653069607353"
     },
     "user_tz": -330
    },
    "id": "eb53c211",
    "outputId": "ba1ef9f9-c6c9-48e4-d709-e615639718b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([8, 224, 672])\n",
      "Output shape: torch.Size([8, 3])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# For spectrogram shape (224, 224, 3) reshaped to (224, 672)\n",
    "# 224 time steps, 672 features per time step\n",
    "input_size = 224 * 3  # 672\n",
    "hidden_size = 128\n",
    "num_layers = 1\n",
    "num_classes = 3\n",
    "\n",
    "model = LstmAttention(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, num_classes=num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# Test with correct input dimensions: (batch_size, seq_len, input_size)\n",
    "# We need to reshape our data from (batch, 224, 224, 3) to (batch, 224, 672)\n",
    "x = torch.randn(8, 224, 672).to(device)  # batch_size=8, seq_len=224, features=672\n",
    "output = model(x)\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")  # Expect: (8, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "psh7bqJLmK1u",
   "metadata": {
    "id": "psh7bqJLmK1u"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# pca = sklearn.decomposition.PCA(3)\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "fold_indices = np.arange(5)\n",
    "fold_indices = np.random.permutation(fold_indices)\n",
    "val_fold_indices = np.roll(fold_indices, 1)\n",
    "\n",
    "input_shape = 224*3\n",
    "num_classes = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f665b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a5f665b8",
    "outputId": "72b7174f-1d92-4492-8392-ccccf613c130"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\cudaenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-05-29 05:39:58,934] A new study created in memory with name: no-name-a5c537fa-bc33-486f-bdc9-de829981980d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:1 hidden_size: 128, num_layers: 2, learning_rate: 3.472801856224001e-08, optimizer_name: Adam, weight_decay: 1.5584727796911125e-05, batch_size: 10, label_smoothing: 0.3, factor: 1trial:0 hidden_size: 1024, num_layers: 2, learning_rate: 0.0003738617129305991, optimizer_name: Adam, weight_decay: 6.587898380225081e-05, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "\n",
      "trial:2 hidden_size: 1024, num_layers: 4, learning_rate: 3.285761397503112e-07, optimizer_name: Adam, weight_decay: 0.00024987752105093197, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 05:45:19,019] Trial 2 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 3.285761397503112e-07, 'weight_decay': 0.00024987752105093197, 'batch_size': 32}. Best is trial 2 with value: 0.3333333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2: Test Accuracy = 0.3333\n",
      "trial:3 hidden_size: 1024, num_layers: 4, learning_rate: 1.9579226781863263e-08, optimizer_name: Adam, weight_decay: 3.416336600347603e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 05:50:04,686] Trial 0 finished with value: 0.40927964287898244 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.1, 'learning_rate': 0.0003738617129305991, 'weight_decay': 6.587898380225081e-05, 'batch_size': 10}. Best is trial 0 with value: 0.40927964287898244.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0: Test Accuracy = 0.4093\n",
      "trial:4 hidden_size: 64, num_layers: 2, learning_rate: 3.8175483234693166e-07, optimizer_name: Adam, weight_decay: 1.0887022156972955e-05, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Trial 1: Test Accuracy = 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 05:51:48,878] Trial 1 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.1, 'learning_rate': 3.472801856224001e-08, 'weight_decay': 1.5584727796911125e-05, 'batch_size': 10}. Best is trial 0 with value: 0.40927964287898244.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:5 hidden_size: 1024, num_layers: 2, learning_rate: 4.207221417695367e-08, optimizer_name: Adam, weight_decay: 0.0004216474328457339, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 12\n",
      "Trial 4: Test Accuracy = 0.4037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 05:55:57,235] Trial 4 finished with value: 0.40372714486638533 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 3.8175483234693166e-07, 'weight_decay': 1.0887022156972955e-05, 'batch_size': 10}. Best is trial 0 with value: 0.40927964287898244.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:6 hidden_size: 32, num_layers: 1, learning_rate: 0.00085265032152192, optimizer_name: Adam, weight_decay: 6.167566210766849e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 05:58:17,623] Trial 3 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 1.9579226781863263e-08, 'weight_decay': 3.416336600347603e-05, 'batch_size': 32}. Best is trial 0 with value: 0.40927964287898244.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3: Test Accuracy = 0.3333\n",
      "trial:7 hidden_size: 1024, num_layers: 2, learning_rate: 1.2394785284254662e-07, optimizer_name: Adam, weight_decay: 0.00024741748397945, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 22\n",
      "Trial 6: Test Accuracy = 0.4809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 06:03:51,582] Trial 6 finished with value: 0.4809301045679692 and parameters: {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.30000000000000004, 'learning_rate': 0.00085265032152192, 'weight_decay': 6.167566210766849e-06, 'batch_size': 16}. Best is trial 6 with value: 0.4809301045679692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:8 hidden_size: 1024, num_layers: 4, learning_rate: 6.986029542221468e-08, optimizer_name: Adam, weight_decay: 4.997006921139995e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n",
      "Trial 7: Test Accuracy = 0.3990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 06:13:37,145] Trial 7 finished with value: 0.3990215862532869 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.2, 'learning_rate': 1.2394785284254662e-07, 'weight_decay': 0.00024741748397945, 'batch_size': 10}. Best is trial 6 with value: 0.4809301045679692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:9 hidden_size: 64, num_layers: 1, learning_rate: 1.009926237731831e-06, optimizer_name: Adam, weight_decay: 7.799733738474434e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 06:20:39,360] Trial 5 finished with value: 0.4007307527670763 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.30000000000000004, 'learning_rate': 4.207221417695367e-08, 'weight_decay': 0.0004216474328457339, 'batch_size': 16}. Best is trial 6 with value: 0.4809301045679692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5: Test Accuracy = 0.4007\n",
      "trial:10 hidden_size: 1024, num_layers: 4, learning_rate: 1.4583663501469593e-07, optimizer_name: Adam, weight_decay: 0.0001426362323333932, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n",
      "Trial 8: Test Accuracy = 0.3278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 06:41:47,704] Trial 8 finished with value: 0.3278022381214456 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 6.986029542221468e-08, 'weight_decay': 4.997006921139995e-06, 'batch_size': 32}. Best is trial 6 with value: 0.4809301045679692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:11 hidden_size: 512, num_layers: 4, learning_rate: 0.004462307209495599, optimizer_name: Adam, weight_decay: 0.0007062301839314429, batch_size: 10, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 06:46:35,029] Trial 9 finished with value: 0.32362869198312233 and parameters: {'hidden_size': 64, 'num_layers': 1, 'dropout': 0.30000000000000004, 'learning_rate': 1.009926237731831e-06, 'weight_decay': 7.799733738474434e-06, 'batch_size': 32}. Best is trial 6 with value: 0.4809301045679692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9: Test Accuracy = 0.3236\n",
      "trial:12 hidden_size: 32, num_layers: 1, learning_rate: 0.003873984476974209, optimizer_name: Adam, weight_decay: 2.3302183831098483e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Trial 10: Test Accuracy = 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 06:50:41,223] Trial 10 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 1.4583663501469593e-07, 'weight_decay': 0.0001426362323333932, 'batch_size': 32}. Best is trial 6 with value: 0.4809301045679692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:13 hidden_size: 32, num_layers: 1, learning_rate: 0.0012970065877308161, optimizer_name: Adam, weight_decay: 2.019490523150996e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 06:50:55,747] Trial 11 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 512, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.004462307209495599, 'weight_decay': 0.0007062301839314429, 'batch_size': 10}. Best is trial 6 with value: 0.4809301045679692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11: Test Accuracy = 0.3333\n",
      "trial:14 hidden_size: 32, num_layers: 1, learning_rate: 0.0004699529731287266, optimizer_name: Adam, weight_decay: 1.3819577562172514e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 06:51:41,441] Trial 12 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.2, 'learning_rate': 0.003873984476974209, 'weight_decay': 2.3302183831098483e-06, 'batch_size': 16}. Best is trial 6 with value: 0.4809301045679692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12: Test Accuracy = 0.3333\n",
      "trial:15 hidden_size: 256, num_layers: 3, learning_rate: 0.00026634064137773846, optimizer_name: Adam, weight_decay: 5.516964468309498e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 06:52:09,324] Trial 13 finished with value: 0.4217299578059072 and parameters: {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.1, 'learning_rate': 0.0012970065877308161, 'weight_decay': 2.019490523150996e-06, 'batch_size': 16}. Best is trial 6 with value: 0.4809301045679692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 13: Test Accuracy = 0.4217\n",
      "trial:16 hidden_size: 32, num_layers: 3, learning_rate: 8.020085156839327e-05, optimizer_name: Adam, weight_decay: 1.3650806588450602e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 06:52:21,226] Trial 14 finished with value: 0.46744022503516175 and parameters: {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.1, 'learning_rate': 0.0004699529731287266, 'weight_decay': 1.3819577562172514e-06, 'batch_size': 16}. Best is trial 6 with value: 0.4809301045679692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14: Test Accuracy = 0.4674\n",
      "trial:17 hidden_size: 32, num_layers: 3, learning_rate: 0.00010916687552800061, optimizer_name: Adam, weight_decay: 1.0248062793558766e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 06:54:01,960] Trial 16 finished with value: 0.4757903748547667 and parameters: {'hidden_size': 32, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 8.020085156839327e-05, 'weight_decay': 1.3650806588450602e-06, 'batch_size': 16}. Best is trial 6 with value: 0.4809301045679692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 24\n",
      "Trial 16: Test Accuracy = 0.4758\n",
      "trial:18 hidden_size: 256, num_layers: 3, learning_rate: 3.607095794083012e-05, optimizer_name: Adam, weight_decay: 4.124751422782404e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 06:54:03,819] Trial 15 finished with value: 0.48454412034489086 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.1, 'learning_rate': 0.00026634064137773846, 'weight_decay': 5.516964468309498e-05, 'batch_size': 16}. Best is trial 15 with value: 0.48454412034489086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15: Test Accuracy = 0.4845\n",
      "trial:19 hidden_size: 256, num_layers: 3, learning_rate: 1.568336709765902e-05, optimizer_name: Adam, weight_decay: 3.7395417390441576e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 06:54:16,608] Trial 17 finished with value: 0.5378584969118816 and parameters: {'hidden_size': 32, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 0.00010916687552800061, 'weight_decay': 1.0248062793558766e-06, 'batch_size': 16}. Best is trial 17 with value: 0.5378584969118816.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 17: Test Accuracy = 0.5379\n",
      "trial:20 hidden_size: 256, num_layers: 3, learning_rate: 1.7883876454599914e-05, optimizer_name: Adam, weight_decay: 6.357900037814713e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 06:56:34,728] Trial 19 finished with value: 0.45010701400354675 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.2, 'learning_rate': 1.568336709765902e-05, 'weight_decay': 3.7395417390441576e-05, 'batch_size': 16}. Best is trial 17 with value: 0.5378584969118816.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 19: Test Accuracy = 0.4501\n",
      "trial:21 hidden_size: 256, num_layers: 3, learning_rate: 5.302242844399862e-05, optimizer_name: Adam, weight_decay: 5.615544698455969e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 06:57:17,073] Trial 20 finished with value: 0.4541827187671987 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 1.7883876454599914e-05, 'weight_decay': 6.357900037814713e-05, 'batch_size': 16}. Best is trial 17 with value: 0.5378584969118816.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20: Test Accuracy = 0.4542\n",
      "trial:22 hidden_size: 256, num_layers: 3, learning_rate: 7.681230754408694e-05, optimizer_name: Adam, weight_decay: 1.8938328712945048e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 06:57:45,877] Trial 18 finished with value: 0.4811166146884364 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 3.607095794083012e-05, 'weight_decay': 4.124751422782404e-06, 'batch_size': 16}. Best is trial 17 with value: 0.5378584969118816.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 18: Test Accuracy = 0.4811\n",
      "trial:23 hidden_size: 256, num_layers: 3, learning_rate: 6.227130451805968e-05, optimizer_name: Adam, weight_decay: 2.7093785717647777e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 06:58:57,790] Trial 21 finished with value: 0.3942579343239772 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 5.302242844399862e-05, 'weight_decay': 5.615544698455969e-05, 'batch_size': 16}. Best is trial 17 with value: 0.5378584969118816.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 21: Test Accuracy = 0.3943\n",
      "trial:24 hidden_size: 256, num_layers: 3, learning_rate: 5.054745218630672e-06, optimizer_name: Adam, weight_decay: 3.3286303513712925e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:01:09,019] Trial 22 finished with value: 0.4265364153366355 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 7.681230754408694e-05, 'weight_decay': 1.8938328712945048e-05, 'batch_size': 16}. Best is trial 17 with value: 0.5378584969118816.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 22: Test Accuracy = 0.4265\n",
      "trial:25 hidden_size: 256, num_layers: 3, learning_rate: 3.3798466545052847e-06, optimizer_name: Adam, weight_decay: 3.787485446057986e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:01:35,672] Trial 23 finished with value: 0.5458906622638048 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 6.227130451805968e-05, 'weight_decay': 2.7093785717647777e-06, 'batch_size': 16}. Best is trial 23 with value: 0.5458906622638048.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 23: Test Accuracy = 0.5459\n",
      "trial:26 hidden_size: 512, num_layers: 3, learning_rate: 4.185647417757516e-06, optimizer_name: Adam, weight_decay: 3.3128117312032423e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:03:36,691] Trial 24 finished with value: 0.5072280315538433 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 5.054745218630672e-06, 'weight_decay': 3.3286303513712925e-06, 'batch_size': 16}. Best is trial 23 with value: 0.5458906622638048.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 24: Test Accuracy = 0.5072\n",
      "trial:27 hidden_size: 128, num_layers: 3, learning_rate: 5.921935935343441e-06, optimizer_name: Adam, weight_decay: 2.551157950085634e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:05:44,617] Trial 25 finished with value: 0.47578425976884975 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 3.3798466545052847e-06, 'weight_decay': 3.787485446057986e-06, 'batch_size': 16}. Best is trial 23 with value: 0.5458906622638048.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25: Test Accuracy = 0.4758\n",
      "trial:28 hidden_size: 512, num_layers: 3, learning_rate: 3.985552049816404e-06, optimizer_name: Adam, weight_decay: 2.6367437697989786e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:05:55,253] Trial 26 finished with value: 0.452721213233046 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 4.185647417757516e-06, 'weight_decay': 3.3128117312032423e-06, 'batch_size': 16}. Best is trial 23 with value: 0.5458906622638048.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26: Test Accuracy = 0.4527\n",
      "trial:29 hidden_size: 128, num_layers: 3, learning_rate: 6.686180467866274e-06, optimizer_name: Adam, weight_decay: 1.0940671884989653e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:07:14,502] Trial 27 finished with value: 0.46653213477649363 and parameters: {'hidden_size': 128, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 5.921935935343441e-06, 'weight_decay': 2.551157950085634e-06, 'batch_size': 16}. Best is trial 23 with value: 0.5458906622638048.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 27: Test Accuracy = 0.4665\n",
      "trial:30 hidden_size: 256, num_layers: 3, learning_rate: 0.00017081266483256867, optimizer_name: Adam, weight_decay: 1.0692160496137655e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:08:23,458] Trial 29 finished with value: 0.4431144132575063 and parameters: {'hidden_size': 128, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 6.686180467866274e-06, 'weight_decay': 1.0940671884989653e-06, 'batch_size': 16}. Best is trial 23 with value: 0.5458906622638048.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 29: Test Accuracy = 0.4431\n",
      "trial:31 hidden_size: 256, num_layers: 3, learning_rate: 0.00020183804726011523, optimizer_name: Adam, weight_decay: 1.0307741391643246e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:09:08,139] Trial 28 finished with value: 0.4504402861860209 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 3.985552049816404e-06, 'weight_decay': 2.6367437697989786e-06, 'batch_size': 16}. Best is trial 23 with value: 0.5458906622638048.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 28: Test Accuracy = 0.4504\n",
      "trial:32 hidden_size: 256, num_layers: 3, learning_rate: 0.00017984205285183027, optimizer_name: Adam, weight_decay: 8.19016586071977e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:09:41,044] Trial 30 finished with value: 0.4869718094539229 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 0.00017081266483256867, 'weight_decay': 1.0692160496137655e-06, 'batch_size': 16}. Best is trial 23 with value: 0.5458906622638048.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30: Test Accuracy = 0.4870\n",
      "trial:33 hidden_size: 256, num_layers: 3, learning_rate: 0.00017652766204073552, optimizer_name: Adam, weight_decay: 1.0374394543844917e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:11:29,693] Trial 31 finished with value: 0.4688558674249374 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 0.00020183804726011523, 'weight_decay': 1.0307741391643246e-06, 'batch_size': 16}. Best is trial 23 with value: 0.5458906622638048.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 31: Test Accuracy = 0.4689\n",
      "trial:34 hidden_size: 256, num_layers: 3, learning_rate: 0.00015828163022572314, optimizer_name: Adam, weight_decay: 1.4164101746302888e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:11:44,126] Trial 32 finished with value: 0.46564850486149334 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 0.00017984205285183027, 'weight_decay': 8.19016586071977e-06, 'batch_size': 10}. Best is trial 23 with value: 0.5458906622638048.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 32: Test Accuracy = 0.4656\n",
      "trial:35 hidden_size: 256, num_layers: 3, learning_rate: 1.6310590776168177e-05, optimizer_name: Adam, weight_decay: 1.8190280846527862e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:11:58,256] Trial 33 finished with value: 0.4953097291016939 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 0.00017652766204073552, 'weight_decay': 1.0374394543844917e-06, 'batch_size': 16}. Best is trial 23 with value: 0.5458906622638048.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 33: Test Accuracy = 0.4953\n",
      "trial:36 hidden_size: 64, num_layers: 3, learning_rate: 2.034755435419094e-05, optimizer_name: Adam, weight_decay: 1.6502712188531186e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:14:35,402] Trial 35 finished with value: 0.5080291078089648 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 1.6310590776168177e-05, 'weight_decay': 1.8190280846527862e-06, 'batch_size': 16}. Best is trial 23 with value: 0.5458906622638048.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 35: Test Accuracy = 0.5080\n",
      "trial:37 hidden_size: 64, num_layers: 3, learning_rate: 1.2779244638936786e-06, optimizer_name: Adam, weight_decay: 1.923317509835789e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:14:45,301] Trial 34 finished with value: 0.4655904115452822 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 0.00015828163022572314, 'weight_decay': 1.4164101746302888e-06, 'batch_size': 16}. Best is trial 23 with value: 0.5458906622638048.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 34: Test Accuracy = 0.4656\n",
      "trial:38 hidden_size: 64, num_layers: 2, learning_rate: 1.2274357307801657e-06, optimizer_name: Adam, weight_decay: 1.3796142896443128e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:14:50,905] Trial 36 finished with value: 0.5221213233045925 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 2.034755435419094e-05, 'weight_decay': 1.6502712188531186e-06, 'batch_size': 16}. Best is trial 23 with value: 0.5458906622638048.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 36: Test Accuracy = 0.5221\n",
      "trial:39 hidden_size: 64, num_layers: 2, learning_rate: 1.5384231480925187e-06, optimizer_name: Adam, weight_decay: 1.6570803729503728e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:15:26,669] Trial 39 finished with value: 0.33473980309423346 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 1.5384231480925187e-06, 'weight_decay': 1.6570803729503728e-06, 'batch_size': 32}. Best is trial 23 with value: 0.5458906622638048.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 39: Test Accuracy = 0.3347\n",
      "trial:40 hidden_size: 64, num_layers: 2, learning_rate: 2.3412547659517785e-05, optimizer_name: Adam, weight_decay: 1.4264299556545916e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:16:02,123] Trial 37 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 1.2779244638936786e-06, 'weight_decay': 1.923317509835789e-06, 'batch_size': 32}. Best is trial 23 with value: 0.5458906622638048.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 37: Test Accuracy = 0.3333\n",
      "trial:41 hidden_size: 64, num_layers: 2, learning_rate: 2.7440562655956753e-05, optimizer_name: Adam, weight_decay: 1.3620703630478439e-05, batch_size: 10, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:16:20,224] Trial 38 finished with value: 0.3997584541062802 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 1.2274357307801657e-06, 'weight_decay': 1.3796142896443128e-05, 'batch_size': 32}. Best is trial 23 with value: 0.5458906622638048.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 38: Test Accuracy = 0.3998\n",
      "trial:42 hidden_size: 64, num_layers: 4, learning_rate: 2.6799918542826326e-05, optimizer_name: Adam, weight_decay: 5.759800224374591e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:16:56,341] Trial 40 finished with value: 0.4868831407081269 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 2.3412547659517785e-05, 'weight_decay': 1.4264299556545916e-05, 'batch_size': 16}. Best is trial 23 with value: 0.5458906622638048.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 40: Test Accuracy = 0.4869\n",
      "trial:43 hidden_size: 32, num_layers: 3, learning_rate: 1.0650501507903034e-05, optimizer_name: Adam, weight_decay: 2.983582333517331e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:17:18,215] Trial 41 finished with value: 0.48034611386289977 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.30000000000000004, 'learning_rate': 2.7440562655956753e-05, 'weight_decay': 1.3620703630478439e-05, 'batch_size': 10}. Best is trial 23 with value: 0.5458906622638048.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 41: Test Accuracy = 0.4803\n",
      "trial:44 hidden_size: 32, num_layers: 3, learning_rate: 1.3375576799517554e-05, optimizer_name: Adam, weight_decay: 5.8230806673000865e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:17:34,552] Trial 43 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 32, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 1.0650501507903034e-05, 'weight_decay': 2.983582333517331e-06, 'batch_size': 10}. Best is trial 23 with value: 0.5458906622638048.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 43: Test Accuracy = 0.3333\n",
      "trial:45 hidden_size: 128, num_layers: 4, learning_rate: 6.339492809821357e-05, optimizer_name: Adam, weight_decay: 5.137548693679295e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:17:40,995] Trial 42 finished with value: 0.431388736011741 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 2.6799918542826326e-05, 'weight_decay': 5.759800224374591e-06, 'batch_size': 10}. Best is trial 23 with value: 0.5458906622638048.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 42: Test Accuracy = 0.4314\n",
      "trial:46 hidden_size: 128, num_layers: 3, learning_rate: 4.1288283092983574e-07, optimizer_name: Adam, weight_decay: 4.872808274419282e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:18:47,636] Trial 45 finished with value: 0.5824833363908763 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 6.339492809821357e-05, 'weight_decay': 5.137548693679295e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 45: Test Accuracy = 0.5825\n",
      "trial:47 hidden_size: 128, num_layers: 4, learning_rate: 0.0005657630110539962, optimizer_name: Adam, weight_decay: 4.843287212007385e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Trial 44: Test Accuracy = 0.4135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:19:00,166] Trial 44 finished with value: 0.41348070690393196 and parameters: {'hidden_size': 32, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 1.3375576799517554e-05, 'weight_decay': 5.8230806673000865e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:48 hidden_size: 128, num_layers: 4, learning_rate: 0.0006047938733534723, optimizer_name: Adam, weight_decay: 1.9144133925784025e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:19:24,259] Trial 46 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 128, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 4.1288283092983574e-07, 'weight_decay': 4.872808274419282e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 46: Test Accuracy = 0.3333\n",
      "trial:49 hidden_size: 128, num_layers: 4, learning_rate: 0.0008276524166979566, optimizer_name: Adam, weight_decay: 1.8744157750293014e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:19:30,284] Trial 47 finished with value: 0.45044640127193786 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 0.0005657630110539962, 'weight_decay': 4.843287212007385e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 47: Test Accuracy = 0.4504\n",
      "trial:50 hidden_size: 128, num_layers: 4, learning_rate: 0.0016954663370852218, optimizer_name: Adam, weight_decay: 1.9647720894535625e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:20:39,741] Trial 50 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 0.0016954663370852218, 'weight_decay': 1.9647720894535625e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50: Test Accuracy = 0.3333\n",
      "trial:51 hidden_size: 1024, num_layers: 4, learning_rate: 7.04063605626784e-05, optimizer_name: Adam, weight_decay: 7.87106990870521e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Trial 48: Test Accuracy = 0.4919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:20:50,248] Trial 48 finished with value: 0.49190668378890723 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 0.0006047938733534723, 'weight_decay': 1.9144133925784025e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:52 hidden_size: 1024, num_layers: 4, learning_rate: 4.798290666610629e-05, optimizer_name: Adam, weight_decay: 8.97072363522147e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:24:08,452] Trial 49 finished with value: 0.4524490919097414 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 0.0008276524166979566, 'weight_decay': 1.8744157750293014e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 49: Test Accuracy = 0.4524\n",
      "trial:53 hidden_size: 1024, num_layers: 1, learning_rate: 7.208640457626904e-05, optimizer_name: Adam, weight_decay: 8.730184305462098e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 20\n",
      "Trial 52: Test Accuracy = 0.4648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:41:27,939] Trial 52 finished with value: 0.46479545037607783 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 4.798290666610629e-05, 'weight_decay': 8.97072363522147e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:54 hidden_size: 256, num_layers: 1, learning_rate: 1.1185302048700829e-08, optimizer_name: Adam, weight_decay: 3.334290379197963e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 27\n",
      "Trial 53: Test Accuracy = 0.4797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:43:45,291] Trial 53 finished with value: 0.47968262704090997 and parameters: {'hidden_size': 1024, 'num_layers': 1, 'dropout': 0.5, 'learning_rate': 7.208640457626904e-05, 'weight_decay': 8.730184305462098e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:55 hidden_size: 32, num_layers: 3, learning_rate: 9.520711552746442e-05, optimizer_name: Adam, weight_decay: 3.3396030994883506e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:44:07,257] Trial 51 finished with value: 0.5231241973949734 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 7.04063605626784e-05, 'weight_decay': 7.87106990870521e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 51: Test Accuracy = 0.5231\n",
      "trial:56 hidden_size: 1024, num_layers: 4, learning_rate: 9.58326007464065e-05, optimizer_name: Adam, weight_decay: 1.5153541107862053e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 22\n",
      "Trial 55: Test Accuracy = 0.4308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:48:13,617] Trial 55 finished with value: 0.43081697547850545 and parameters: {'hidden_size': 32, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 9.520711552746442e-05, 'weight_decay': 3.3396030994883506e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:57 hidden_size: 1024, num_layers: 4, learning_rate: 0.00010326025254796035, optimizer_name: Adam, weight_decay: 0.00011794411982189283, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 07:55:06,602] Trial 54 finished with value: 0.3239099859353024 and parameters: {'hidden_size': 256, 'num_layers': 1, 'dropout': 0.5, 'learning_rate': 1.1185302048700829e-08, 'weight_decay': 3.334290379197963e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 54: Test Accuracy = 0.3239\n",
      "trial:58 hidden_size: 1024, num_layers: 4, learning_rate: 9.481672954626657e-05, optimizer_name: Adam, weight_decay: 1.8759699337874683e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n",
      "Trial 57: Test Accuracy = 0.5079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 08:14:35,508] Trial 57 finished with value: 0.5078976334617501 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00010326025254796035, 'weight_decay': 0.00011794411982189283, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:59 hidden_size: 1024, num_layers: 4, learning_rate: 0.0003366681757210211, optimizer_name: Adam, weight_decay: 2.49460897172366e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 27\n",
      "Trial 59: Test Accuracy = 0.4806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 10:38:24,077] Trial 59 finished with value: 0.48057848712774415 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.0003366681757210211, 'weight_decay': 2.49460897172366e-06, 'batch_size': 32}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:60 hidden_size: 512, num_layers: 4, learning_rate: 3.9274539963314394e-05, optimizer_name: Adam, weight_decay: 2.924202286455527e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 26\n",
      "Trial 56: Test Accuracy = 0.4744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 10:38:46,892] Trial 56 finished with value: 0.47442059560936833 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 9.58326007464065e-05, 'weight_decay': 1.5153541107862053e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:61 hidden_size: 32, num_layers: 4, learning_rate: 4.4345906301302604e-05, optimizer_name: Adam, weight_decay: 2.0489011837121367e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 29\n",
      "Trial 58: Test Accuracy = 0.4850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 10:45:25,275] Trial 58 finished with value: 0.48497523390203634 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 9.481672954626657e-05, 'weight_decay': 1.8759699337874683e-05, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:62 hidden_size: 512, num_layers: 4, learning_rate: 4.1941047087544825e-05, optimizer_name: Adam, weight_decay: 2.4820025435979283e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Trial 61: Test Accuracy = 0.4801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 10:47:03,677] Trial 61 finished with value: 0.4801443160276402 and parameters: {'hidden_size': 32, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 4.4345906301302604e-05, 'weight_decay': 2.0489011837121367e-05, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:63 hidden_size: 1024, num_layers: 4, learning_rate: 3.280601586302327e-05, optimizer_name: Adam, weight_decay: 0.00011119455121110105, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 24\n",
      "Trial 60: Test Accuracy = 0.5062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 10:48:47,896] Trial 60 finished with value: 0.5061670641472512 and parameters: {'hidden_size': 512, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 3.9274539963314394e-05, 'weight_decay': 2.924202286455527e-05, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:64 hidden_size: 1024, num_layers: 4, learning_rate: 8.840177932301243e-06, optimizer_name: Adam, weight_decay: 0.00019600430610629675, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 11:04:57,706] Trial 62 finished with value: 0.5045251635785483 and parameters: {'hidden_size': 512, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 4.1941047087544825e-05, 'weight_decay': 2.4820025435979283e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 62: Test Accuracy = 0.5045\n",
      "trial:65 hidden_size: 1024, num_layers: 4, learning_rate: 1.0404291497878331e-05, optimizer_name: Adam, weight_decay: 7.982886252692402e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 23\n",
      "Trial 64: Test Accuracy = 0.5021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 12:59:25,509] Trial 64 finished with value: 0.5021311074420596 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 8.840177932301243e-06, 'weight_decay': 0.00019600430610629675, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:66 hidden_size: 1024, num_layers: 4, learning_rate: 0.000281932087618352, optimizer_name: Adam, weight_decay: 8.81097986750354e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 18\n",
      "Trial 65: Test Accuracy = 0.4252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 13:16:54,469] Trial 65 finished with value: 0.4252400171222406 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 1.0404291497878331e-05, 'weight_decay': 7.982886252692402e-05, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:67 hidden_size: 1024, num_layers: 3, learning_rate: 2.5439009253783245e-06, optimizer_name: Adam, weight_decay: 0.0001281404466450345, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 19\n",
      "Trial 63: Test Accuracy = 0.5033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 14:26:53,231] Trial 63 finished with value: 0.5032868586803645 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 3.280601586302327e-05, 'weight_decay': 0.00011119455121110105, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:68 hidden_size: 32, num_layers: 3, learning_rate: 1.6993552106436047e-05, optimizer_name: Adam, weight_decay: 0.0009144508362710398, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 22\n",
      "Trial 66: Test Accuracy = 0.4704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:03:00,270] Trial 66 finished with value: 0.47035100593163337 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.1, 'learning_rate': 0.000281932087618352, 'weight_decay': 8.81097986750354e-05, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:69 hidden_size: 32, num_layers: 3, learning_rate: 1.9376368737861753e-05, optimizer_name: Adam, weight_decay: 0.0005043575879504142, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Trial 68: Test Accuracy = 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:05:00,911] Trial 68 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 32, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 1.6993552106436047e-05, 'weight_decay': 0.0009144508362710398, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:70 hidden_size: 64, num_layers: 3, learning_rate: 0.009189740718549949, optimizer_name: Adam, weight_decay: 1.3666849932439686e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:06:29,356] Trial 67 finished with value: 0.44688130618235195 and parameters: {'hidden_size': 1024, 'num_layers': 3, 'dropout': 0.1, 'learning_rate': 2.5439009253783245e-06, 'weight_decay': 0.0001281404466450345, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 67: Test Accuracy = 0.4469\n",
      "trial:71 hidden_size: 64, num_layers: 1, learning_rate: 0.00012851230408672475, optimizer_name: Adam, weight_decay: 0.0003720466928370262, batch_size: 10, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:07:00,750] Trial 69 finished with value: 0.38816425120772946 and parameters: {'hidden_size': 32, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 1.9376368737861753e-05, 'weight_decay': 0.0005043575879504142, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 69: Test Accuracy = 0.3882\n",
      "trial:72 hidden_size: 256, num_layers: 1, learning_rate: 0.00890098443272906, optimizer_name: Adam, weight_decay: 1.2257784718629584e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:07:30,459] Trial 71 finished with value: 0.4825628325077968 and parameters: {'hidden_size': 64, 'num_layers': 1, 'dropout': 0.4, 'learning_rate': 0.00012851230408672475, 'weight_decay': 0.0003720466928370262, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 71: Test Accuracy = 0.4826\n",
      "trial:73 hidden_size: 256, num_layers: 3, learning_rate: 7.063001591583166e-05, optimizer_name: Adam, weight_decay: 1.2815339842145125e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:07:46,653] Trial 70 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.1, 'learning_rate': 0.009189740718549949, 'weight_decay': 1.3666849932439686e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 70: Test Accuracy = 0.3333\n",
      "trial:74 hidden_size: 256, num_layers: 3, learning_rate: 5.8910803901583556e-05, optimizer_name: Adam, weight_decay: 3.974836234524744e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:07:59,427] Trial 72 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 256, 'num_layers': 1, 'dropout': 0.4, 'learning_rate': 0.00890098443272906, 'weight_decay': 1.2257784718629584e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 72: Test Accuracy = 0.3333\n",
      "trial:75 hidden_size: 256, num_layers: 3, learning_rate: 5.6951345794289284e-05, optimizer_name: Adam, weight_decay: 3.845574121240023e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:10:23,995] Trial 74 finished with value: 0.4654436494832752 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 5.8910803901583556e-05, 'weight_decay': 3.974836234524744e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 74: Test Accuracy = 0.4654\n",
      "trial:76 hidden_size: 256, num_layers: 3, learning_rate: 5.234073777759766e-06, optimizer_name: Adam, weight_decay: 6.620510757950101e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:10:25,570] Trial 75 finished with value: 0.4396746774292179 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 5.6951345794289284e-05, 'weight_decay': 3.845574121240023e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 75: Test Accuracy = 0.4397\n",
      "trial:77 hidden_size: 256, num_layers: 3, learning_rate: 2.3155714047189033e-05, optimizer_name: Adam, weight_decay: 6.341681566355062e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:11:25,437] Trial 73 finished with value: 0.48408854644407756 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 7.063001591583166e-05, 'weight_decay': 1.2815339842145125e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 73: Test Accuracy = 0.4841\n",
      "trial:78 hidden_size: 256, num_layers: 3, learning_rate: 2.4276215534451476e-06, optimizer_name: Adam, weight_decay: 4.544667264030401e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:12:28,936] Trial 77 finished with value: 0.4994893903259341 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 2.3155714047189033e-05, 'weight_decay': 6.341681566355062e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 77: Test Accuracy = 0.4995\n",
      "trial:79 hidden_size: 128, num_layers: 3, learning_rate: 7.374660646513799e-06, optimizer_name: Adam, weight_decay: 7.156417678461185e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:13:37,908] Trial 78 finished with value: 0.46750137589433133 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 2.4276215534451476e-06, 'weight_decay': 4.544667264030401e-05, 'batch_size': 32}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 78: Test Accuracy = 0.4675\n",
      "trial:80 hidden_size: 128, num_layers: 2, learning_rate: 6.2557038395132335e-06, optimizer_name: Adam, weight_decay: 6.885577993030594e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:14:19,360] Trial 76 finished with value: 0.5403687396807926 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 5.234073777759766e-06, 'weight_decay': 6.620510757950101e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 76: Test Accuracy = 0.5404\n",
      "trial:81 hidden_size: 128, num_layers: 2, learning_rate: 0.0001308759406932796, optimizer_name: Adam, weight_decay: 1.6234398844611214e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:14:30,933] Trial 79 finished with value: 0.48794410811471894 and parameters: {'hidden_size': 128, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 7.374660646513799e-06, 'weight_decay': 7.156417678461185e-06, 'batch_size': 32}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 79: Test Accuracy = 0.4879\n",
      "trial:82 hidden_size: 256, num_layers: 2, learning_rate: 0.00011493240963402832, optimizer_name: Adam, weight_decay: 1.1237332855938683e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:15:24,155] Trial 81 finished with value: 0.4700177337491591 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.30000000000000004, 'learning_rate': 0.0001308759406932796, 'weight_decay': 1.6234398844611214e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 81: Test Accuracy = 0.4700\n",
      "trial:83 hidden_size: 256, num_layers: 3, learning_rate: 7.103927428191886e-07, optimizer_name: Adam, weight_decay: 2.8952017676710424e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:15:40,984] Trial 80 finished with value: 0.4340029352412402 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.30000000000000004, 'learning_rate': 6.2557038395132335e-06, 'weight_decay': 6.885577993030594e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 80: Test Accuracy = 0.4340\n",
      "trial:84 hidden_size: 256, num_layers: 3, learning_rate: 3.257150893931696e-06, optimizer_name: Adam, weight_decay: 1.1497900091801026e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:16:47,078] Trial 82 finished with value: 0.43499052161682866 and parameters: {'hidden_size': 256, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 0.00011493240963402832, 'weight_decay': 1.1237332855938683e-05, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 82: Test Accuracy = 0.4350\n",
      "trial:85 hidden_size: 256, num_layers: 3, learning_rate: 1.2276902963740052e-05, optimizer_name: Adam, weight_decay: 4.624659422490529e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:19:36,312] Trial 85 finished with value: 0.46217819360362006 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 1.2276902963740052e-05, 'weight_decay': 4.624659422490529e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 85: Test Accuracy = 0.4622\n",
      "trial:86 hidden_size: 256, num_layers: 3, learning_rate: 4.408246535191593e-06, optimizer_name: Adam, weight_decay: 2.104918597460127e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:20:02,236] Trial 83 finished with value: 0.35295358649789027 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 7.103927428191886e-07, 'weight_decay': 2.8952017676710424e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 83: Test Accuracy = 0.3530\n",
      "trial:87 hidden_size: 256, num_layers: 3, learning_rate: 4.664435078335767e-06, optimizer_name: Adam, weight_decay: 2.156271758485406e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:20:10,870] Trial 84 finished with value: 0.4716168287164435 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 3.257150893931696e-06, 'weight_decay': 1.1497900091801026e-05, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 84: Test Accuracy = 0.4716\n",
      "trial:88 hidden_size: 64, num_layers: 3, learning_rate: 1.5588279386303904e-05, optimizer_name: Adam, weight_decay: 2.2152816197658966e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:21:16,947] Trial 88 finished with value: 0.42215189873417724 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 1.5588279386303904e-05, 'weight_decay': 2.2152816197658966e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 88: Test Accuracy = 0.4222\n",
      "trial:89 hidden_size: 256, num_layers: 3, learning_rate: 0.00024391829210004246, optimizer_name: Adam, weight_decay: 3.017968960532364e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:24:12,109] Trial 86 finished with value: 0.531031003485599 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 4.408246535191593e-06, 'weight_decay': 2.104918597460127e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 86: Test Accuracy = 0.5310\n",
      "trial:90 hidden_size: 256, num_layers: 3, learning_rate: 2.9506615891840144e-05, optimizer_name: Adam, weight_decay: 1.8104354599273158e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:24:16,233] Trial 89 finished with value: 0.4531492692472329 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 0.00024391829210004246, 'weight_decay': 3.017968960532364e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 89: Test Accuracy = 0.4531\n",
      "trial:91 hidden_size: 512, num_layers: 3, learning_rate: 3.1903158862626636e-05, optimizer_name: Adam, weight_decay: 1.7479872249027043e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:24:48,600] Trial 87 finished with value: 0.533247722130496 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 4.664435078335767e-06, 'weight_decay': 2.156271758485406e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 87: Test Accuracy = 0.5332\n",
      "trial:92 hidden_size: 256, num_layers: 3, learning_rate: 1.9393412175186558e-06, optimizer_name: Adam, weight_decay: 1.7741846034998748e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:27:27,548] Trial 90 finished with value: 0.5079312664342934 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 2.9506615891840144e-05, 'weight_decay': 1.8104354599273158e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 90: Test Accuracy = 0.5079\n",
      "trial:93 hidden_size: 256, num_layers: 3, learning_rate: 4.745260368772041e-06, optimizer_name: Adam, weight_decay: 1.768330759660113e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:27:42,613] Trial 91 finished with value: 0.47421268268819183 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 3.1903158862626636e-05, 'weight_decay': 1.7479872249027043e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 91: Test Accuracy = 0.4742\n",
      "trial:94 hidden_size: 256, num_layers: 3, learning_rate: 4.60815416061837e-06, optimizer_name: Adam, weight_decay: 2.3051504770351466e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:30:11,751] Trial 92 finished with value: 0.4505717605332355 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 1.9393412175186558e-06, 'weight_decay': 1.7741846034998748e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 92: Test Accuracy = 0.4506\n",
      "trial:95 hidden_size: 256, num_layers: 3, learning_rate: 7.971367640131373e-06, optimizer_name: Adam, weight_decay: 2.2197209468503305e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:32:12,478] Trial 93 finished with value: 0.485082247905583 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 4.745260368772041e-06, 'weight_decay': 1.768330759660113e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 93: Test Accuracy = 0.4851\n",
      "trial:96 hidden_size: 256, num_layers: 3, learning_rate: 8.244669015066603e-06, optimizer_name: Adam, weight_decay: 2.2248441901676865e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:32:25,098] Trial 94 finished with value: 0.49586008683422006 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 4.60815416061837e-06, 'weight_decay': 2.3051504770351466e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 94: Test Accuracy = 0.4959\n",
      "trial:97 hidden_size: 256, num_layers: 3, learning_rate: 8.21363225600508e-06, optimizer_name: Adam, weight_decay: 1.1675684008559463e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:35:26,916] Trial 95 finished with value: 0.4825230844493365 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 7.971367640131373e-06, 'weight_decay': 2.2197209468503305e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 95: Test Accuracy = 0.4825\n",
      "trial:98 hidden_size: 256, num_layers: 3, learning_rate: 2.1717405392546046e-05, optimizer_name: Adam, weight_decay: 1.208264692507042e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:36:22,120] Trial 96 finished with value: 0.44198923744878615 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 8.244669015066603e-06, 'weight_decay': 2.2248441901676865e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 96: Test Accuracy = 0.4420\n",
      "trial:99 hidden_size: 256, num_layers: 3, learning_rate: 2.752744146570901e-05, optimizer_name: Adam, weight_decay: 1.4613543129961264e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:37:06,448] Trial 97 finished with value: 0.4824099553598728 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 8.21363225600508e-06, 'weight_decay': 1.1675684008559463e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 97: Test Accuracy = 0.4824\n",
      "trial:100 hidden_size: 32, num_layers: 3, learning_rate: 2.742528385580587e-05, optimizer_name: Adam, weight_decay: 1.5444495309136558e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:38:37,616] Trial 98 finished with value: 0.5175625267535009 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 2.1717405392546046e-05, 'weight_decay': 1.208264692507042e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 98: Test Accuracy = 0.5176\n",
      "trial:101 hidden_size: 32, num_layers: 3, learning_rate: 2.0933992863424964e-05, optimizer_name: Adam, weight_decay: 1.4508466056976126e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:39:52,034] Trial 100 finished with value: 0.3598728062129273 and parameters: {'hidden_size': 32, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 2.742528385580587e-05, 'weight_decay': 1.5444495309136558e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100: Test Accuracy = 0.3599\n",
      "trial:102 hidden_size: 256, num_layers: 3, learning_rate: 7.881222139125556e-07, optimizer_name: Adam, weight_decay: 2.795879091527542e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:40:16,491] Trial 101 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 32, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 2.0933992863424964e-05, 'weight_decay': 1.4508466056976126e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 101: Test Accuracy = 0.3333\n",
      "trial:103 hidden_size: 256, num_layers: 3, learning_rate: 1.2768957429892368e-05, optimizer_name: Adam, weight_decay: 1.1164754595028456e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:40:26,415] Trial 99 finished with value: 0.4593193909374427 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 2.752744146570901e-05, 'weight_decay': 1.4613543129961264e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 99: Test Accuracy = 0.4593\n",
      "trial:104 hidden_size: 256, num_layers: 3, learning_rate: 1.3389575682725228e-05, optimizer_name: Adam, weight_decay: 1.0378795601446366e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:44:42,544] Trial 104 finished with value: 0.4741912798874824 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 1.3389575682725228e-05, 'weight_decay': 1.0378795601446366e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 104: Test Accuracy = 0.4742\n",
      "trial:105 hidden_size: 256, num_layers: 3, learning_rate: 6.0072933271553846e-05, optimizer_name: Adam, weight_decay: 2.9063467566625714e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:45:57,851] Trial 103 finished with value: 0.46609184859047265 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 1.2768957429892368e-05, 'weight_decay': 1.1164754595028456e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 103: Test Accuracy = 0.4661\n",
      "trial:106 hidden_size: 256, num_layers: 3, learning_rate: 6.499908867178303e-05, optimizer_name: Adam, weight_decay: 2.806541668616492e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:46:24,732] Trial 102 finished with value: 0.38658350149819604 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 7.881222139125556e-07, 'weight_decay': 2.795879091527542e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 102: Test Accuracy = 0.3866\n",
      "trial:107 hidden_size: 64, num_layers: 3, learning_rate: 3.2802340622997205e-06, optimizer_name: Adam, weight_decay: 5.1417113122842725e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:47:37,619] Trial 105 finished with value: 0.44372286430624347 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 6.0072933271553846e-05, 'weight_decay': 2.9063467566625714e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 105: Test Accuracy = 0.4437\n",
      "trial:108 hidden_size: 64, num_layers: 3, learning_rate: 4.820055092464264e-05, optimizer_name: Adam, weight_decay: 3.4733168101129252e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:48:47,293] Trial 107 finished with value: 0.33888888888888885 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 3.2802340622997205e-06, 'weight_decay': 5.1417113122842725e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 107: Test Accuracy = 0.3389\n",
      "trial:109 hidden_size: 256, num_layers: 3, learning_rate: 5.66628109352953e-06, optimizer_name: Adam, weight_decay: 2.064351381301615e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:49:09,270] Trial 106 finished with value: 0.5214975845410629 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 6.499908867178303e-05, 'weight_decay': 2.806541668616492e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 106: Test Accuracy = 0.5215\n",
      "trial:110 hidden_size: 256, num_layers: 1, learning_rate: 4.058900067123065e-05, optimizer_name: Adam, weight_decay: 4.420781362187665e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:49:18,060] Trial 108 finished with value: 0.5443863511282334 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 4.820055092464264e-05, 'weight_decay': 3.4733168101129252e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 108: Test Accuracy = 0.5444\n",
      "trial:111 hidden_size: 64, num_layers: 1, learning_rate: 7.826399191973147e-05, optimizer_name: Adam, weight_decay: 4.1392764289853746e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:51:17,547] Trial 111 finished with value: 0.4631841252369595 and parameters: {'hidden_size': 64, 'num_layers': 1, 'dropout': 0.4, 'learning_rate': 7.826399191973147e-05, 'weight_decay': 4.1392764289853746e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 111: Test Accuracy = 0.4632\n",
      "trial:112 hidden_size: 64, num_layers: 3, learning_rate: 4.0485635874918275e-05, optimizer_name: Adam, weight_decay: 3.3784196725527723e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:52:10,407] Trial 110 finished with value: 0.5073381031003485 and parameters: {'hidden_size': 256, 'num_layers': 1, 'dropout': 0.4, 'learning_rate': 4.058900067123065e-05, 'weight_decay': 4.420781362187665e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 110: Test Accuracy = 0.5073\n",
      "trial:113 hidden_size: 64, num_layers: 3, learning_rate: 0.00014420665633715622, optimizer_name: Adam, weight_decay: 9.245135601340798e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:52:31,537] Trial 109 finished with value: 0.47257383966244726 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 5.66628109352953e-06, 'weight_decay': 2.064351381301615e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 109: Test Accuracy = 0.4726\n",
      "trial:114 hidden_size: 64, num_layers: 3, learning_rate: 5.91513461223835e-05, optimizer_name: Adam, weight_decay: 3.442552390986921e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:53:05,530] Trial 112 finished with value: 0.45952730385861923 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 4.0485635874918275e-05, 'weight_decay': 3.3784196725527723e-06, 'batch_size': 32}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 112: Test Accuracy = 0.4595\n",
      "trial:115 hidden_size: 64, num_layers: 3, learning_rate: 0.00021467400198071256, optimizer_name: Adam, weight_decay: 5.397331709804964e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:53:31,141] Trial 113 finished with value: 0.4953922827615728 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 0.00014420665633715622, 'weight_decay': 9.245135601340798e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 113: Test Accuracy = 0.4954\n",
      "trial:116 hidden_size: 64, num_layers: 3, learning_rate: 0.00021004928343650492, optimizer_name: Adam, weight_decay: 5.471536335884914e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 21\n",
      "Trial 114: Test Accuracy = 0.4825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:53:45,950] Trial 114 finished with value: 0.48251391182046105 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 5.91513461223835e-05, 'weight_decay': 3.442552390986921e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:117 hidden_size: 128, num_layers: 3, learning_rate: 0.0002006842619354549, optimizer_name: Adam, weight_decay: 5.567831791654155e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:54:36,896] Trial 116 finished with value: 0.4738396624472574 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 0.00021004928343650492, 'weight_decay': 5.471536335884914e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 116: Test Accuracy = 0.4738\n",
      "trial:118 hidden_size: 128, num_layers: 4, learning_rate: 1.7612922557856576e-05, optimizer_name: Adam, weight_decay: 2.6275372345091473e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:54:47,000] Trial 115 finished with value: 0.4232770745428973 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 0.00021467400198071256, 'weight_decay': 5.397331709804964e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 115: Test Accuracy = 0.4233\n",
      "trial:119 hidden_size: 32, num_layers: 4, learning_rate: 1.9359498476930684e-05, optimizer_name: Adam, weight_decay: 2.4926040537397336e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:55:05,403] Trial 117 finished with value: 0.4515104262214884 and parameters: {'hidden_size': 128, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 0.0002006842619354549, 'weight_decay': 5.567831791654155e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 117: Test Accuracy = 0.4515\n",
      "trial:120 hidden_size: 512, num_layers: 4, learning_rate: 1.874592565360945e-05, optimizer_name: Adam, weight_decay: 2.569842161293558e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:57:06,126] Trial 119 finished with value: 0.47956338286552924 and parameters: {'hidden_size': 32, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 1.9359498476930684e-05, 'weight_decay': 2.4926040537397336e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 119: Test Accuracy = 0.4796\n",
      "trial:121 hidden_size: 512, num_layers: 3, learning_rate: 8.109426548452025e-05, optimizer_name: Adam, weight_decay: 1.2603229907962955e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 15:57:29,043] Trial 118 finished with value: 0.4799792087078823 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 1.7612922557856576e-05, 'weight_decay': 2.6275372345091473e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 118: Test Accuracy = 0.4800\n",
      "trial:122 hidden_size: 512, num_layers: 3, learning_rate: 8.923025070071365e-05, optimizer_name: Adam, weight_decay: 1.3565665563343416e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 16:00:05,739] Trial 120 finished with value: 0.4547116736990155 and parameters: {'hidden_size': 512, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 1.874592565360945e-05, 'weight_decay': 2.569842161293558e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 120: Test Accuracy = 0.4547\n",
      "trial:123 hidden_size: 256, num_layers: 3, learning_rate: 8.581141398283648e-05, optimizer_name: Adam, weight_decay: 1.2598036885033525e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 16:01:57,379] Trial 122 finished with value: 0.530960679997554 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 8.923025070071365e-05, 'weight_decay': 1.3565665563343416e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 122: Test Accuracy = 0.5310\n",
      "trial:124 hidden_size: 512, num_layers: 3, learning_rate: 8.451157244932836e-05, optimizer_name: Adam, weight_decay: 1.3201779996114307e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 16:02:36,988] Trial 123 finished with value: 0.4991989237448786 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 8.581141398283648e-05, 'weight_decay': 1.2598036885033525e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 123: Test Accuracy = 0.4992\n",
      "trial:125 hidden_size: 512, num_layers: 3, learning_rate: 4.747633239917501e-05, optimizer_name: Adam, weight_decay: 1.9950499748192297e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 16:03:13,308] Trial 121 finished with value: 0.4420503883079558 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 8.109426548452025e-05, 'weight_decay': 1.2603229907962955e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 121: Test Accuracy = 0.4421\n",
      "trial:126 hidden_size: 256, num_layers: 3, learning_rate: 0.00011371114204562336, optimizer_name: Adam, weight_decay: 2.0110648331978613e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 16:06:43,708] Trial 125 finished with value: 0.45452822112150676 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 4.747633239917501e-05, 'weight_decay': 1.9950499748192297e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 125: Test Accuracy = 0.4545\n",
      "trial:127 hidden_size: 512, num_layers: 3, learning_rate: 0.00010792058260509826, optimizer_name: Adam, weight_decay: 1.6048707722451486e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 16:08:22,761] Trial 126 finished with value: 0.4632850241545894 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 0.00011371114204562336, 'weight_decay': 2.0110648331978613e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 126: Test Accuracy = 0.4633\n",
      "trial:128 hidden_size: 512, num_layers: 3, learning_rate: 1.0944169860638288e-05, optimizer_name: Adam, weight_decay: 1.0012630032254276e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 16:08:29,124] Trial 124 finished with value: 0.46552314560019575 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 8.451157244932836e-05, 'weight_decay': 1.3201779996114307e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 124: Test Accuracy = 0.4655\n",
      "trial:129 hidden_size: 512, num_layers: 3, learning_rate: 0.0004289938347942635, optimizer_name: Adam, weight_decay: 1.6924366034544753e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 16:12:34,716] Trial 129 finished with value: 0.445731670029964 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 0.0004289938347942635, 'weight_decay': 1.6924366034544753e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 129: Test Accuracy = 0.4457\n",
      "trial:130 hidden_size: 256, num_layers: 3, learning_rate: 5.271990201055737e-05, optimizer_name: Adam, weight_decay: 3.5241406012117257e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 16:12:52,981] Trial 127 finished with value: 0.48009233779734606 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 0.00010792058260509826, 'weight_decay': 1.6048707722451486e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 127: Test Accuracy = 0.4801\n",
      "trial:131 hidden_size: 256, num_layers: 3, learning_rate: 3.624451081806662e-05, optimizer_name: Adam, weight_decay: 3.14673639615622e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 16:14:19,486] Trial 128 finished with value: 0.44204733076499725 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 1.0944169860638288e-05, 'weight_decay': 1.0012630032254276e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 128: Test Accuracy = 0.4420\n",
      "trial:132 hidden_size: 256, num_layers: 3, learning_rate: 3.713169677623988e-05, optimizer_name: Adam, weight_decay: 6.586304849828502e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 16:15:03,638] Trial 130 finished with value: 0.4993640310646365 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 5.271990201055737e-05, 'weight_decay': 3.5241406012117257e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 130: Test Accuracy = 0.4994\n",
      "trial:133 hidden_size: 256, num_layers: 3, learning_rate: 3.2596516038082136e-05, optimizer_name: Adam, weight_decay: 1.8683328391843971e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 16:15:06,798] Trial 131 finished with value: 0.44113618296337065 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 3.624451081806662e-05, 'weight_decay': 3.14673639615622e-06, 'batch_size': 32}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 131: Test Accuracy = 0.4411\n",
      "trial:134 hidden_size: 256, num_layers: 3, learning_rate: 2.999330257145665e-05, optimizer_name: Adam, weight_decay: 1.4920393231688057e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 16:17:34,071] Trial 132 finished with value: 0.4364826025805663 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 3.713169677623988e-05, 'weight_decay': 6.586304849828502e-06, 'batch_size': 32}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 132: Test Accuracy = 0.4365\n",
      "trial:135 hidden_size: 256, num_layers: 3, learning_rate: 2.3891862909422718e-05, optimizer_name: Adam, weight_decay: 1.489913914978627e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 16:18:55,557] Trial 133 finished with value: 0.4709197089219104 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 3.2596516038082136e-05, 'weight_decay': 1.8683328391843971e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 133: Test Accuracy = 0.4709\n",
      "trial:136 hidden_size: 256, num_layers: 3, learning_rate: 2.3393696146956654e-05, optimizer_name: Adam, weight_decay: 1.4559725335993145e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 16:19:07,432] Trial 134 finished with value: 0.4672047942273589 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 2.999330257145665e-05, 'weight_decay': 1.4920393231688057e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 134: Test Accuracy = 0.4672\n",
      "trial:137 hidden_size: 1024, num_layers: 2, learning_rate: 6.230279192652879e-05, optimizer_name: Adam, weight_decay: 2.295820030337506e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 24\n",
      "Trial 135: Test Accuracy = 0.4441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 16:23:38,437] Trial 135 finished with value: 0.4440744817464686 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 2.3891862909422718e-05, 'weight_decay': 1.489913914978627e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:138 hidden_size: 1024, num_layers: 3, learning_rate: 2.356889030740107e-06, optimizer_name: Adam, weight_decay: 2.3071130485240125e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 22\n",
      "Trial 136: Test Accuracy = 0.4783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 16:27:58,877] Trial 136 finished with value: 0.47830061762367765 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 2.3393696146956654e-05, 'weight_decay': 1.4559725335993145e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:139 hidden_size: 1024, num_layers: 2, learning_rate: 6.20932994238299e-05, optimizer_name: Adam, weight_decay: 2.278545199525027e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 26\n",
      "Trial 137: Test Accuracy = 0.5194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 16:31:30,588] Trial 137 finished with value: 0.5193725921849203 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 6.230279192652879e-05, 'weight_decay': 2.295820030337506e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:140 hidden_size: 1024, num_layers: 2, learning_rate: 5.5537538909202854e-05, optimizer_name: Adam, weight_decay: 3.8470548473908085e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n",
      "Trial 139: Test Accuracy = 0.5373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 16:40:01,117] Trial 139 finished with value: 0.5373356570659819 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 6.20932994238299e-05, 'weight_decay': 2.278545199525027e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:141 hidden_size: 1024, num_layers: 2, learning_rate: 6.67811672055421e-05, optimizer_name: Adam, weight_decay: 3.905309014218907e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 14\n",
      "Trial 140: Test Accuracy = 0.4288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 16:42:46,058] Trial 140 finished with value: 0.4288356876414114 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 5.5537538909202854e-05, 'weight_decay': 3.8470548473908085e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:142 hidden_size: 1024, num_layers: 2, learning_rate: 0.00014830414287630807, optimizer_name: Adam, weight_decay: 7.776432350320728e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Trial 138: Test Accuracy = 0.4800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 16:44:57,356] Trial 138 finished with value: 0.4800311869381764 and parameters: {'hidden_size': 1024, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 2.356889030740107e-06, 'weight_decay': 2.3071130485240125e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:143 hidden_size: 1024, num_layers: 2, learning_rate: 0.00015757872496044775, optimizer_name: Adam, weight_decay: 7.681676070927202e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 11\n",
      "Trial 141: Test Accuracy = 0.5063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 16:48:33,911] Trial 141 finished with value: 0.5063015960374243 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 6.67811672055421e-05, 'weight_decay': 3.905309014218907e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:144 hidden_size: 1024, num_layers: 2, learning_rate: 0.00014991153316823257, optimizer_name: Adam, weight_decay: 2.666257997890808e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 14\n",
      "Trial 144: Test Accuracy = 0.5454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 16:59:28,463] Trial 144 finished with value: 0.5453555922460711 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 0.00014991153316823257, 'weight_decay': 2.666257997890808e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:145 hidden_size: 1024, num_layers: 2, learning_rate: 0.00010834731030664073, optimizer_name: Adam, weight_decay: 2.756267421759102e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Trial 142: Test Accuracy = 0.4888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 17:01:39,341] Trial 142 finished with value: 0.48877881734238365 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.00014830414287630807, 'weight_decay': 7.776432350320728e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:146 hidden_size: 1024, num_layers: 2, learning_rate: 0.00015450019137347787, optimizer_name: Adam, weight_decay: 2.7827617612220848e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Trial 143: Test Accuracy = 0.4627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 17:03:34,035] Trial 143 finished with value: 0.4626674004769767 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 0.00015757872496044775, 'weight_decay': 7.681676070927202e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:147 hidden_size: 1024, num_layers: 2, learning_rate: 0.00011438166223284585, optimizer_name: Adam, weight_decay: 2.837069314922313e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n",
      "Trial 145: Test Accuracy = 0.5132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 17:07:12,323] Trial 145 finished with value: 0.5132361034672537 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 0.00010834731030664073, 'weight_decay': 2.756267421759102e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:148 hidden_size: 1024, num_layers: 2, learning_rate: 7.164848028094578e-05, optimizer_name: Adam, weight_decay: 2.2031920243004695e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 24\n",
      "Trial 146: Test Accuracy = 0.4730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 17:17:10,116] Trial 146 finished with value: 0.47302329847734365 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 0.00015450019137347787, 'weight_decay': 2.7827617612220848e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:149 hidden_size: 1024, num_layers: 2, learning_rate: 6.478575295931085e-05, optimizer_name: Adam, weight_decay: 2.1716781796472683e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 17:21:39,904] Trial 147 finished with value: 0.44825414297070876 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 0.00011438166223284585, 'weight_decay': 2.837069314922313e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 147: Test Accuracy = 0.4483\n",
      "trial:150 hidden_size: 1024, num_layers: 2, learning_rate: 0.00032747731661669424, optimizer_name: Adam, weight_decay: 2.1882109116149925e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 17:26:45,917] Trial 148 finished with value: 0.516975478505473 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 7.164848028094578e-05, 'weight_decay': 2.2031920243004695e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 148: Test Accuracy = 0.5170\n",
      "trial:151 hidden_size: 1024, num_layers: 2, learning_rate: 0.0003341435236428683, optimizer_name: Adam, weight_decay: 1.2049191748304256e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 22\n",
      "Trial 149: Test Accuracy = 0.4727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 17:36:53,477] Trial 149 finished with value: 0.4727267168103712 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 6.478575295931085e-05, 'weight_decay': 2.1716781796472683e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:152 hidden_size: 32, num_layers: 2, learning_rate: 4.806054720163461e-05, optimizer_name: Adam, weight_decay: 4.522403408991995e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 17:38:20,495] Trial 151 finished with value: 0.48583440347336876 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.0003341435236428683, 'weight_decay': 1.2049191748304256e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 151: Test Accuracy = 0.4858\n",
      "trial:153 hidden_size: 1024, num_layers: 2, learning_rate: 7.503029935450465e-05, optimizer_name: Adam, weight_decay: 2.4038634491050404e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 17:40:26,048] Trial 150 finished with value: 0.5513911820461078 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.00032747731661669424, 'weight_decay': 2.1882109116149925e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 150: Test Accuracy = 0.5514\n",
      "trial:154 hidden_size: 1024, num_layers: 2, learning_rate: 0.00025066394474382466, optimizer_name: Adam, weight_decay: 4.484566576985278e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 17:44:52,530] Trial 152 finished with value: 0.49104751421757475 and parameters: {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 4.806054720163461e-05, 'weight_decay': 4.522403408991995e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 152: Test Accuracy = 0.4910\n",
      "trial:155 hidden_size: 1024, num_layers: 2, learning_rate: 0.0002796057437372313, optimizer_name: Adam, weight_decay: 2.4676647690956293e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 24\n",
      "Trial 153: Test Accuracy = 0.5116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 17:53:27,027] Trial 153 finished with value: 0.5115850302696753 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 7.503029935450465e-05, 'weight_decay': 2.4038634491050404e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:156 hidden_size: 1024, num_layers: 2, learning_rate: 0.00029003642462796037, optimizer_name: Adam, weight_decay: 3.214314622886313e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 17:55:48,129] Trial 154 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.00025066394474382466, 'weight_decay': 4.484566576985278e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 154: Test Accuracy = 0.3333\n",
      "trial:157 hidden_size: 1024, num_layers: 2, learning_rate: 0.001628438266714901, optimizer_name: Adam, weight_decay: 3.322813588384977e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n",
      "Trial 155: Test Accuracy = 0.5455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 17:58:28,684] Trial 155 finished with value: 0.5455176420228703 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.0002796057437372313, 'weight_decay': 2.4676647690956293e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:158 hidden_size: 1024, num_layers: 2, learning_rate: 0.00027385138312798423, optimizer_name: Adam, weight_decay: 3.1331904948324517e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n",
      "Trial 157: Test Accuracy = 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 18:05:10,598] Trial 157 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.001628438266714901, 'weight_decay': 3.322813588384977e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:159 hidden_size: 1024, num_layers: 2, learning_rate: 0.0005633792174408507, optimizer_name: Adam, weight_decay: 1.9741508508447467e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 18:06:09,085] Trial 156 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.00029003642462796037, 'weight_decay': 3.214314622886313e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 156: Test Accuracy = 0.3333\n",
      "trial:160 hidden_size: 1024, num_layers: 2, learning_rate: 0.0007715104966323789, optimizer_name: Adam, weight_decay: 2.7287086817121243e-05, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 12\n",
      "Trial 158: Test Accuracy = 0.3958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 18:09:44,730] Trial 158 finished with value: 0.3958142236898428 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.00027385138312798423, 'weight_decay': 3.1331904948324517e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:161 hidden_size: 1024, num_layers: 2, learning_rate: 3.889764218552209e-06, optimizer_name: Adam, weight_decay: 1.9997589997781276e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 14\n",
      "Trial 159: Test Accuracy = 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 18:13:51,693] Trial 159 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.0005633792174408507, 'weight_decay': 1.9741508508447467e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:162 hidden_size: 128, num_layers: 2, learning_rate: 0.0007427227055760138, optimizer_name: Adam, weight_decay: 2.3316801794384753e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n",
      "Trial 161: Test Accuracy = 0.4953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 18:22:36,939] Trial 161 finished with value: 0.4953219592735278 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 3.889764218552209e-06, 'weight_decay': 1.9997589997781276e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:163 hidden_size: 128, num_layers: 4, learning_rate: 1.387844036919123e-07, optimizer_name: Adam, weight_decay: 1.6530779089137321e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 20\n",
      "Trial 160: Test Accuracy = 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 18:22:46,039] Trial 160 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.0007715104966323789, 'weight_decay': 2.7287086817121243e-05, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:164 hidden_size: 128, num_layers: 4, learning_rate: 0.0001729372575451811, optimizer_name: Adam, weight_decay: 2.5942977528313783e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 18:23:14,461] Trial 162 finished with value: 0.5324466458753746 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.0007427227055760138, 'weight_decay': 2.3316801794384753e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 162: Test Accuracy = 0.5324\n",
      "trial:165 hidden_size: 128, num_layers: 2, learning_rate: 0.0010723364496896778, optimizer_name: Adam, weight_decay: 2.4944875214724177e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 18:24:43,202] Trial 164 finished with value: 0.45769277808353204 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 0.0001729372575451811, 'weight_decay': 2.5942977528313783e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 164: Test Accuracy = 0.4577\n",
      "trial:166 hidden_size: 128, num_layers: 2, learning_rate: 0.0007765738532150569, optimizer_name: Adam, weight_decay: 1.6961521382237295e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 18:24:45,998] Trial 163 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 1.387844036919123e-07, 'weight_decay': 1.6530779089137321e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 163: Test Accuracy = 0.3333\n",
      "trial:167 hidden_size: 128, num_layers: 2, learning_rate: 0.0010119311271806575, optimizer_name: Adam, weight_decay: 2.3544704458332626e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 18:25:15,707] Trial 165 finished with value: 0.5315263254448725 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.0010723364496896778, 'weight_decay': 2.4944875214724177e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 165: Test Accuracy = 0.5315\n",
      "trial:168 hidden_size: 128, num_layers: 2, learning_rate: 0.0006561073002225118, optimizer_name: Adam, weight_decay: 2.541099670813349e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 18:25:27,210] Trial 167 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.0010119311271806575, 'weight_decay': 2.3544704458332626e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 167: Test Accuracy = 0.3333\n",
      "trial:169 hidden_size: 128, num_layers: 2, learning_rate: 0.003617178115715378, optimizer_name: Adam, weight_decay: 3.552327158755971e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 18:26:15,276] Trial 168 finished with value: 0.43982449703418336 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.0006561073002225118, 'weight_decay': 2.541099670813349e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 168: Test Accuracy = 0.4398\n",
      "trial:170 hidden_size: 128, num_layers: 2, learning_rate: 0.003792236406666779, optimizer_name: Adam, weight_decay: 3.6249352073290208e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 18:26:32,031] Trial 166 finished with value: 0.36294563688619824 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.0007765738532150569, 'weight_decay': 1.6961521382237295e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 166: Test Accuracy = 0.3629\n",
      "trial:171 hidden_size: 128, num_layers: 2, learning_rate: 0.0003973085255092236, optimizer_name: Adam, weight_decay: 9.67475407125402e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 18:26:48,511] Trial 169 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.003617178115715378, 'weight_decay': 3.552327158755971e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 169: Test Accuracy = 0.3333\n",
      "trial:172 hidden_size: 128, num_layers: 1, learning_rate: 0.00040003236661101144, optimizer_name: Adam, weight_decay: 1.016181220208999e-05, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 18:27:13,614] Trial 170 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.003792236406666779, 'weight_decay': 3.6249352073290208e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 170: Test Accuracy = 0.3333\n",
      "trial:173 hidden_size: 128, num_layers: 2, learning_rate: 0.002425456898832653, optimizer_name: Adam, weight_decay: 2.9054713614773773e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 18:28:08,541] Trial 171 finished with value: 0.4521769705864367 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.0003973085255092236, 'weight_decay': 9.67475407125402e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 171: Test Accuracy = 0.4522\n",
      "trial:174 hidden_size: 64, num_layers: 2, learning_rate: 0.0018583498584303043, optimizer_name: Adam, weight_decay: 2.192093135470955e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 18:28:14,970] Trial 173 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.002425456898832653, 'weight_decay': 2.9054713614773773e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 173: Test Accuracy = 0.3333\n",
      "trial:175 hidden_size: 64, num_layers: 2, learning_rate: 0.0013493235899243918, optimizer_name: Adam, weight_decay: 2.170250235800763e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 18:28:30,910] Trial 172 finished with value: 0.4717238427199902 and parameters: {'hidden_size': 128, 'num_layers': 1, 'dropout': 0.5, 'learning_rate': 0.00040003236661101144, 'weight_decay': 1.016181220208999e-05, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 172: Test Accuracy = 0.4717\n",
      "trial:176 hidden_size: 64, num_layers: 2, learning_rate: 0.0010971188577556731, optimizer_name: Adam, weight_decay: 2.1646524918800625e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 18:29:51,033] Trial 174 finished with value: 0.36781936036201307 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.0018583498584303043, 'weight_decay': 2.192093135470955e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 174: Test Accuracy = 0.3678\n",
      "trial:177 hidden_size: 32, num_layers: 2, learning_rate: 0.0010216455097511725, optimizer_name: Adam, weight_decay: 1.8958758981879163e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 18:29:57,024] Trial 175 finished with value: 0.394147862777472 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.0013493235899243918, 'weight_decay': 2.170250235800763e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 175: Test Accuracy = 0.3941\n",
      "trial:178 hidden_size: 32, num_layers: 4, learning_rate: 0.0010538337088604557, optimizer_name: Adam, weight_decay: 1.908466510520135e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 18:30:12,700] Trial 176 finished with value: 0.42027762490062986 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.0010971188577556731, 'weight_decay': 2.1646524918800625e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 176: Test Accuracy = 0.4203\n",
      "trial:179 hidden_size: 1024, num_layers: 4, learning_rate: 5.3317718157958937e-08, optimizer_name: Adam, weight_decay: 1.8753969748242904e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 12\n",
      "Trial 178: Test Accuracy = 0.4376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 18:31:51,871] Trial 178 finished with value: 0.43755885770195074 and parameters: {'hidden_size': 32, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 0.0010538337088604557, 'weight_decay': 1.908466510520135e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:180 hidden_size: 1024, num_layers: 2, learning_rate: 0.0005013326099114507, optimizer_name: Adam, weight_decay: 2.6554695701232206e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 26\n",
      "Trial 177: Test Accuracy = 0.4816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 18:37:22,258] Trial 177 finished with value: 0.4816088791047514 and parameters: {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.0010216455097511725, 'weight_decay': 1.8958758981879163e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:181 hidden_size: 1024, num_layers: 4, learning_rate: 8.801903712761388e-05, optimizer_name: Adam, weight_decay: 2.505907779513629e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 11\n",
      "Trial 179: Test Accuracy = 0.3361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 18:39:31,446] Trial 179 finished with value: 0.3360759493670886 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 5.3317718157958937e-08, 'weight_decay': 1.8753969748242904e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:182 hidden_size: 1024, num_layers: 2, learning_rate: 9.511690999083619e-05, optimizer_name: Adam, weight_decay: 2.5211852258355694e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n",
      "Trial 180: Test Accuracy = 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 18:41:29,095] Trial 180 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.0005013326099114507, 'weight_decay': 2.6554695701232206e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:183 hidden_size: 1024, num_layers: 3, learning_rate: 9.258710350596693e-05, optimizer_name: Adam, weight_decay: 1.3307031127397919e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 21\n",
      "Trial 181: Test Accuracy = 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 19:43:01,574] Trial 181 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 8.801903712761388e-05, 'weight_decay': 2.505907779513629e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:184 hidden_size: 256, num_layers: 3, learning_rate: 4.9382517504774965e-06, optimizer_name: Adam, weight_decay: 1.333475143607681e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 29\n",
      "Trial 182: Test Accuracy = 0.4914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 19:44:41,668] Trial 182 finished with value: 0.491368556228215 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.30000000000000004, 'learning_rate': 9.511690999083619e-05, 'weight_decay': 2.5211852258355694e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:185 hidden_size: 256, num_layers: 3, learning_rate: 5.47445660636247e-06, optimizer_name: Adam, weight_decay: 1.1693439302830745e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 19:45:51,337] Trial 183 finished with value: 0.506995658288999 and parameters: {'hidden_size': 1024, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 9.258710350596693e-05, 'weight_decay': 1.3307031127397919e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 183: Test Accuracy = 0.5070\n",
      "trial:186 hidden_size: 256, num_layers: 3, learning_rate: 5.84190604953103e-06, optimizer_name: Adam, weight_decay: 1.6142336238901281e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 19:48:49,386] Trial 184 finished with value: 0.5123891640677551 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 4.9382517504774965e-06, 'weight_decay': 1.333475143607681e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 184: Test Accuracy = 0.5124\n",
      "trial:187 hidden_size: 256, num_layers: 3, learning_rate: 4.439254329687938e-05, optimizer_name: Adam, weight_decay: 1.1519022702036823e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 19:49:17,405] Trial 185 finished with value: 0.5046474652968874 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 5.47445660636247e-06, 'weight_decay': 1.1693439302830745e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 185: Test Accuracy = 0.5046\n",
      "trial:188 hidden_size: 64, num_layers: 3, learning_rate: 5.252881368563077e-05, optimizer_name: Adam, weight_decay: 1.0755908273521813e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 19:49:43,148] Trial 186 finished with value: 0.46837277563749774 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 5.84190604953103e-06, 'weight_decay': 1.6142336238901281e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 186: Test Accuracy = 0.4684\n",
      "trial:189 hidden_size: 512, num_layers: 3, learning_rate: 5.409221010222414e-05, optimizer_name: Adam, weight_decay: 3.04743265782847e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 19:51:38,202] Trial 188 finished with value: 0.46660857335045564 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 5.252881368563077e-05, 'weight_decay': 1.0755908273521813e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 188: Test Accuracy = 0.4666\n",
      "trial:190 hidden_size: 128, num_layers: 3, learning_rate: 0.0001215125455670776, optimizer_name: Adam, weight_decay: 3.000259854340182e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 19:51:51,623] Trial 187 finished with value: 0.3918088424142359 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 4.439254329687938e-05, 'weight_decay': 1.1519022702036823e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 187: Test Accuracy = 0.3918\n",
      "trial:191 hidden_size: 512, num_layers: 2, learning_rate: 0.00013290576983150952, optimizer_name: Adam, weight_decay: 3.0720527414631375e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 19:52:41,492] Trial 189 finished with value: 0.514969730324711 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 5.409221010222414e-05, 'weight_decay': 3.04743265782847e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 189: Test Accuracy = 0.5150\n",
      "trial:192 hidden_size: 128, num_layers: 2, learning_rate: 0.00012387251336363458, optimizer_name: Adam, weight_decay: 1.737719567247022e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 19:53:18,173] Trial 190 finished with value: 0.450076438573962 and parameters: {'hidden_size': 128, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 0.0001215125455670776, 'weight_decay': 3.000259854340182e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 190: Test Accuracy = 0.4501\n",
      "trial:193 hidden_size: 1024, num_layers: 2, learning_rate: 7.305662818339301e-05, optimizer_name: Adam, weight_decay: 2.2292025104195204e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 22\n",
      "Trial 191: Test Accuracy = 0.5426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 19:55:09,489] Trial 191 finished with value: 0.5425548828961047 and parameters: {'hidden_size': 512, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 0.00013290576983150952, 'weight_decay': 3.0720527414631375e-06, 'batch_size': 32}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:194 hidden_size: 512, num_layers: 2, learning_rate: 0.00013247545035242547, optimizer_name: Adam, weight_decay: 3.977574049742052e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 19:55:42,828] Trial 192 finished with value: 0.47434721457836476 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 0.00012387251336363458, 'weight_decay': 1.737719567247022e-06, 'batch_size': 32}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 192: Test Accuracy = 0.4743\n",
      "trial:195 hidden_size: 32, num_layers: 2, learning_rate: 0.00018939670670699012, optimizer_name: Adam, weight_decay: 2.352393951250878e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 26\n",
      "Trial 195: Test Accuracy = 0.4757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 19:58:53,118] Trial 195 finished with value: 0.47573533908151405 and parameters: {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 0.00018939670670699012, 'weight_decay': 2.352393951250878e-06, 'batch_size': 32}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:196 hidden_size: 512, num_layers: 2, learning_rate: 6.993963760772151e-05, optimizer_name: Adam, weight_decay: 4.0072555920957575e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 19:59:05,747] Trial 193 finished with value: 0.4959426404940989 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 7.305662818339301e-05, 'weight_decay': 2.2292025104195204e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 193: Test Accuracy = 0.4959\n",
      "trial:197 hidden_size: 512, num_layers: 2, learning_rate: 0.00013387111919715936, optimizer_name: Adam, weight_decay: 2.8993387680200132e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 20:00:19,238] Trial 194 finished with value: 0.5069987158319574 and parameters: {'hidden_size': 512, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 0.00013247545035242547, 'weight_decay': 3.977574049742052e-06, 'batch_size': 32}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 194: Test Accuracy = 0.5070\n",
      "trial:198 hidden_size: 512, num_layers: 2, learning_rate: 0.00020502907324900185, optimizer_name: Adam, weight_decay: 4.913458426472654e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 20:00:30,157] Trial 196 finished with value: 0.4082217330153488 and parameters: {'hidden_size': 512, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 6.993963760772151e-05, 'weight_decay': 4.0072555920957575e-06, 'batch_size': 32}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 196: Test Accuracy = 0.4082\n",
      "trial:199 hidden_size: 512, num_layers: 2, learning_rate: 3.639583066745105e-05, optimizer_name: Adam, weight_decay: 2.883843463878537e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 20:02:39,644] Trial 198 finished with value: 0.4809820827982633 and parameters: {'hidden_size': 512, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 0.00020502907324900185, 'weight_decay': 4.913458426472654e-06, 'batch_size': 32}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 198: Test Accuracy = 0.4810\n",
      "trial:200 hidden_size: 512, num_layers: 1, learning_rate: 3.3739606069967048e-06, optimizer_name: Adam, weight_decay: 6.176604076556577e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 20:03:10,005] Trial 197 finished with value: 0.4752124992356142 and parameters: {'hidden_size': 512, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 0.00013387111919715936, 'weight_decay': 2.8993387680200132e-06, 'batch_size': 32}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 197: Test Accuracy = 0.4752\n",
      "trial:201 hidden_size: 1024, num_layers: 1, learning_rate: 4.393060674222963e-05, optimizer_name: Adam, weight_decay: 3.4191889238184773e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Trial 199: Test Accuracy = 0.4228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 20:04:53,430] Trial 199 finished with value: 0.42280621292729165 and parameters: {'hidden_size': 512, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 3.639583066745105e-05, 'weight_decay': 2.883843463878537e-06, 'batch_size': 32}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:202 hidden_size: 1024, num_layers: 1, learning_rate: 2.992271558263836e-06, optimizer_name: Adam, weight_decay: 6.606537318637357e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 21\n",
      "Trial 201: Test Accuracy = 0.4648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 20:09:12,917] Trial 201 finished with value: 0.4647893352901608 and parameters: {'hidden_size': 1024, 'num_layers': 1, 'dropout': 0.5, 'learning_rate': 4.393060674222963e-05, 'weight_decay': 3.4191889238184773e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:203 hidden_size: 1024, num_layers: 2, learning_rate: 7.50010322103267e-05, optimizer_name: Adam, weight_decay: 2.252395523415707e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Trial 200: Test Accuracy = 0.4920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 20:10:09,379] Trial 200 finished with value: 0.4919556044762428 and parameters: {'hidden_size': 512, 'num_layers': 1, 'dropout': 0.4, 'learning_rate': 3.3739606069967048e-06, 'weight_decay': 6.176604076556577e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:204 hidden_size: 1024, num_layers: 2, learning_rate: 6.833826573089511e-05, optimizer_name: Adam, weight_decay: 2.1462382879043864e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Trial 202: Test Accuracy = 0.4861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 20:16:00,115] Trial 202 finished with value: 0.48610346725371495 and parameters: {'hidden_size': 1024, 'num_layers': 1, 'dropout': 0.2, 'learning_rate': 2.992271558263836e-06, 'weight_decay': 6.606537318637357e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:205 hidden_size: 1024, num_layers: 2, learning_rate: 8.152035502543871e-05, optimizer_name: Adam, weight_decay: 2.0697514975796693e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Trial 203: Test Accuracy = 0.5017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 20:26:49,356] Trial 203 finished with value: 0.5016847061701217 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 7.50010322103267e-05, 'weight_decay': 2.252395523415707e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:206 hidden_size: 1024, num_layers: 2, learning_rate: 5.7939162328302244e-05, optimizer_name: Adam, weight_decay: 2.104708992500584e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Trial 204: Test Accuracy = 0.4899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 20:31:29,230] Trial 204 finished with value: 0.48986424509264354 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 6.833826573089511e-05, 'weight_decay': 2.1462382879043864e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:207 hidden_size: 1024, num_layers: 2, learning_rate: 0.0001003897065198372, optimizer_name: Adam, weight_decay: 1.441580723345431e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 20:34:28,735] Trial 205 finished with value: 0.49916529077233535 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 8.152035502543871e-05, 'weight_decay': 2.0697514975796693e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 205: Test Accuracy = 0.4992\n",
      "trial:208 hidden_size: 256, num_layers: 3, learning_rate: 9.807603517763855e-05, optimizer_name: Adam, weight_decay: 1.654773367232489e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 14\n",
      "Trial 206: Test Accuracy = 0.4825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 20:35:27,040] Trial 206 finished with value: 0.4824986241056686 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 5.7939162328302244e-05, 'weight_decay': 2.104708992500584e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:209 hidden_size: 256, num_layers: 3, learning_rate: 9.263727730416856e-05, optimizer_name: Adam, weight_decay: 2.5520124262862423e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 20:41:31,977] Trial 208 finished with value: 0.35779673454412037 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 9.807603517763855e-05, 'weight_decay': 1.654773367232489e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 208: Test Accuracy = 0.3578\n",
      "trial:210 hidden_size: 64, num_layers: 3, learning_rate: 0.00032044841173272173, optimizer_name: Adam, weight_decay: 2.5015122700812207e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 20:43:44,302] Trial 210 finished with value: 0.5032195927352779 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 0.00032044841173272173, 'weight_decay': 2.5015122700812207e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 210: Test Accuracy = 0.5032\n",
      "trial:211 hidden_size: 256, num_layers: 4, learning_rate: 1.7293278640233006e-06, optimizer_name: Adam, weight_decay: 1.460810270930129e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 20:45:05,049] Trial 209 finished with value: 0.4388583134593041 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 9.263727730416856e-05, 'weight_decay': 2.5520124262862423e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 209: Test Accuracy = 0.4389\n",
      "trial:212 hidden_size: 1024, num_layers: 4, learning_rate: 1.692713871800412e-06, optimizer_name: Adam, weight_decay: 1.4101058062159739e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Trial 207: Test Accuracy = 0.4136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 20:45:07,336] Trial 207 finished with value: 0.41362746896593894 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 0.0001003897065198372, 'weight_decay': 1.441580723345431e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:213 hidden_size: 512, num_layers: 3, learning_rate: 5.75245299789549e-05, optimizer_name: Adam, weight_decay: 3.2421460464006265e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 20:57:32,921] Trial 212 finished with value: 0.5516724759982877 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 1.692713871800412e-06, 'weight_decay': 1.4101058062159739e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 212: Test Accuracy = 0.5517\n",
      "trial:214 hidden_size: 1024, num_layers: 4, learning_rate: 6.373029117413765e-07, optimizer_name: Adam, weight_decay: 1.8056028751597604e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 19\n",
      "Trial 213: Test Accuracy = 0.5261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 20:58:11,221] Trial 213 finished with value: 0.5260502660062374 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 5.75245299789549e-05, 'weight_decay': 3.2421460464006265e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:215 hidden_size: 512, num_layers: 4, learning_rate: 1.7985333937465142e-06, optimizer_name: Adam, weight_decay: 1.0264375335908086e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 21:02:51,779] Trial 211 finished with value: 0.47009722986607966 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 1.7293278640233006e-06, 'weight_decay': 1.460810270930129e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 211: Test Accuracy = 0.4701\n",
      "trial:216 hidden_size: 512, num_layers: 3, learning_rate: 1.4621243017376688e-06, optimizer_name: Adam, weight_decay: 3.158376305695348e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 21:14:51,926] Trial 214 finished with value: 0.46191218736623246 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 6.373029117413765e-07, 'weight_decay': 1.8056028751597604e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 214: Test Accuracy = 0.4619\n",
      "trial:217 hidden_size: 512, num_layers: 3, learning_rate: 9.260923478633913e-06, optimizer_name: Adam, weight_decay: 3.2538646848936313e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 21:16:19,350] Trial 216 finished with value: 0.4755243686173791 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 1.4621243017376688e-06, 'weight_decay': 3.158376305695348e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 216: Test Accuracy = 0.4755\n",
      "trial:218 hidden_size: 512, num_layers: 4, learning_rate: 1.0110733372253746e-05, optimizer_name: Adam, weight_decay: 3.588646268688525e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 21:16:40,941] Trial 215 finished with value: 0.49008744572861246 and parameters: {'hidden_size': 512, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 1.7985333937465142e-06, 'weight_decay': 1.0264375335908086e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 215: Test Accuracy = 0.4901\n",
      "trial:219 hidden_size: 128, num_layers: 4, learning_rate: 2.4523026444146466e-07, optimizer_name: Adam, weight_decay: 2.7353566235560403e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 21:18:55,775] Trial 219 finished with value: 0.2950070323488045 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 2.4523026444146466e-07, 'weight_decay': 2.7353566235560403e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 219: Test Accuracy = 0.2950\n",
      "trial:220 hidden_size: 512, num_layers: 3, learning_rate: 8.571576587570774e-06, optimizer_name: Adam, weight_decay: 1.317788387813373e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 21:20:26,365] Trial 218 finished with value: 0.5520485537821807 and parameters: {'hidden_size': 512, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 1.0110733372253746e-05, 'weight_decay': 3.588646268688525e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 218: Test Accuracy = 0.5520\n",
      "trial:221 hidden_size: 512, num_layers: 4, learning_rate: 8.536314966907811e-06, optimizer_name: Adam, weight_decay: 3.58785768661256e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 21:21:09,380] Trial 217 finished with value: 0.45195071240750934 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 9.260923478633913e-06, 'weight_decay': 3.2538646848936313e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 217: Test Accuracy = 0.4520\n",
      "trial:222 hidden_size: 512, num_layers: 4, learning_rate: 4.5014954282574775e-05, optimizer_name: Adam, weight_decay: 4.230433129641135e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 21:24:03,061] Trial 220 finished with value: 0.48286858680364464 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 8.571576587570774e-06, 'weight_decay': 1.317788387813373e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 220: Test Accuracy = 0.4829\n",
      "trial:223 hidden_size: 512, num_layers: 4, learning_rate: 1.006660705263168e-06, optimizer_name: Adam, weight_decay: 3.83768578681863e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 21:25:24,075] Trial 221 finished with value: 0.49010273344340494 and parameters: {'hidden_size': 512, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 8.536314966907811e-06, 'weight_decay': 3.58785768661256e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 221: Test Accuracy = 0.4901\n",
      "trial:224 hidden_size: 512, num_layers: 4, learning_rate: 1.4865451444699622e-05, optimizer_name: Adam, weight_decay: 3.986326358998434e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 21:26:19,132] Trial 222 finished with value: 0.46205283434232247 and parameters: {'hidden_size': 512, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 4.5014954282574775e-05, 'weight_decay': 4.230433129641135e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 222: Test Accuracy = 0.4621\n",
      "trial:225 hidden_size: 64, num_layers: 4, learning_rate: 2.3283143027803005e-06, optimizer_name: Adam, weight_decay: 2.741824126520373e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 21:27:57,513] Trial 225 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 2.3283143027803005e-06, 'weight_decay': 2.741824126520373e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 225: Test Accuracy = 0.3333\n",
      "trial:226 hidden_size: 32, num_layers: 4, learning_rate: 3.186005398359044e-05, optimizer_name: Adam, weight_decay: 4.752967531567123e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 21:29:45,279] Trial 226 finished with value: 0.42180028129395214 and parameters: {'hidden_size': 32, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 3.186005398359044e-05, 'weight_decay': 4.752967531567123e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 226: Test Accuracy = 0.4218\n",
      "trial:227 hidden_size: 512, num_layers: 3, learning_rate: 1.4568694653797127e-05, optimizer_name: Adam, weight_decay: 3.6447806629544687e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 21:32:26,963] Trial 224 finished with value: 0.47356142603803586 and parameters: {'hidden_size': 512, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 1.4865451444699622e-05, 'weight_decay': 3.986326358998434e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 224: Test Accuracy = 0.4736\n",
      "trial:228 hidden_size: 256, num_layers: 3, learning_rate: 4.321779371715315e-06, optimizer_name: Adam, weight_decay: 2.4761621581886523e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 21:32:35,461] Trial 223 finished with value: 0.510829817158931 and parameters: {'hidden_size': 512, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 1.006660705263168e-06, 'weight_decay': 3.83768578681863e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 223: Test Accuracy = 0.5108\n",
      "trial:229 hidden_size: 256, num_layers: 3, learning_rate: 1.1484753364805996e-05, optimizer_name: Adam, weight_decay: 2.533648067295354e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 21:34:42,484] Trial 227 finished with value: 0.5035834403473369 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 1.4568694653797127e-05, 'weight_decay': 3.6447806629544687e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 227: Test Accuracy = 0.5036\n",
      "trial:230 hidden_size: 256, num_layers: 3, learning_rate: 5.743719090613463e-05, optimizer_name: Adam, weight_decay: 3.0097825713814104e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 21:37:06,990] Trial 228 finished with value: 0.5076193970525286 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 4.321779371715315e-06, 'weight_decay': 2.4761621581886523e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 228: Test Accuracy = 0.5076\n",
      "trial:231 hidden_size: 128, num_layers: 3, learning_rate: 0.0001562529755323759, optimizer_name: Adam, weight_decay: 3.0393763180801072e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Trial 229: Test Accuracy = 0.5391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 21:37:27,057] Trial 229 finished with value: 0.5391029168959823 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 1.1484753364805996e-05, 'weight_decay': 2.533648067295354e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:232 hidden_size: 128, num_layers: 3, learning_rate: 6.701151658275359e-06, optimizer_name: Adam, weight_decay: 3.0520906831278386e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 20\n",
      "Trial 230: Test Accuracy = 0.4792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 21:37:31,263] Trial 230 finished with value: 0.47922093805417965 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 5.743719090613463e-05, 'weight_decay': 3.0097825713814104e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:233 hidden_size: 256, num_layers: 3, learning_rate: 5.993860338855451e-06, optimizer_name: Adam, weight_decay: 1.9135174388202035e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 21:38:37,944] Trial 231 finished with value: 0.41798141013881246 and parameters: {'hidden_size': 128, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 0.0001562529755323759, 'weight_decay': 3.0393763180801072e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 231: Test Accuracy = 0.4180\n",
      "trial:234 hidden_size: 256, num_layers: 3, learning_rate: 1.0765820304332054e-05, optimizer_name: Adam, weight_decay: 2.43055381705635e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 21:40:15,200] Trial 232 finished with value: 0.49263743655598363 and parameters: {'hidden_size': 128, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 6.701151658275359e-06, 'weight_decay': 3.0520906831278386e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 232: Test Accuracy = 0.4926\n",
      "trial:235 hidden_size: 256, num_layers: 3, learning_rate: 1.2109155475306842e-05, optimizer_name: Adam, weight_decay: 2.4397898852516547e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 21:41:04,163] Trial 233 finished with value: 0.5085978107992417 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 5.993860338855451e-06, 'weight_decay': 1.9135174388202035e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 233: Test Accuracy = 0.5086\n",
      "trial:236 hidden_size: 256, num_layers: 3, learning_rate: 1.0745181839224403e-05, optimizer_name: Adam, weight_decay: 2.4406895556146923e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 21:41:49,488] Trial 234 finished with value: 0.49893903259340794 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 1.0765820304332054e-05, 'weight_decay': 2.43055381705635e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 234: Test Accuracy = 0.4989\n",
      "trial:237 hidden_size: 256, num_layers: 3, learning_rate: 2.2481514353130946e-05, optimizer_name: Adam, weight_decay: 1.957209308424941e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 21:44:18,524] Trial 235 finished with value: 0.43552559163456245 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 1.2109155475306842e-05, 'weight_decay': 2.4397898852516547e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 235: Test Accuracy = 0.4355\n",
      "trial:238 hidden_size: 1024, num_layers: 3, learning_rate: 2.009122427916742e-05, optimizer_name: Adam, weight_decay: 1.5439039322763657e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 29\n",
      "Trial 236: Test Accuracy = 0.4765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 21:45:56,099] Trial 236 finished with value: 0.4765027823640922 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 1.0745181839224403e-05, 'weight_decay': 2.4406895556146923e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:239 hidden_size: 1024, num_layers: 3, learning_rate: 1.8977032846492244e-05, optimizer_name: Adam, weight_decay: 1.2046252826247672e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Trial 237: Test Accuracy = 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 21:48:46,178] Trial 237 finished with value: 0.4409374426710695 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 2.2481514353130946e-05, 'weight_decay': 1.957209308424941e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:240 hidden_size: 1024, num_layers: 4, learning_rate: 5.8467247814056156e-05, optimizer_name: Adam, weight_decay: 1.6129143039794964e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 16\n",
      "Trial 239: Test Accuracy = 0.5184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 22:08:21,455] Trial 239 finished with value: 0.518394178438207 and parameters: {'hidden_size': 1024, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 1.8977032846492244e-05, 'weight_decay': 1.2046252826247672e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:241 hidden_size: 1024, num_layers: 3, learning_rate: 6.200238861280165e-05, optimizer_name: Adam, weight_decay: 1.5979338729167546e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n",
      "Trial 238: Test Accuracy = 0.4689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 22:12:16,469] Trial 238 finished with value: 0.46885892496789583 and parameters: {'hidden_size': 1024, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 2.009122427916742e-05, 'weight_decay': 1.5439039322763657e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:242 hidden_size: 1024, num_layers: 4, learning_rate: 5.4866378293653584e-05, optimizer_name: Adam, weight_decay: 2.7188548077844423e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 20\n",
      "Trial 241: Test Accuracy = 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 23:15:24,978] Trial 241 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 1024, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 6.200238861280165e-05, 'weight_decay': 1.5979338729167546e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:243 hidden_size: 1024, num_layers: 3, learning_rate: 1.7468903241288573e-05, optimizer_name: Adam, weight_decay: 1.1921507354789756e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 23:34:03,318] Trial 240 finished with value: 0.4997248211337369 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 5.8467247814056156e-05, 'weight_decay': 1.6129143039794964e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 240: Test Accuracy = 0.4997\n",
      "trial:244 hidden_size: 1024, num_layers: 3, learning_rate: 1.6407585432856636e-05, optimizer_name: Adam, weight_decay: 1.1708869114525917e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 18\n",
      "Trial 243: Test Accuracy = 0.4793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-30 00:36:55,045] Trial 243 finished with value: 0.4793340671436434 and parameters: {'hidden_size': 1024, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 1.7468903241288573e-05, 'weight_decay': 1.1921507354789756e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:245 hidden_size: 1024, num_layers: 3, learning_rate: 4.366738227173966e-05, optimizer_name: Adam, weight_decay: 1.2605243094161151e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 14\n",
      "Trial 244: Test Accuracy = 0.4805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-30 00:37:22,419] Trial 244 finished with value: 0.4804623004953219 and parameters: {'hidden_size': 1024, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 1.6407585432856636e-05, 'weight_decay': 1.1708869114525917e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:246 hidden_size: 64, num_layers: 3, learning_rate: 3.9317566612876935e-05, optimizer_name: Adam, weight_decay: 1.354131768892963e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 22\n",
      "Trial 242: Test Accuracy = 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-30 00:40:09,213] Trial 242 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 5.4866378293653584e-05, 'weight_decay': 2.7188548077844423e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:247 hidden_size: 32, num_layers: 3, learning_rate: 0.00011163338316341673, optimizer_name: Adam, weight_decay: 1.3354622311182552e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-30 00:43:40,545] Trial 246 finished with value: 0.4742677184614444 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 3.9317566612876935e-05, 'weight_decay': 1.354131768892963e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 246: Test Accuracy = 0.4743\n",
      "trial:248 hidden_size: 32, num_layers: 3, learning_rate: 2.8348787925320316e-05, optimizer_name: Adam, weight_decay: 1.0261745975039385e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Trial 247: Test Accuracy = 0.4708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-30 00:45:46,056] Trial 247 finished with value: 0.47080963737540515 and parameters: {'hidden_size': 32, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 0.00011163338316341673, 'weight_decay': 1.3354622311182552e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:249 hidden_size: 1024, num_layers: 2, learning_rate: 0.0002466352338192184, optimizer_name: Adam, weight_decay: 1.0166727228556006e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Trial 248: Test Accuracy = 0.5032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-30 00:49:59,902] Trial 248 finished with value: 0.5031890173056932 and parameters: {'hidden_size': 32, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 2.8348787925320316e-05, 'weight_decay': 1.0261745975039385e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:250 hidden_size: 1024, num_layers: 2, learning_rate: 0.00024683356355099327, optimizer_name: Adam, weight_decay: 2.07170798833352e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Trial 245: Test Accuracy = 0.3786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-30 00:52:42,430] Trial 245 finished with value: 0.3786430624350272 and parameters: {'hidden_size': 1024, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 4.366738227173966e-05, 'weight_decay': 1.2605243094161151e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:251 hidden_size: 256, num_layers: 2, learning_rate: 8.410862518684443e-05, optimizer_name: Adam, weight_decay: 5.768643055558032e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-30 01:02:21,519] Trial 249 finished with value: 0.3790436005625879 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.0002466352338192184, 'weight_decay': 1.0166727228556006e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 249: Test Accuracy = 0.3790\n",
      "trial:252 hidden_size: 256, num_layers: 2, learning_rate: 0.0005676301126489808, optimizer_name: Adam, weight_decay: 2.1728814648684337e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-30 01:02:26,423] Trial 250 finished with value: 0.41659634317862165 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.00024683356355099327, 'weight_decay': 2.07170798833352e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 250: Test Accuracy = 0.4166\n",
      "trial:253 hidden_size: 256, num_layers: 3, learning_rate: 8.131173209093863e-05, optimizer_name: Adam, weight_decay: 5.336112732016819e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-30 01:02:28,840] Trial 251 finished with value: 0.4632177582095029 and parameters: {'hidden_size': 256, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 8.410862518684443e-05, 'weight_decay': 5.768643055558032e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 251: Test Accuracy = 0.4632\n",
      "trial:254 hidden_size: 128, num_layers: 3, learning_rate: 0.0005857752397010553, optimizer_name: Adam, weight_decay: 1.8411530213712518e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-30 01:03:36,264] Trial 254 finished with value: 0.435024154589372 and parameters: {'hidden_size': 128, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 0.0005857752397010553, 'weight_decay': 1.8411530213712518e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254: Test Accuracy = 0.4350\n",
      "trial:255 hidden_size: 256, num_layers: 3, learning_rate: 0.0001323941929771185, optimizer_name: Adam, weight_decay: 3.3132204383898123e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-30 01:05:05,657] Trial 253 finished with value: 0.4804775882101144 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 8.131173209093863e-05, 'weight_decay': 5.336112732016819e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 253: Test Accuracy = 0.4805\n",
      "trial:256 hidden_size: 64, num_layers: 4, learning_rate: 6.971459851113376e-06, optimizer_name: Adam, weight_decay: 3.3803600204967286e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-30 01:05:50,654] Trial 256 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 6.971459851113376e-06, 'weight_decay': 3.3803600204967286e-06, 'batch_size': 32}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 256: Test Accuracy = 0.3333\n",
      "trial:257 hidden_size: 512, num_layers: 2, learning_rate: 2.6627949366420717e-05, optimizer_name: Adam, weight_decay: 2.732990396664205e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-30 01:06:20,841] Trial 252 finished with value: 0.39535559224607103 and parameters: {'hidden_size': 256, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.0005676301126489808, 'weight_decay': 2.1728814648684337e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 252: Test Accuracy = 0.3954\n",
      "trial:258 hidden_size: 512, num_layers: 3, learning_rate: 0.00014258572712456057, optimizer_name: Adam, weight_decay: 2.7569167799756378e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-30 01:06:58,639] Trial 255 finished with value: 0.5308169754785054 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 0.0001323941929771185, 'weight_decay': 3.3132204383898123e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 255: Test Accuracy = 0.5308\n",
      "trial:259 hidden_size: 512, num_layers: 3, learning_rate: 0.00017037259273338756, optimizer_name: Adam, weight_decay: 2.8058020588197495e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-30 01:10:16,204] Trial 258 finished with value: 0.4159848345869259 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 0.00014258572712456057, 'weight_decay': 2.7569167799756378e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 258: Test Accuracy = 0.4160\n",
      "trial:260 hidden_size: 1024, num_layers: 2, learning_rate: 0.00017512271430853387, optimizer_name: Adam, weight_decay: 3.2070441056373306e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-30 01:11:03,045] Trial 259 finished with value: 0.47095639943741213 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.2, 'learning_rate': 0.00017037259273338756, 'weight_decay': 2.8058020588197495e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 259: Test Accuracy = 0.4710\n",
      "trial:261 hidden_size: 1024, num_layers: 2, learning_rate: 0.00011991996358015679, optimizer_name: Adam, weight_decay: 8.43469800845013e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 25\n",
      "Trial 257: Test Accuracy = 0.4740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-30 01:11:30,968] Trial 257 finished with value: 0.4740322876536416 and parameters: {'hidden_size': 512, 'num_layers': 2, 'dropout': 0.2, 'learning_rate': 2.6627949366420717e-05, 'weight_decay': 2.732990396664205e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:262 hidden_size: 1024, num_layers: 4, learning_rate: 9.938802098642603e-05, optimizer_name: Adam, weight_decay: 3.1856510250195224e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "def objective(trial):\n",
    "    # Hyperparameter suggestions\n",
    "    hidden_size = trial.suggest_categorical(\"hidden_size\", [32,64,128,256,512,1024])\n",
    "    num_layers = trial.suggest_categorical(\"num_layers\", [1, 2, 3, 4])\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5, step=0.1)\n",
    "\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-8, 1e-2, log=True)\n",
    "    optimizer_name = \"Adam\"\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [10, 16, 32])\n",
    "    label_smoothing = 0.3\n",
    "    factor = 1\n",
    "\n",
    "    print(f\"trial:{trial.number} hidden_size: {hidden_size}, num_layers: {num_layers}, learning_rate: {learning_rate}, optimizer_name: {optimizer_name}, weight_decay: {weight_decay}, batch_size: {batch_size}, label_smoothing: {label_smoothing}, factor: {factor}\")\n",
    "\n",
    "    # Run only for 1 fold (fold 0)\n",
    "    test_fold_idx = 0\n",
    "    test_fold = fold_indices[test_fold_idx]\n",
    "    remaining_folds = [fold_indices[i] for i in range(5) if i != test_fold_idx]\n",
    "    val_fold_idx = test_fold_idx % 4\n",
    "    val_fold = remaining_folds[val_fold_idx]\n",
    "    train_folds = [fold for fold in remaining_folds if fold != val_fold]\n",
    "\n",
    "    # Prepare data with correct reshaping\n",
    "    train_data = np.concatenate([eeg_folds[j] for j in train_folds])\n",
    "    train_data = train_data.reshape(train_data.shape[0], train_data.shape[1], train_data.shape[2]*train_data.shape[3])\n",
    "    train_labels = np.concatenate([labels_folds[j] for j in train_folds])\n",
    "\n",
    "    val_data = eeg_folds[val_fold]\n",
    "    val_data = val_data.reshape(val_data.shape[0], val_data.shape[1], val_data.shape[2]*val_data.shape[3])\n",
    "    val_labels = labels_folds[val_fold]\n",
    "\n",
    "    test_data = eeg_folds[test_fold]\n",
    "    test_data = test_data.reshape(test_data.shape[0], test_data.shape[1], test_data.shape[2]*test_data.shape[3])\n",
    "    test_labels = labels_folds[test_fold]\n",
    "\n",
    "    balanced_train_data, balanced_train_labels = data_balancer(train_data, train_labels, factor=factor)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_dataset = TensorDataset(torch.tensor(balanced_train_data, dtype=torch.float32),\n",
    "                                  torch.tensor(balanced_train_labels, dtype=torch.long))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=1, pin_memory=True)\n",
    "\n",
    "    val_dataset = TensorDataset(torch.tensor(val_data, dtype=torch.float32),\n",
    "                                torch.tensor(val_labels, dtype=torch.long))\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=1, pin_memory=True)\n",
    "\n",
    "    test_dataset = TensorDataset(torch.tensor(test_data, dtype=torch.float32),\n",
    "                                 torch.tensor(test_labels, dtype=torch.long))\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=1, pin_memory=True)\n",
    "\n",
    "    # Initialize model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = LstmAttention(\n",
    "        input_size=672,  # Fixed input size: 224*3\n",
    "        hidden_size=hidden_size,\n",
    "        num_layers=num_layers,\n",
    "        num_classes=num_classes,\n",
    "        dropout=dropout\n",
    "    ).to(device)  # Move model to device immediately after creation\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "    optimizer_cls = {\"Adam\": optim.Adam, \"AdamW\": optim.AdamW, \"SGD\": optim.SGD}\n",
    "    optimizer = optimizer_cls[optimizer_name](model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=10)\n",
    "\n",
    "    epochs = 30\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_labels in val_loader:\n",
    "                val_inputs, val_labels = val_inputs.to(device, non_blocking=True), val_labels.to(device, non_blocking=True)\n",
    "                val_outputs = model(val_inputs)\n",
    "                loss = criterion(val_outputs, val_labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        early_stopping(val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "    early_stopping.load_best_model(model)\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = balanced_accuracy_score(all_labels, all_preds)\n",
    "    print(f\"Trial {trial.number}: Test Accuracy = {accuracy:.4f}\")\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    trial.report(accuracy, step=0)\n",
    "\n",
    "    if trial.should_prune():\n",
    "        raise optuna.TrialPruned()\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Start Optuna Study\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=optuna.samplers.TPESampler(),\n",
    "    pruner=optuna.pruners.MedianPruner(n_warmup_steps=5)\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=300, n_jobs=3) \n",
    "\n",
    "# Best result\n",
    "print(\"Best hyperparameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb2090e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3250846a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1wsVLiiebraTQaPsj9O9sap_UyjGLTS4y",
     "timestamp": 1747774865523
    }
   ]
  },
  "kernelspec": {
   "display_name": "cudaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
