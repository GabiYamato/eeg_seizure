Input shape: torch.Size([8, 224, 672])
Output shape: torch.Size([8, 3])
c:\Users\Gabriel\anaconda3\envs\cudaenv\Lib\site-packages\tqdm\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm
[I 2025-05-29 03:25:53,478] A new study created in memory with name: no-name-898cbd83-e6f9-411c-9131-39d650cffd57
hidden_size: 512, num_layers: 3, learning_rate: 1.2982699360205788e-05, optimizer_name: Adam, weight_decay: 1.7361612479586764e-05, batch_size: 16, label_smoothing: 0.3, factor: 1hidden_size: 64, num_layers: 1, learning_rate: 3.0454236094397555e-05, optimizer_name: Adam, weight_decay: 5.306695559979247e-06, batch_size: 16, label_smoothing: 0.3, factor: 1

hidden_size: 32, num_layers: 3, learning_rate: 2.6395009335196565e-08, optimizer_name: Adam, weight_decay: 0.00021900508512168323, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
[I 2025-05-29 03:26:52,684] Trial 2 finished with value: 0.33460076045627374 and parameters: {'hidden_size': 32, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 2.6395009335196565e-08, 'weight_decay': 0.00021900508512168323, 'batch_size': 10}. Best is trial 2 with value: 0.33460076045627374.
Trial 2: Test Accuracy = 0.3346
hidden_size: 128, num_layers: 3, learning_rate: 3.01493161658156e-05, optimizer_name: Adam, weight_decay: 0.0006794050105941614, batch_size: 10, label_smoothing: 0.3, factor: 1
[I 2025-05-29 03:28:09,480] Trial 1 finished with value: 0.5349637455429233 and parameters: {'hidden_size': 64, 'num_layers': 1, 'dropout': 0.2, 'learning_rate': 3.0454236094397555e-05, 'weight_decay': 5.306695559979247e-06, 'batch_size': 16}. Best is trial 1 with value: 0.5349637455429233.
Trial 1: Test Accuracy = 0.5350
hidden_size: 512, num_layers: 1, learning_rate: 0.0004091886724592837, optimizer_name: Adam, weight_decay: 8.34655813164896e-05, batch_size: 32, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 0: Test Accuracy = 0.4496
[I 2025-05-29 03:29:05,419] Trial 0 finished with value: 0.4496181985921113 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 1.2982699360205788e-05, 'weight_decay': 1.7361612479586764e-05, 'batch_size': 16}. Best is trial 1 with value: 0.5349637455429233.
hidden_size: 64, num_layers: 2, learning_rate: 1.11181072331645e-06, optimizer_name: Adam, weight_decay: 1.0531673837181614e-05, batch_size: 32, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
[I 2025-05-29 03:29:14,156] Trial 3 finished with value: 0.4747364141755493 and parameters: {'hidden_size': 128, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 3.01493161658156e-05, 'weight_decay': 0.0006794050105941614, 'batch_size': 10}. Best is trial 1 with value: 0.5349637455429233.
Trial 3: Test Accuracy = 0.4747
hidden_size: 64, num_layers: 2, learning_rate: 0.0001198555031454689, optimizer_name: Adam, weight_decay: 5.9246202767415226e-05, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
[I 2025-05-29 03:29:49,058] Trial 4 finished with value: 0.5309370108438228 and parameters: {'hidden_size': 512, 'num_layers': 1, 'dropout': 0.2, 'learning_rate': 0.0004091886724592837, 'weight_decay': 8.34655813164896e-05, 'batch_size': 32}. Best is trial 1 with value: 0.5349637455429233.
Trial 4: Test Accuracy = 0.5309
hidden_size: 1024, num_layers: 1, learning_rate: 0.0003874665334407114, optimizer_name: Adam, weight_decay: 5.0561553975611905e-06, batch_size: 32, label_smoothing: 0.3, factor: 1
[I 2025-05-29 03:29:50,149] Trial 5 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.2, 'learning_rate': 1.11181072331645e-06, 'weight_decay': 1.0531673837181614e-05, 'batch_size': 32}. Best is trial 1 with value: 0.5349637455429233.
Trial 5: Test Accuracy = 0.3333
hidden_size: 512, num_layers: 1, learning_rate: 1.6047306777985417e-06, optimizer_name: Adam, weight_decay: 1.6488292763592139e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
[I 2025-05-29 03:31:39,231] Trial 7 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 1024, 'num_layers': 1, 'dropout': 0.4, 'learning_rate': 0.0003874665334407114, 'weight_decay': 5.0561553975611905e-06, 'batch_size': 32}. Best is trial 1 with value: 0.5349637455429233.
Trial 7: Test Accuracy = 0.3333
hidden_size: 64, num_layers: 3, learning_rate: 0.0004200816637478655, optimizer_name: Adam, weight_decay: 0.00027279858001293805, batch_size: 32, label_smoothing: 0.3, factor: 1
[I 2025-05-29 03:32:19,946] Trial 6 finished with value: 0.5070916763894815 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.0001198555031454689, 'weight_decay': 5.9246202767415226e-05, 'batch_size': 16}. Best is trial 1 with value: 0.5349637455429233.
Trial 6: Test Accuracy = 0.5071
hidden_size: 128, num_layers: 3, learning_rate: 0.0001150047360478183, optimizer_name: Adam, weight_decay: 3.2174114216202434e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
[I 2025-05-29 03:33:30,208] Trial 10 finished with value: 0.5133419674446177 and parameters: {'hidden_size': 128, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 0.0001150047360478183, 'weight_decay': 3.2174114216202434e-06, 'batch_size': 16}. Best is trial 1 with value: 0.5349637455429233.
Trial 10: Test Accuracy = 0.5133
hidden_size: 256, num_layers: 3, learning_rate: 1.3326291651143448e-07, optimizer_name: Adam, weight_decay: 0.00019951779268472566, batch_size: 10, label_smoothing: 0.3, factor: 1
[I 2025-05-29 03:33:30,586] Trial 9 finished with value: 0.48399312123962 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 0.0004200816637478655, 'weight_decay': 0.00027279858001293805, 'batch_size': 32}. Best is trial 1 with value: 0.5349637455429233.
Trial 9: Test Accuracy = 0.4840
hidden_size: 256, num_layers: 4, learning_rate: 0.008766772869008694, optimizer_name: Adam, weight_decay: 1.2556216106809985e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 03:34:02,279] Trial 8 finished with value: 0.5569924764082769 and parameters: {'hidden_size': 512, 'num_layers': 1, 'dropout': 0.30000000000000004, 'learning_rate': 1.6047306777985417e-06, 'weight_decay': 1.6488292763592139e-06, 'batch_size': 10}. Best is trial 8 with value: 0.5569924764082769.
Trial 8: Test Accuracy = 0.5570
hidden_size: 256, num_layers: 1, learning_rate: 5.431301384957763e-07, optimizer_name: Adam, weight_decay: 1.3425229188098602e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
[I 2025-05-29 03:35:04,295] Trial 12 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.1, 'learning_rate': 0.008766772869008694, 'weight_decay': 1.2556216106809985e-06, 'batch_size': 16}. Best is trial 8 with value: 0.5569924764082769.
Trial 12: Test Accuracy = 0.3333
hidden_size: 512, num_layers: 1, learning_rate: 1.096972395925297e-06, optimizer_name: Adam, weight_decay: 1.0117335791084028e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
[I 2025-05-29 03:35:42,330] Trial 13 finished with value: 0.32192648922686945 and parameters: {'hidden_size': 256, 'num_layers': 1, 'dropout': 0.1, 'learning_rate': 5.431301384957763e-07, 'weight_decay': 1.3425229188098602e-06, 'batch_size': 10}. Best is trial 8 with value: 0.5569924764082769.
Trial 13: Test Accuracy = 0.3219
hidden_size: 512, num_layers: 1, learning_rate: 1.051994445064749e-06, optimizer_name: Adam, weight_decay: 4.848862855553916e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
[I 2025-05-29 03:36:53,738] Trial 14 finished with value: 0.5154241391795246 and parameters: {'hidden_size': 512, 'num_layers': 1, 'dropout': 0.1, 'learning_rate': 1.096972395925297e-06, 'weight_decay': 1.0117335791084028e-06, 'batch_size': 10}. Best is trial 8 with value: 0.5569924764082769.
Trial 14: Test Accuracy = 0.5154
hidden_size: 32, num_layers: 1, learning_rate: 8.360670207111352e-08, optimizer_name: Adam, weight_decay: 4.762324185835687e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
[I 2025-05-29 03:38:06,368] Trial 16 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.2, 'learning_rate': 8.360670207111352e-08, 'weight_decay': 4.762324185835687e-06, 'batch_size': 10}. Best is trial 8 with value: 0.5569924764082769.
Trial 16: Test Accuracy = 0.3333
hidden_size: 1024, num_layers: 4, learning_rate: 4.564144592354786e-06, optimizer_name: Adam, weight_decay: 1.0922435054282096e-05, batch_size: 16, label_smoothing: 0.3, factor: 1
Trial 11: Test Accuracy = 0.3333
[I 2025-05-29 03:39:03,308] Trial 11 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 1.3326291651143448e-07, 'weight_decay': 0.00019951779268472566, 'batch_size': 10}. Best is trial 8 with value: 0.5569924764082769.
hidden_size: 1024, num_layers: 4, learning_rate: 3.721601369382627e-06, optimizer_name: Adam, weight_decay: 1.9407467579816976e-05, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
[I 2025-05-29 03:57:40,363] Trial 18 finished with value: 0.5317618243902316 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 3.721601369382627e-06, 'weight_decay': 1.9407467579816976e-05, 'batch_size': 16}. Best is trial 8 with value: 0.5569924764082769.
Trial 18: Test Accuracy = 0.5318
hidden_size: 64, num_layers: 1, learning_rate: 6.580875635489819e-06, optimizer_name: Adam, weight_decay: 2.283622377636686e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 03:58:06,080] Trial 15 finished with value: 0.541029439466615 and parameters: {'hidden_size': 512, 'num_layers': 1, 'dropout': 0.2, 'learning_rate': 1.051994445064749e-06, 'weight_decay': 4.848862855553916e-06, 'batch_size': 10}. Best is trial 8 with value: 0.5569924764082769.
Trial 15: Test Accuracy = 0.5410
hidden_size: 512, num_layers: 1, learning_rate: 1.1300025379785476e-08, optimizer_name: Adam, weight_decay: 2.3022880888874215e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
[I 2025-05-29 03:58:19,654] Trial 17 finished with value: 0.5271179479175975 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 4.564144592354786e-06, 'weight_decay': 1.0922435054282096e-05, 'batch_size': 16}. Best is trial 8 with value: 0.5569924764082769.
Trial 17: Test Accuracy = 0.5271
hidden_size: 512, num_layers: 1, learning_rate: 1.2840923772299628e-08, optimizer_name: Adam, weight_decay: 2.3786672454730966e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
[I 2025-05-29 03:58:54,912] Trial 19 finished with value: 0.4116788731519834 and parameters: {'hidden_size': 64, 'num_layers': 1, 'dropout': 0.2, 'learning_rate': 6.580875635489819e-06, 'weight_decay': 2.283622377636686e-06, 'batch_size': 16}. Best is trial 8 with value: 0.5569924764082769.
Trial 19: Test Accuracy = 0.4117
hidden_size: 512, num_layers: 1, learning_rate: 2.5388518329906415e-07, optimizer_name: Adam, weight_decay: 2.2218151222993157e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
[I 2025-05-29 04:02:46,674] Trial 20 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 512, 'num_layers': 1, 'dropout': 0.30000000000000004, 'learning_rate': 1.1300025379785476e-08, 'weight_decay': 2.3022880888874215e-06, 'batch_size': 10}. Best is trial 8 with value: 0.5569924764082769.
Trial 20: Test Accuracy = 0.3333
hidden_size: 512, num_layers: 1, learning_rate: 2.314377462059741e-07, optimizer_name: Adam, weight_decay: 6.890899746149838e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
[I 2025-05-29 04:02:57,027] Trial 21 finished with value: 0.3005606298789756 and parameters: {'hidden_size': 512, 'num_layers': 1, 'dropout': 0.30000000000000004, 'learning_rate': 1.2840923772299628e-08, 'weight_decay': 2.3786672454730966e-06, 'batch_size': 10}. Best is trial 8 with value: 0.5569924764082769.
Trial 21: Test Accuracy = 0.3006
hidden_size: 512, num_layers: 1, learning_rate: 2.523972703977979e-07, optimizer_name: Adam, weight_decay: 6.634346904085941e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
[I 2025-05-29 04:03:32,428] Trial 22 finished with value: 0.4763273058174527 and parameters: {'hidden_size': 512, 'num_layers': 1, 'dropout': 0.30000000000000004, 'learning_rate': 2.5388518329906415e-07, 'weight_decay': 2.2218151222993157e-06, 'batch_size': 10}. Best is trial 8 with value: 0.5569924764082769.
Trial 22: Test Accuracy = 0.4763
hidden_size: 512, num_layers: 1, learning_rate: 2.0593272003503062e-05, optimizer_name: Adam, weight_decay: 7.245254656116747e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
[I 2025-05-29 04:04:31,607] Trial 23 finished with value: 0.36539911368204564 and parameters: {'hidden_size': 512, 'num_layers': 1, 'dropout': 0.2, 'learning_rate': 2.314377462059741e-07, 'weight_decay': 6.890899746149838e-06, 'batch_size': 10}. Best is trial 8 with value: 0.5569924764082769.
Trial 23: Test Accuracy = 0.3654
hidden_size: 64, num_layers: 2, learning_rate: 2.1017249883097747e-05, optimizer_name: Adam, weight_decay: 4.0702325315389763e-05, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
[I 2025-05-29 04:06:15,264] Trial 25 finished with value: 0.5124915620231678 and parameters: {'hidden_size': 512, 'num_layers': 1, 'dropout': 0.2, 'learning_rate': 2.0593272003503062e-05, 'weight_decay': 7.245254656116747e-06, 'batch_size': 10}. Best is trial 8 with value: 0.5569924764082769.
Trial 25: Test Accuracy = 0.5125
hidden_size: 64, num_layers: 1, learning_rate: 2.4906843109274077e-06, optimizer_name: Adam, weight_decay: 2.7862354593295223e-05, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 04:06:46,312] Trial 24 finished with value: 0.47301210915228387 and parameters: {'hidden_size': 512, 'num_layers': 1, 'dropout': 0.2, 'learning_rate': 2.523972703977979e-07, 'weight_decay': 6.634346904085941e-06, 'batch_size': 10}. Best is trial 8 with value: 0.5569924764082769.
Trial 24: Test Accuracy = 0.4730
hidden_size: 64, num_layers: 2, learning_rate: 2.502350465346809e-06, optimizer_name: Adam, weight_decay: 2.3471040488311583e-05, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 04:06:59,340] Trial 26 finished with value: 0.5096374386476751 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.1, 'learning_rate': 2.1017249883097747e-05, 'weight_decay': 4.0702325315389763e-05, 'batch_size': 10}. Best is trial 8 with value: 0.5569924764082769.
Trial 26: Test Accuracy = 0.5096
hidden_size: 128, num_layers: 1, learning_rate: 1.6757063547116134e-06, optimizer_name: Adam, weight_decay: 1.8801815281310766e-05, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
[I 2025-05-29 04:07:36,506] Trial 29 finished with value: 0.32387650619721936 and parameters: {'hidden_size': 128, 'num_layers': 1, 'dropout': 0.1, 'learning_rate': 1.6757063547116134e-06, 'weight_decay': 1.8801815281310766e-05, 'batch_size': 16}. Best is trial 8 with value: 0.5569924764082769.
Trial 29: Test Accuracy = 0.3239
hidden_size: 32, num_layers: 1, learning_rate: 8.540876021779352e-05, optimizer_name: Adam, weight_decay: 3.875778935085648e-06, batch_size: 32, label_smoothing: 0.3, factor: 1
[I 2025-05-29 04:07:55,950] Trial 27 finished with value: 0.44824966258581145 and parameters: {'hidden_size': 64, 'num_layers': 1, 'dropout': 0.1, 'learning_rate': 2.4906843109274077e-06, 'weight_decay': 2.7862354593295223e-05, 'batch_size': 16}. Best is trial 8 with value: 0.5569924764082769.
Trial 27: Test Accuracy = 0.4482
hidden_size: 32, num_layers: 4, learning_rate: 5.6544897341085565e-05, optimizer_name: Adam, weight_decay: 3.842125279557313e-06, batch_size: 32, label_smoothing: 0.3, factor: 1
[I 2025-05-29 04:08:22,822] Trial 28 finished with value: 0.39902432025252893 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.1, 'learning_rate': 2.502350465346809e-06, 'weight_decay': 2.3471040488311583e-05, 'batch_size': 16}. Best is trial 8 with value: 0.5569924764082769.
Trial 28: Test Accuracy = 0.3990
hidden_size: 32, num_layers: 4, learning_rate: 6.345520921030721e-05, optimizer_name: Adam, weight_decay: 1.1057166716915071e-05, batch_size: 32, label_smoothing: 0.3, factor: 1
[I 2025-05-29 04:09:12,615] Trial 30 finished with value: 0.4747909542371125 and parameters: {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.2, 'learning_rate': 8.540876021779352e-05, 'weight_decay': 3.875778935085648e-06, 'batch_size': 32}. Best is trial 8 with value: 0.5569924764082769.
Trial 30: Test Accuracy = 0.4748
hidden_size: 1024, num_layers: 4, learning_rate: 8.627825620227349e-06, optimizer_name: Adam, weight_decay: 1.1811709148912714e-05, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 32: Test Accuracy = 0.4655
[I 2025-05-29 04:09:46,263] Trial 32 finished with value: 0.46548977604592107 and parameters: {'hidden_size': 32, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 6.345520921030721e-05, 'weight_decay': 1.1057166716915071e-05, 'batch_size': 32}. Best is trial 8 with value: 0.5569924764082769.
hidden_size: 1024, num_layers: 4, learning_rate: 5.936114192340244e-06, optimizer_name: Adam, weight_decay: 1.3675289410136962e-05, batch_size: 16, label_smoothing: 0.3, factor: 1
Trial 31: Test Accuracy = 0.4990
[I 2025-05-29 04:10:07,097] Trial 31 finished with value: 0.4990331725240595 and parameters: {'hidden_size': 32, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 5.6544897341085565e-05, 'weight_decay': 3.842125279557313e-06, 'batch_size': 32}. Best is trial 8 with value: 0.5569924764082769.
hidden_size: 1024, num_layers: 4, learning_rate: 1.0865010548196216e-05, optimizer_name: Adam, weight_decay: 1.6328755382670934e-05, batch_size: 16, label_smoothing: 0.3, factor: 1

Input shape: torch.Size([8, 224, 672])
Output shape: torch.Size([8, 3])
c:\Users\Gabriel\anaconda3\envs\cudaenv\Lib\site-packages\tqdm\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm
[I 2025-05-29 05:39:58,934] A new study created in memory with name: no-name-a5c537fa-bc33-486f-bdc9-de829981980d
trial:1 hidden_size: 128, num_layers: 2, learning_rate: 3.472801856224001e-08, optimizer_name: Adam, weight_decay: 1.5584727796911125e-05, batch_size: 10, label_smoothing: 0.3, factor: 1trial:0 hidden_size: 1024, num_layers: 2, learning_rate: 0.0003738617129305991, optimizer_name: Adam, weight_decay: 6.587898380225081e-05, batch_size: 10, label_smoothing: 0.3, factor: 1

trial:2 hidden_size: 1024, num_layers: 4, learning_rate: 3.285761397503112e-07, optimizer_name: Adam, weight_decay: 0.00024987752105093197, batch_size: 32, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
[I 2025-05-29 05:45:19,019] Trial 2 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 3.285761397503112e-07, 'weight_decay': 0.00024987752105093197, 'batch_size': 32}. Best is trial 2 with value: 0.3333333333333333.
Trial 2: Test Accuracy = 0.3333
trial:3 hidden_size: 1024, num_layers: 4, learning_rate: 1.9579226781863263e-08, optimizer_name: Adam, weight_decay: 3.416336600347603e-05, batch_size: 32, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
[I 2025-05-29 05:50:04,686] Trial 0 finished with value: 0.40927964287898244 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.1, 'learning_rate': 0.0003738617129305991, 'weight_decay': 6.587898380225081e-05, 'batch_size': 10}. Best is trial 0 with value: 0.40927964287898244.
Trial 0: Test Accuracy = 0.4093
trial:4 hidden_size: 64, num_layers: 2, learning_rate: 3.8175483234693166e-07, optimizer_name: Adam, weight_decay: 1.0887022156972955e-05, batch_size: 10, label_smoothing: 0.3, factor: 1
Trial 1: Test Accuracy = 0.3333
[I 2025-05-29 05:51:48,878] Trial 1 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.1, 'learning_rate': 3.472801856224001e-08, 'weight_decay': 1.5584727796911125e-05, 'batch_size': 10}. Best is trial 0 with value: 0.40927964287898244.
trial:5 hidden_size: 1024, num_layers: 2, learning_rate: 4.207221417695367e-08, optimizer_name: Adam, weight_decay: 0.0004216474328457339, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 4: Test Accuracy = 0.4037
[I 2025-05-29 05:55:57,235] Trial 4 finished with value: 0.40372714486638533 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 3.8175483234693166e-07, 'weight_decay': 1.0887022156972955e-05, 'batch_size': 10}. Best is trial 0 with value: 0.40927964287898244.
trial:6 hidden_size: 32, num_layers: 1, learning_rate: 0.00085265032152192, optimizer_name: Adam, weight_decay: 6.167566210766849e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 05:58:17,623] Trial 3 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 1.9579226781863263e-08, 'weight_decay': 3.416336600347603e-05, 'batch_size': 32}. Best is trial 0 with value: 0.40927964287898244.
Trial 3: Test Accuracy = 0.3333
trial:7 hidden_size: 1024, num_layers: 2, learning_rate: 1.2394785284254662e-07, optimizer_name: Adam, weight_decay: 0.00024741748397945, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 6: Test Accuracy = 0.4809
[I 2025-05-29 06:03:51,582] Trial 6 finished with value: 0.4809301045679692 and parameters: {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.30000000000000004, 'learning_rate': 0.00085265032152192, 'weight_decay': 6.167566210766849e-06, 'batch_size': 16}. Best is trial 6 with value: 0.4809301045679692.
trial:8 hidden_size: 1024, num_layers: 4, learning_rate: 6.986029542221468e-08, optimizer_name: Adam, weight_decay: 4.997006921139995e-06, batch_size: 32, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 7: Test Accuracy = 0.3990
[I 2025-05-29 06:13:37,145] Trial 7 finished with value: 0.3990215862532869 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.2, 'learning_rate': 1.2394785284254662e-07, 'weight_decay': 0.00024741748397945, 'batch_size': 10}. Best is trial 6 with value: 0.4809301045679692.
trial:9 hidden_size: 64, num_layers: 1, learning_rate: 1.009926237731831e-06, optimizer_name: Adam, weight_decay: 7.799733738474434e-06, batch_size: 32, label_smoothing: 0.3, factor: 1
[I 2025-05-29 06:20:39,360] Trial 5 finished with value: 0.4007307527670763 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.30000000000000004, 'learning_rate': 4.207221417695367e-08, 'weight_decay': 0.0004216474328457339, 'batch_size': 16}. Best is trial 6 with value: 0.4809301045679692.
Trial 5: Test Accuracy = 0.4007
trial:10 hidden_size: 1024, num_layers: 4, learning_rate: 1.4583663501469593e-07, optimizer_name: Adam, weight_decay: 0.0001426362323333932, batch_size: 32, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 8: Test Accuracy = 0.3278
[I 2025-05-29 06:41:47,704] Trial 8 finished with value: 0.3278022381214456 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 6.986029542221468e-08, 'weight_decay': 4.997006921139995e-06, 'batch_size': 32}. Best is trial 6 with value: 0.4809301045679692.
trial:11 hidden_size: 512, num_layers: 4, learning_rate: 0.004462307209495599, optimizer_name: Adam, weight_decay: 0.0007062301839314429, batch_size: 10, label_smoothing: 0.3, factor: 1
[I 2025-05-29 06:46:35,029] Trial 9 finished with value: 0.32362869198312233 and parameters: {'hidden_size': 64, 'num_layers': 1, 'dropout': 0.30000000000000004, 'learning_rate': 1.009926237731831e-06, 'weight_decay': 7.799733738474434e-06, 'batch_size': 32}. Best is trial 6 with value: 0.4809301045679692.
Trial 9: Test Accuracy = 0.3236
trial:12 hidden_size: 32, num_layers: 1, learning_rate: 0.003873984476974209, optimizer_name: Adam, weight_decay: 2.3302183831098483e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Trial 10: Test Accuracy = 0.3333
[I 2025-05-29 06:50:41,223] Trial 10 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 1.4583663501469593e-07, 'weight_decay': 0.0001426362323333932, 'batch_size': 32}. Best is trial 6 with value: 0.4809301045679692.
trial:13 hidden_size: 32, num_layers: 1, learning_rate: 0.0012970065877308161, optimizer_name: Adam, weight_decay: 2.019490523150996e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
[I 2025-05-29 06:50:55,747] Trial 11 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 512, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.004462307209495599, 'weight_decay': 0.0007062301839314429, 'batch_size': 10}. Best is trial 6 with value: 0.4809301045679692.
Trial 11: Test Accuracy = 0.3333
trial:14 hidden_size: 32, num_layers: 1, learning_rate: 0.0004699529731287266, optimizer_name: Adam, weight_decay: 1.3819577562172514e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
[I 2025-05-29 06:51:41,441] Trial 12 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.2, 'learning_rate': 0.003873984476974209, 'weight_decay': 2.3302183831098483e-06, 'batch_size': 16}. Best is trial 6 with value: 0.4809301045679692.
Trial 12: Test Accuracy = 0.3333
trial:15 hidden_size: 256, num_layers: 3, learning_rate: 0.00026634064137773846, optimizer_name: Adam, weight_decay: 5.516964468309498e-05, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
[I 2025-05-29 06:52:09,324] Trial 13 finished with value: 0.4217299578059072 and parameters: {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.1, 'learning_rate': 0.0012970065877308161, 'weight_decay': 2.019490523150996e-06, 'batch_size': 16}. Best is trial 6 with value: 0.4809301045679692.
Trial 13: Test Accuracy = 0.4217
trial:16 hidden_size: 32, num_layers: 3, learning_rate: 8.020085156839327e-05, optimizer_name: Adam, weight_decay: 1.3650806588450602e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
[I 2025-05-29 06:52:21,226] Trial 14 finished with value: 0.46744022503516175 and parameters: {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.1, 'learning_rate': 0.0004699529731287266, 'weight_decay': 1.3819577562172514e-06, 'batch_size': 16}. Best is trial 6 with value: 0.4809301045679692.
Trial 14: Test Accuracy = 0.4674
trial:17 hidden_size: 32, num_layers: 3, learning_rate: 0.00010916687552800061, optimizer_name: Adam, weight_decay: 1.0248062793558766e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 06:54:01,960] Trial 16 finished with value: 0.4757903748547667 and parameters: {'hidden_size': 32, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 8.020085156839327e-05, 'weight_decay': 1.3650806588450602e-06, 'batch_size': 16}. Best is trial 6 with value: 0.4809301045679692.
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
Trial 16: Test Accuracy = 0.4758
trial:18 hidden_size: 256, num_layers: 3, learning_rate: 3.607095794083012e-05, optimizer_name: Adam, weight_decay: 4.124751422782404e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 06:54:03,819] Trial 15 finished with value: 0.48454412034489086 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.1, 'learning_rate': 0.00026634064137773846, 'weight_decay': 5.516964468309498e-05, 'batch_size': 16}. Best is trial 15 with value: 0.48454412034489086.
Trial 15: Test Accuracy = 0.4845
trial:19 hidden_size: 256, num_layers: 3, learning_rate: 1.568336709765902e-05, optimizer_name: Adam, weight_decay: 3.7395417390441576e-05, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 06:54:16,608] Trial 17 finished with value: 0.5378584969118816 and parameters: {'hidden_size': 32, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 0.00010916687552800061, 'weight_decay': 1.0248062793558766e-06, 'batch_size': 16}. Best is trial 17 with value: 0.5378584969118816.
Trial 17: Test Accuracy = 0.5379
trial:20 hidden_size: 256, num_layers: 3, learning_rate: 1.7883876454599914e-05, optimizer_name: Adam, weight_decay: 6.357900037814713e-05, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
[I 2025-05-29 06:56:34,728] Trial 19 finished with value: 0.45010701400354675 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.2, 'learning_rate': 1.568336709765902e-05, 'weight_decay': 3.7395417390441576e-05, 'batch_size': 16}. Best is trial 17 with value: 0.5378584969118816.
Trial 19: Test Accuracy = 0.4501
trial:21 hidden_size: 256, num_layers: 3, learning_rate: 5.302242844399862e-05, optimizer_name: Adam, weight_decay: 5.615544698455969e-05, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
[I 2025-05-29 06:57:17,073] Trial 20 finished with value: 0.4541827187671987 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 1.7883876454599914e-05, 'weight_decay': 6.357900037814713e-05, 'batch_size': 16}. Best is trial 17 with value: 0.5378584969118816.
Trial 20: Test Accuracy = 0.4542
trial:22 hidden_size: 256, num_layers: 3, learning_rate: 7.681230754408694e-05, optimizer_name: Adam, weight_decay: 1.8938328712945048e-05, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 06:57:45,877] Trial 18 finished with value: 0.4811166146884364 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 3.607095794083012e-05, 'weight_decay': 4.124751422782404e-06, 'batch_size': 16}. Best is trial 17 with value: 0.5378584969118816.
Trial 18: Test Accuracy = 0.4811
trial:23 hidden_size: 256, num_layers: 3, learning_rate: 6.227130451805968e-05, optimizer_name: Adam, weight_decay: 2.7093785717647777e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
[I 2025-05-29 06:58:57,790] Trial 21 finished with value: 0.3942579343239772 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 5.302242844399862e-05, 'weight_decay': 5.615544698455969e-05, 'batch_size': 16}. Best is trial 17 with value: 0.5378584969118816.
Trial 21: Test Accuracy = 0.3943
trial:24 hidden_size: 256, num_layers: 3, learning_rate: 5.054745218630672e-06, optimizer_name: Adam, weight_decay: 3.3286303513712925e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 07:01:09,019] Trial 22 finished with value: 0.4265364153366355 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 7.681230754408694e-05, 'weight_decay': 1.8938328712945048e-05, 'batch_size': 16}. Best is trial 17 with value: 0.5378584969118816.
Trial 22: Test Accuracy = 0.4265
trial:25 hidden_size: 256, num_layers: 3, learning_rate: 3.3798466545052847e-06, optimizer_name: Adam, weight_decay: 3.787485446057986e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 28
[I 2025-05-29 07:01:35,672] Trial 23 finished with value: 0.5458906622638048 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 6.227130451805968e-05, 'weight_decay': 2.7093785717647777e-06, 'batch_size': 16}. Best is trial 23 with value: 0.5458906622638048.
Trial 23: Test Accuracy = 0.5459
trial:26 hidden_size: 512, num_layers: 3, learning_rate: 4.185647417757516e-06, optimizer_name: Adam, weight_decay: 3.3128117312032423e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 07:03:36,691] Trial 24 finished with value: 0.5072280315538433 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 5.054745218630672e-06, 'weight_decay': 3.3286303513712925e-06, 'batch_size': 16}. Best is trial 23 with value: 0.5458906622638048.
Trial 24: Test Accuracy = 0.5072
trial:27 hidden_size: 128, num_layers: 3, learning_rate: 5.921935935343441e-06, optimizer_name: Adam, weight_decay: 2.551157950085634e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 07:05:44,617] Trial 25 finished with value: 0.47578425976884975 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 3.3798466545052847e-06, 'weight_decay': 3.787485446057986e-06, 'batch_size': 16}. Best is trial 23 with value: 0.5458906622638048.
Trial 25: Test Accuracy = 0.4758
trial:28 hidden_size: 512, num_layers: 3, learning_rate: 3.985552049816404e-06, optimizer_name: Adam, weight_decay: 2.6367437697989786e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
[I 2025-05-29 07:05:55,253] Trial 26 finished with value: 0.452721213233046 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 4.185647417757516e-06, 'weight_decay': 3.3128117312032423e-06, 'batch_size': 16}. Best is trial 23 with value: 0.5458906622638048.
Trial 26: Test Accuracy = 0.4527
trial:29 hidden_size: 128, num_layers: 3, learning_rate: 6.686180467866274e-06, optimizer_name: Adam, weight_decay: 1.0940671884989653e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 07:07:14,502] Trial 27 finished with value: 0.46653213477649363 and parameters: {'hidden_size': 128, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 5.921935935343441e-06, 'weight_decay': 2.551157950085634e-06, 'batch_size': 16}. Best is trial 23 with value: 0.5458906622638048.
Trial 27: Test Accuracy = 0.4665
trial:30 hidden_size: 256, num_layers: 3, learning_rate: 0.00017081266483256867, optimizer_name: Adam, weight_decay: 1.0692160496137655e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 07:08:23,458] Trial 29 finished with value: 0.4431144132575063 and parameters: {'hidden_size': 128, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 6.686180467866274e-06, 'weight_decay': 1.0940671884989653e-06, 'batch_size': 16}. Best is trial 23 with value: 0.5458906622638048.
Trial 29: Test Accuracy = 0.4431
trial:31 hidden_size: 256, num_layers: 3, learning_rate: 0.00020183804726011523, optimizer_name: Adam, weight_decay: 1.0307741391643246e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
[I 2025-05-29 07:09:08,139] Trial 28 finished with value: 0.4504402861860209 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 3.985552049816404e-06, 'weight_decay': 2.6367437697989786e-06, 'batch_size': 16}. Best is trial 23 with value: 0.5458906622638048.
Trial 28: Test Accuracy = 0.4504
trial:32 hidden_size: 256, num_layers: 3, learning_rate: 0.00017984205285183027, optimizer_name: Adam, weight_decay: 8.19016586071977e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
[I 2025-05-29 07:09:41,044] Trial 30 finished with value: 0.4869718094539229 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 0.00017081266483256867, 'weight_decay': 1.0692160496137655e-06, 'batch_size': 16}. Best is trial 23 with value: 0.5458906622638048.
Trial 30: Test Accuracy = 0.4870
trial:33 hidden_size: 256, num_layers: 3, learning_rate: 0.00017652766204073552, optimizer_name: Adam, weight_decay: 1.0374394543844917e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
[I 2025-05-29 07:11:29,693] Trial 31 finished with value: 0.4688558674249374 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 0.00020183804726011523, 'weight_decay': 1.0307741391643246e-06, 'batch_size': 16}. Best is trial 23 with value: 0.5458906622638048.
Trial 31: Test Accuracy = 0.4689
trial:34 hidden_size: 256, num_layers: 3, learning_rate: 0.00015828163022572314, optimizer_name: Adam, weight_decay: 1.4164101746302888e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
[I 2025-05-29 07:11:44,126] Trial 32 finished with value: 0.46564850486149334 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 0.00017984205285183027, 'weight_decay': 8.19016586071977e-06, 'batch_size': 10}. Best is trial 23 with value: 0.5458906622638048.
Trial 32: Test Accuracy = 0.4656
trial:35 hidden_size: 256, num_layers: 3, learning_rate: 1.6310590776168177e-05, optimizer_name: Adam, weight_decay: 1.8190280846527862e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
[I 2025-05-29 07:11:58,256] Trial 33 finished with value: 0.4953097291016939 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 0.00017652766204073552, 'weight_decay': 1.0374394543844917e-06, 'batch_size': 16}. Best is trial 23 with value: 0.5458906622638048.
Trial 33: Test Accuracy = 0.4953
trial:36 hidden_size: 64, num_layers: 3, learning_rate: 2.034755435419094e-05, optimizer_name: Adam, weight_decay: 1.6502712188531186e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
[I 2025-05-29 07:14:35,402] Trial 35 finished with value: 0.5080291078089648 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 1.6310590776168177e-05, 'weight_decay': 1.8190280846527862e-06, 'batch_size': 16}. Best is trial 23 with value: 0.5458906622638048.
Trial 35: Test Accuracy = 0.5080
trial:37 hidden_size: 64, num_layers: 3, learning_rate: 1.2779244638936786e-06, optimizer_name: Adam, weight_decay: 1.923317509835789e-06, batch_size: 32, label_smoothing: 0.3, factor: 1
[I 2025-05-29 07:14:45,301] Trial 34 finished with value: 0.4655904115452822 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 0.00015828163022572314, 'weight_decay': 1.4164101746302888e-06, 'batch_size': 16}. Best is trial 23 with value: 0.5458906622638048.
Trial 34: Test Accuracy = 0.4656
trial:38 hidden_size: 64, num_layers: 2, learning_rate: 1.2274357307801657e-06, optimizer_name: Adam, weight_decay: 1.3796142896443128e-05, batch_size: 32, label_smoothing: 0.3, factor: 1
[I 2025-05-29 07:14:50,905] Trial 36 finished with value: 0.5221213233045925 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 2.034755435419094e-05, 'weight_decay': 1.6502712188531186e-06, 'batch_size': 16}. Best is trial 23 with value: 0.5458906622638048.
Trial 36: Test Accuracy = 0.5221
trial:39 hidden_size: 64, num_layers: 2, learning_rate: 1.5384231480925187e-06, optimizer_name: Adam, weight_decay: 1.6570803729503728e-06, batch_size: 32, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
[I 2025-05-29 07:15:26,669] Trial 39 finished with value: 0.33473980309423346 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 1.5384231480925187e-06, 'weight_decay': 1.6570803729503728e-06, 'batch_size': 32}. Best is trial 23 with value: 0.5458906622638048.
Trial 39: Test Accuracy = 0.3347
trial:40 hidden_size: 64, num_layers: 2, learning_rate: 2.3412547659517785e-05, optimizer_name: Adam, weight_decay: 1.4264299556545916e-05, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
[I 2025-05-29 07:16:02,123] Trial 37 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 1.2779244638936786e-06, 'weight_decay': 1.923317509835789e-06, 'batch_size': 32}. Best is trial 23 with value: 0.5458906622638048.
Trial 37: Test Accuracy = 0.3333
trial:41 hidden_size: 64, num_layers: 2, learning_rate: 2.7440562655956753e-05, optimizer_name: Adam, weight_decay: 1.3620703630478439e-05, batch_size: 10, label_smoothing: 0.3, factor: 1
[I 2025-05-29 07:16:20,224] Trial 38 finished with value: 0.3997584541062802 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 1.2274357307801657e-06, 'weight_decay': 1.3796142896443128e-05, 'batch_size': 32}. Best is trial 23 with value: 0.5458906622638048.
Trial 38: Test Accuracy = 0.3998
trial:42 hidden_size: 64, num_layers: 4, learning_rate: 2.6799918542826326e-05, optimizer_name: Adam, weight_decay: 5.759800224374591e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
[I 2025-05-29 07:16:56,341] Trial 40 finished with value: 0.4868831407081269 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 2.3412547659517785e-05, 'weight_decay': 1.4264299556545916e-05, 'batch_size': 16}. Best is trial 23 with value: 0.5458906622638048.
Trial 40: Test Accuracy = 0.4869
trial:43 hidden_size: 32, num_layers: 3, learning_rate: 1.0650501507903034e-05, optimizer_name: Adam, weight_decay: 2.983582333517331e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
[I 2025-05-29 07:17:18,215] Trial 41 finished with value: 0.48034611386289977 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.30000000000000004, 'learning_rate': 2.7440562655956753e-05, 'weight_decay': 1.3620703630478439e-05, 'batch_size': 10}. Best is trial 23 with value: 0.5458906622638048.
Trial 41: Test Accuracy = 0.4803
trial:44 hidden_size: 32, num_layers: 3, learning_rate: 1.3375576799517554e-05, optimizer_name: Adam, weight_decay: 5.8230806673000865e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
[I 2025-05-29 07:17:34,552] Trial 43 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 32, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 1.0650501507903034e-05, 'weight_decay': 2.983582333517331e-06, 'batch_size': 10}. Best is trial 23 with value: 0.5458906622638048.
Trial 43: Test Accuracy = 0.3333
trial:45 hidden_size: 128, num_layers: 4, learning_rate: 6.339492809821357e-05, optimizer_name: Adam, weight_decay: 5.137548693679295e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
[I 2025-05-29 07:17:40,995] Trial 42 finished with value: 0.431388736011741 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 2.6799918542826326e-05, 'weight_decay': 5.759800224374591e-06, 'batch_size': 10}. Best is trial 23 with value: 0.5458906622638048.
Trial 42: Test Accuracy = 0.4314
trial:46 hidden_size: 128, num_layers: 3, learning_rate: 4.1288283092983574e-07, optimizer_name: Adam, weight_decay: 4.872808274419282e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
[I 2025-05-29 07:18:47,636] Trial 45 finished with value: 0.5824833363908763 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 6.339492809821357e-05, 'weight_decay': 5.137548693679295e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 45: Test Accuracy = 0.5825
trial:47 hidden_size: 128, num_layers: 4, learning_rate: 0.0005657630110539962, optimizer_name: Adam, weight_decay: 4.843287212007385e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Trial 44: Test Accuracy = 0.4135
[I 2025-05-29 07:19:00,166] Trial 44 finished with value: 0.41348070690393196 and parameters: {'hidden_size': 32, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 1.3375576799517554e-05, 'weight_decay': 5.8230806673000865e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:48 hidden_size: 128, num_layers: 4, learning_rate: 0.0006047938733534723, optimizer_name: Adam, weight_decay: 1.9144133925784025e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 07:19:24,259] Trial 46 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 128, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 4.1288283092983574e-07, 'weight_decay': 4.872808274419282e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 46: Test Accuracy = 0.3333
trial:49 hidden_size: 128, num_layers: 4, learning_rate: 0.0008276524166979566, optimizer_name: Adam, weight_decay: 1.8744157750293014e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
[I 2025-05-29 07:19:30,284] Trial 47 finished with value: 0.45044640127193786 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 0.0005657630110539962, 'weight_decay': 4.843287212007385e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 47: Test Accuracy = 0.4504
trial:50 hidden_size: 128, num_layers: 4, learning_rate: 0.0016954663370852218, optimizer_name: Adam, weight_decay: 1.9647720894535625e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
[I 2025-05-29 07:20:39,741] Trial 50 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 0.0016954663370852218, 'weight_decay': 1.9647720894535625e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 50: Test Accuracy = 0.3333
trial:51 hidden_size: 1024, num_layers: 4, learning_rate: 7.04063605626784e-05, optimizer_name: Adam, weight_decay: 7.87106990870521e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Trial 48: Test Accuracy = 0.4919
[I 2025-05-29 07:20:50,248] Trial 48 finished with value: 0.49190668378890723 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 0.0006047938733534723, 'weight_decay': 1.9144133925784025e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:52 hidden_size: 1024, num_layers: 4, learning_rate: 4.798290666610629e-05, optimizer_name: Adam, weight_decay: 8.97072363522147e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 07:24:08,452] Trial 49 finished with value: 0.4524490919097414 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 0.0008276524166979566, 'weight_decay': 1.8744157750293014e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 49: Test Accuracy = 0.4524
trial:53 hidden_size: 1024, num_layers: 1, learning_rate: 7.208640457626904e-05, optimizer_name: Adam, weight_decay: 8.730184305462098e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 52: Test Accuracy = 0.4648
[I 2025-05-29 07:41:27,939] Trial 52 finished with value: 0.46479545037607783 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 4.798290666610629e-05, 'weight_decay': 8.97072363522147e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:54 hidden_size: 256, num_layers: 1, learning_rate: 1.1185302048700829e-08, optimizer_name: Adam, weight_decay: 3.334290379197963e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
Trial 53: Test Accuracy = 0.4797
[I 2025-05-29 07:43:45,291] Trial 53 finished with value: 0.47968262704090997 and parameters: {'hidden_size': 1024, 'num_layers': 1, 'dropout': 0.5, 'learning_rate': 7.208640457626904e-05, 'weight_decay': 8.730184305462098e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:55 hidden_size: 32, num_layers: 3, learning_rate: 9.520711552746442e-05, optimizer_name: Adam, weight_decay: 3.3396030994883506e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
[I 2025-05-29 07:44:07,257] Trial 51 finished with value: 0.5231241973949734 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 7.04063605626784e-05, 'weight_decay': 7.87106990870521e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 51: Test Accuracy = 0.5231
trial:56 hidden_size: 1024, num_layers: 4, learning_rate: 9.58326007464065e-05, optimizer_name: Adam, weight_decay: 1.5153541107862053e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 55: Test Accuracy = 0.4308
[I 2025-05-29 07:48:13,617] Trial 55 finished with value: 0.43081697547850545 and parameters: {'hidden_size': 32, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 9.520711552746442e-05, 'weight_decay': 3.3396030994883506e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:57 hidden_size: 1024, num_layers: 4, learning_rate: 0.00010326025254796035, optimizer_name: Adam, weight_decay: 0.00011794411982189283, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 07:55:06,602] Trial 54 finished with value: 0.3239099859353024 and parameters: {'hidden_size': 256, 'num_layers': 1, 'dropout': 0.5, 'learning_rate': 1.1185302048700829e-08, 'weight_decay': 3.334290379197963e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 54: Test Accuracy = 0.3239
trial:58 hidden_size: 1024, num_layers: 4, learning_rate: 9.481672954626657e-05, optimizer_name: Adam, weight_decay: 1.8759699337874683e-05, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 57: Test Accuracy = 0.5079
[I 2025-05-29 08:14:35,508] Trial 57 finished with value: 0.5078976334617501 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00010326025254796035, 'weight_decay': 0.00011794411982189283, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:59 hidden_size: 1024, num_layers: 4, learning_rate: 0.0003366681757210211, optimizer_name: Adam, weight_decay: 2.49460897172366e-06, batch_size: 32, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
Trial 59: Test Accuracy = 0.4806
[I 2025-05-29 10:38:24,077] Trial 59 finished with value: 0.48057848712774415 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.0003366681757210211, 'weight_decay': 2.49460897172366e-06, 'batch_size': 32}. Best is trial 45 with value: 0.5824833363908763.
trial:60 hidden_size: 512, num_layers: 4, learning_rate: 3.9274539963314394e-05, optimizer_name: Adam, weight_decay: 2.924202286455527e-05, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
Trial 56: Test Accuracy = 0.4744
[I 2025-05-29 10:38:46,892] Trial 56 finished with value: 0.47442059560936833 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 9.58326007464065e-05, 'weight_decay': 1.5153541107862053e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:61 hidden_size: 32, num_layers: 4, learning_rate: 4.4345906301302604e-05, optimizer_name: Adam, weight_decay: 2.0489011837121367e-05, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 29
Trial 58: Test Accuracy = 0.4850
[I 2025-05-29 10:45:25,275] Trial 58 finished with value: 0.48497523390203634 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 9.481672954626657e-05, 'weight_decay': 1.8759699337874683e-05, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:62 hidden_size: 512, num_layers: 4, learning_rate: 4.1941047087544825e-05, optimizer_name: Adam, weight_decay: 2.4820025435979283e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Trial 61: Test Accuracy = 0.4801
[I 2025-05-29 10:47:03,677] Trial 61 finished with value: 0.4801443160276402 and parameters: {'hidden_size': 32, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 4.4345906301302604e-05, 'weight_decay': 2.0489011837121367e-05, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:63 hidden_size: 1024, num_layers: 4, learning_rate: 3.280601586302327e-05, optimizer_name: Adam, weight_decay: 0.00011119455121110105, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
Trial 60: Test Accuracy = 0.5062
[I 2025-05-29 10:48:47,896] Trial 60 finished with value: 0.5061670641472512 and parameters: {'hidden_size': 512, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 3.9274539963314394e-05, 'weight_decay': 2.924202286455527e-05, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:64 hidden_size: 1024, num_layers: 4, learning_rate: 8.840177932301243e-06, optimizer_name: Adam, weight_decay: 0.00019600430610629675, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
[I 2025-05-29 11:04:57,706] Trial 62 finished with value: 0.5045251635785483 and parameters: {'hidden_size': 512, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 4.1941047087544825e-05, 'weight_decay': 2.4820025435979283e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 62: Test Accuracy = 0.5045
trial:65 hidden_size: 1024, num_layers: 4, learning_rate: 1.0404291497878331e-05, optimizer_name: Adam, weight_decay: 7.982886252692402e-05, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
Trial 64: Test Accuracy = 0.5021
[I 2025-05-29 12:59:25,509] Trial 64 finished with value: 0.5021311074420596 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 8.840177932301243e-06, 'weight_decay': 0.00019600430610629675, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:66 hidden_size: 1024, num_layers: 4, learning_rate: 0.000281932087618352, optimizer_name: Adam, weight_decay: 8.81097986750354e-05, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Trial 65: Test Accuracy = 0.4252
[I 2025-05-29 13:16:54,469] Trial 65 finished with value: 0.4252400171222406 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 1.0404291497878331e-05, 'weight_decay': 7.982886252692402e-05, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:67 hidden_size: 1024, num_layers: 3, learning_rate: 2.5439009253783245e-06, optimizer_name: Adam, weight_decay: 0.0001281404466450345, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 63: Test Accuracy = 0.5033
[I 2025-05-29 14:26:53,231] Trial 63 finished with value: 0.5032868586803645 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 3.280601586302327e-05, 'weight_decay': 0.00011119455121110105, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:68 hidden_size: 32, num_layers: 3, learning_rate: 1.6993552106436047e-05, optimizer_name: Adam, weight_decay: 0.0009144508362710398, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 66: Test Accuracy = 0.4704
[I 2025-05-29 15:03:00,270] Trial 66 finished with value: 0.47035100593163337 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.1, 'learning_rate': 0.000281932087618352, 'weight_decay': 8.81097986750354e-05, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:69 hidden_size: 32, num_layers: 3, learning_rate: 1.9376368737861753e-05, optimizer_name: Adam, weight_decay: 0.0005043575879504142, batch_size: 16, label_smoothing: 0.3, factor: 1
Trial 68: Test Accuracy = 0.3333
[I 2025-05-29 15:05:00,911] Trial 68 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 32, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 1.6993552106436047e-05, 'weight_decay': 0.0009144508362710398, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:70 hidden_size: 64, num_layers: 3, learning_rate: 0.009189740718549949, optimizer_name: Adam, weight_decay: 1.3666849932439686e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 15:06:29,356] Trial 67 finished with value: 0.44688130618235195 and parameters: {'hidden_size': 1024, 'num_layers': 3, 'dropout': 0.1, 'learning_rate': 2.5439009253783245e-06, 'weight_decay': 0.0001281404466450345, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 67: Test Accuracy = 0.4469
trial:71 hidden_size: 64, num_layers: 1, learning_rate: 0.00012851230408672475, optimizer_name: Adam, weight_decay: 0.0003720466928370262, batch_size: 10, label_smoothing: 0.3, factor: 1
[I 2025-05-29 15:07:00,750] Trial 69 finished with value: 0.38816425120772946 and parameters: {'hidden_size': 32, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 1.9376368737861753e-05, 'weight_decay': 0.0005043575879504142, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 69: Test Accuracy = 0.3882
trial:72 hidden_size: 256, num_layers: 1, learning_rate: 0.00890098443272906, optimizer_name: Adam, weight_decay: 1.2257784718629584e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
[I 2025-05-29 15:07:30,459] Trial 71 finished with value: 0.4825628325077968 and parameters: {'hidden_size': 64, 'num_layers': 1, 'dropout': 0.4, 'learning_rate': 0.00012851230408672475, 'weight_decay': 0.0003720466928370262, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
Trial 71: Test Accuracy = 0.4826
trial:73 hidden_size: 256, num_layers: 3, learning_rate: 7.063001591583166e-05, optimizer_name: Adam, weight_decay: 1.2815339842145125e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 28
[I 2025-05-29 15:07:46,653] Trial 70 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.1, 'learning_rate': 0.009189740718549949, 'weight_decay': 1.3666849932439686e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 70: Test Accuracy = 0.3333
trial:74 hidden_size: 256, num_layers: 3, learning_rate: 5.8910803901583556e-05, optimizer_name: Adam, weight_decay: 3.974836234524744e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
[I 2025-05-29 15:07:59,427] Trial 72 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 256, 'num_layers': 1, 'dropout': 0.4, 'learning_rate': 0.00890098443272906, 'weight_decay': 1.2257784718629584e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
Trial 72: Test Accuracy = 0.3333
trial:75 hidden_size: 256, num_layers: 3, learning_rate: 5.6951345794289284e-05, optimizer_name: Adam, weight_decay: 3.845574121240023e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
[I 2025-05-29 15:10:23,995] Trial 74 finished with value: 0.4654436494832752 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 5.8910803901583556e-05, 'weight_decay': 3.974836234524744e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 74: Test Accuracy = 0.4654
trial:76 hidden_size: 256, num_layers: 3, learning_rate: 5.234073777759766e-06, optimizer_name: Adam, weight_decay: 6.620510757950101e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 15:10:25,570] Trial 75 finished with value: 0.4396746774292179 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 5.6951345794289284e-05, 'weight_decay': 3.845574121240023e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 75: Test Accuracy = 0.4397
trial:77 hidden_size: 256, num_layers: 3, learning_rate: 2.3155714047189033e-05, optimizer_name: Adam, weight_decay: 6.341681566355062e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 15:11:25,437] Trial 73 finished with value: 0.48408854644407756 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 7.063001591583166e-05, 'weight_decay': 1.2815339842145125e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 73: Test Accuracy = 0.4841
trial:78 hidden_size: 256, num_layers: 3, learning_rate: 2.4276215534451476e-06, optimizer_name: Adam, weight_decay: 4.544667264030401e-05, batch_size: 32, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
[I 2025-05-29 15:12:28,936] Trial 77 finished with value: 0.4994893903259341 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 2.3155714047189033e-05, 'weight_decay': 6.341681566355062e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 77: Test Accuracy = 0.4995
trial:79 hidden_size: 128, num_layers: 3, learning_rate: 7.374660646513799e-06, optimizer_name: Adam, weight_decay: 7.156417678461185e-06, batch_size: 32, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
[I 2025-05-29 15:13:37,908] Trial 78 finished with value: 0.46750137589433133 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 2.4276215534451476e-06, 'weight_decay': 4.544667264030401e-05, 'batch_size': 32}. Best is trial 45 with value: 0.5824833363908763.
Trial 78: Test Accuracy = 0.4675
trial:80 hidden_size: 128, num_layers: 2, learning_rate: 6.2557038395132335e-06, optimizer_name: Adam, weight_decay: 6.885577993030594e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 15:14:19,360] Trial 76 finished with value: 0.5403687396807926 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 5.234073777759766e-06, 'weight_decay': 6.620510757950101e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 76: Test Accuracy = 0.5404
trial:81 hidden_size: 128, num_layers: 2, learning_rate: 0.0001308759406932796, optimizer_name: Adam, weight_decay: 1.6234398844611214e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 15:14:30,933] Trial 79 finished with value: 0.48794410811471894 and parameters: {'hidden_size': 128, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 7.374660646513799e-06, 'weight_decay': 7.156417678461185e-06, 'batch_size': 32}. Best is trial 45 with value: 0.5824833363908763.
Trial 79: Test Accuracy = 0.4879
trial:82 hidden_size: 256, num_layers: 2, learning_rate: 0.00011493240963402832, optimizer_name: Adam, weight_decay: 1.1237332855938683e-05, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
[I 2025-05-29 15:15:24,155] Trial 81 finished with value: 0.4700177337491591 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.30000000000000004, 'learning_rate': 0.0001308759406932796, 'weight_decay': 1.6234398844611214e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 81: Test Accuracy = 0.4700
trial:83 hidden_size: 256, num_layers: 3, learning_rate: 7.103927428191886e-07, optimizer_name: Adam, weight_decay: 2.8952017676710424e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 15:15:40,984] Trial 80 finished with value: 0.4340029352412402 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.30000000000000004, 'learning_rate': 6.2557038395132335e-06, 'weight_decay': 6.885577993030594e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 80: Test Accuracy = 0.4340
trial:84 hidden_size: 256, num_layers: 3, learning_rate: 3.257150893931696e-06, optimizer_name: Adam, weight_decay: 1.1497900091801026e-05, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
[I 2025-05-29 15:16:47,078] Trial 82 finished with value: 0.43499052161682866 and parameters: {'hidden_size': 256, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 0.00011493240963402832, 'weight_decay': 1.1237332855938683e-05, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 82: Test Accuracy = 0.4350
trial:85 hidden_size: 256, num_layers: 3, learning_rate: 1.2276902963740052e-05, optimizer_name: Adam, weight_decay: 4.624659422490529e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
[I 2025-05-29 15:19:36,312] Trial 85 finished with value: 0.46217819360362006 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 1.2276902963740052e-05, 'weight_decay': 4.624659422490529e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 85: Test Accuracy = 0.4622
trial:86 hidden_size: 256, num_layers: 3, learning_rate: 4.408246535191593e-06, optimizer_name: Adam, weight_decay: 2.104918597460127e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 15:20:02,236] Trial 83 finished with value: 0.35295358649789027 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 7.103927428191886e-07, 'weight_decay': 2.8952017676710424e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 83: Test Accuracy = 0.3530
trial:87 hidden_size: 256, num_layers: 3, learning_rate: 4.664435078335767e-06, optimizer_name: Adam, weight_decay: 2.156271758485406e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 15:20:10,870] Trial 84 finished with value: 0.4716168287164435 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 3.257150893931696e-06, 'weight_decay': 1.1497900091801026e-05, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 84: Test Accuracy = 0.4716
trial:88 hidden_size: 64, num_layers: 3, learning_rate: 1.5588279386303904e-05, optimizer_name: Adam, weight_decay: 2.2152816197658966e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
[I 2025-05-29 15:21:16,947] Trial 88 finished with value: 0.42215189873417724 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 1.5588279386303904e-05, 'weight_decay': 2.2152816197658966e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 88: Test Accuracy = 0.4222
trial:89 hidden_size: 256, num_layers: 3, learning_rate: 0.00024391829210004246, optimizer_name: Adam, weight_decay: 3.017968960532364e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 15:24:12,109] Trial 86 finished with value: 0.531031003485599 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 4.408246535191593e-06, 'weight_decay': 2.104918597460127e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 86: Test Accuracy = 0.5310
trial:90 hidden_size: 256, num_layers: 3, learning_rate: 2.9506615891840144e-05, optimizer_name: Adam, weight_decay: 1.8104354599273158e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
[I 2025-05-29 15:24:16,233] Trial 89 finished with value: 0.4531492692472329 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 0.00024391829210004246, 'weight_decay': 3.017968960532364e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 89: Test Accuracy = 0.4531
trial:91 hidden_size: 512, num_layers: 3, learning_rate: 3.1903158862626636e-05, optimizer_name: Adam, weight_decay: 1.7479872249027043e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 15:24:48,600] Trial 87 finished with value: 0.533247722130496 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 4.664435078335767e-06, 'weight_decay': 2.156271758485406e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 87: Test Accuracy = 0.5332
trial:92 hidden_size: 256, num_layers: 3, learning_rate: 1.9393412175186558e-06, optimizer_name: Adam, weight_decay: 1.7741846034998748e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
[I 2025-05-29 15:27:27,548] Trial 90 finished with value: 0.5079312664342934 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 2.9506615891840144e-05, 'weight_decay': 1.8104354599273158e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 90: Test Accuracy = 0.5079
trial:93 hidden_size: 256, num_layers: 3, learning_rate: 4.745260368772041e-06, optimizer_name: Adam, weight_decay: 1.768330759660113e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
[I 2025-05-29 15:27:42,613] Trial 91 finished with value: 0.47421268268819183 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 3.1903158862626636e-05, 'weight_decay': 1.7479872249027043e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 91: Test Accuracy = 0.4742
trial:94 hidden_size: 256, num_layers: 3, learning_rate: 4.60815416061837e-06, optimizer_name: Adam, weight_decay: 2.3051504770351466e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 15:30:11,751] Trial 92 finished with value: 0.4505717605332355 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 1.9393412175186558e-06, 'weight_decay': 1.7741846034998748e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 92: Test Accuracy = 0.4506
trial:95 hidden_size: 256, num_layers: 3, learning_rate: 7.971367640131373e-06, optimizer_name: Adam, weight_decay: 2.2197209468503305e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 15:32:12,478] Trial 93 finished with value: 0.485082247905583 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 4.745260368772041e-06, 'weight_decay': 1.768330759660113e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 93: Test Accuracy = 0.4851
trial:96 hidden_size: 256, num_layers: 3, learning_rate: 8.244669015066603e-06, optimizer_name: Adam, weight_decay: 2.2248441901676865e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 15:32:25,098] Trial 94 finished with value: 0.49586008683422006 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 4.60815416061837e-06, 'weight_decay': 2.3051504770351466e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 94: Test Accuracy = 0.4959
trial:97 hidden_size: 256, num_layers: 3, learning_rate: 8.21363225600508e-06, optimizer_name: Adam, weight_decay: 1.1675684008559463e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 15:35:26,916] Trial 95 finished with value: 0.4825230844493365 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 7.971367640131373e-06, 'weight_decay': 2.2197209468503305e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 95: Test Accuracy = 0.4825
trial:98 hidden_size: 256, num_layers: 3, learning_rate: 2.1717405392546046e-05, optimizer_name: Adam, weight_decay: 1.208264692507042e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
[I 2025-05-29 15:36:22,120] Trial 96 finished with value: 0.44198923744878615 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 8.244669015066603e-06, 'weight_decay': 2.2248441901676865e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 96: Test Accuracy = 0.4420
trial:99 hidden_size: 256, num_layers: 3, learning_rate: 2.752744146570901e-05, optimizer_name: Adam, weight_decay: 1.4613543129961264e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 15:37:06,448] Trial 97 finished with value: 0.4824099553598728 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 8.21363225600508e-06, 'weight_decay': 1.1675684008559463e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 97: Test Accuracy = 0.4824
trial:100 hidden_size: 32, num_layers: 3, learning_rate: 2.742528385580587e-05, optimizer_name: Adam, weight_decay: 1.5444495309136558e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
[I 2025-05-29 15:38:37,616] Trial 98 finished with value: 0.5175625267535009 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 2.1717405392546046e-05, 'weight_decay': 1.208264692507042e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 98: Test Accuracy = 0.5176
trial:101 hidden_size: 32, num_layers: 3, learning_rate: 2.0933992863424964e-05, optimizer_name: Adam, weight_decay: 1.4508466056976126e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
[I 2025-05-29 15:39:52,034] Trial 100 finished with value: 0.3598728062129273 and parameters: {'hidden_size': 32, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 2.742528385580587e-05, 'weight_decay': 1.5444495309136558e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 100: Test Accuracy = 0.3599
trial:102 hidden_size: 256, num_layers: 3, learning_rate: 7.881222139125556e-07, optimizer_name: Adam, weight_decay: 2.795879091527542e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
[I 2025-05-29 15:40:16,491] Trial 101 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 32, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 2.0933992863424964e-05, 'weight_decay': 1.4508466056976126e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
Trial 101: Test Accuracy = 0.3333
trial:103 hidden_size: 256, num_layers: 3, learning_rate: 1.2768957429892368e-05, optimizer_name: Adam, weight_decay: 1.1164754595028456e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 15:40:26,415] Trial 99 finished with value: 0.4593193909374427 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 2.752744146570901e-05, 'weight_decay': 1.4613543129961264e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 99: Test Accuracy = 0.4593
trial:104 hidden_size: 256, num_layers: 3, learning_rate: 1.3389575682725228e-05, optimizer_name: Adam, weight_decay: 1.0378795601446366e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
[I 2025-05-29 15:44:42,544] Trial 104 finished with value: 0.4741912798874824 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 1.3389575682725228e-05, 'weight_decay': 1.0378795601446366e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 104: Test Accuracy = 0.4742
trial:105 hidden_size: 256, num_layers: 3, learning_rate: 6.0072933271553846e-05, optimizer_name: Adam, weight_decay: 2.9063467566625714e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
[I 2025-05-29 15:45:57,851] Trial 103 finished with value: 0.46609184859047265 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 1.2768957429892368e-05, 'weight_decay': 1.1164754595028456e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 103: Test Accuracy = 0.4661
trial:106 hidden_size: 256, num_layers: 3, learning_rate: 6.499908867178303e-05, optimizer_name: Adam, weight_decay: 2.806541668616492e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 15:46:24,732] Trial 102 finished with value: 0.38658350149819604 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 7.881222139125556e-07, 'weight_decay': 2.795879091527542e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
Trial 102: Test Accuracy = 0.3866
trial:107 hidden_size: 64, num_layers: 3, learning_rate: 3.2802340622997205e-06, optimizer_name: Adam, weight_decay: 5.1417113122842725e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
[I 2025-05-29 15:47:37,619] Trial 105 finished with value: 0.44372286430624347 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 6.0072933271553846e-05, 'weight_decay': 2.9063467566625714e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 105: Test Accuracy = 0.4437
trial:108 hidden_size: 64, num_layers: 3, learning_rate: 4.820055092464264e-05, optimizer_name: Adam, weight_decay: 3.4733168101129252e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 15:48:47,293] Trial 107 finished with value: 0.33888888888888885 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 3.2802340622997205e-06, 'weight_decay': 5.1417113122842725e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 107: Test Accuracy = 0.3389
trial:109 hidden_size: 256, num_layers: 3, learning_rate: 5.66628109352953e-06, optimizer_name: Adam, weight_decay: 2.064351381301615e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
[I 2025-05-29 15:49:09,270] Trial 106 finished with value: 0.5214975845410629 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 6.499908867178303e-05, 'weight_decay': 2.806541668616492e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 106: Test Accuracy = 0.5215
trial:110 hidden_size: 256, num_layers: 1, learning_rate: 4.058900067123065e-05, optimizer_name: Adam, weight_decay: 4.420781362187665e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
[I 2025-05-29 15:49:18,060] Trial 108 finished with value: 0.5443863511282334 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 4.820055092464264e-05, 'weight_decay': 3.4733168101129252e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 108: Test Accuracy = 0.5444
trial:111 hidden_size: 64, num_layers: 1, learning_rate: 7.826399191973147e-05, optimizer_name: Adam, weight_decay: 4.1392764289853746e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
[I 2025-05-29 15:51:17,547] Trial 111 finished with value: 0.4631841252369595 and parameters: {'hidden_size': 64, 'num_layers': 1, 'dropout': 0.4, 'learning_rate': 7.826399191973147e-05, 'weight_decay': 4.1392764289853746e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 111: Test Accuracy = 0.4632
trial:112 hidden_size: 64, num_layers: 3, learning_rate: 4.0485635874918275e-05, optimizer_name: Adam, weight_decay: 3.3784196725527723e-06, batch_size: 32, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
[I 2025-05-29 15:52:10,407] Trial 110 finished with value: 0.5073381031003485 and parameters: {'hidden_size': 256, 'num_layers': 1, 'dropout': 0.4, 'learning_rate': 4.058900067123065e-05, 'weight_decay': 4.420781362187665e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 110: Test Accuracy = 0.5073
trial:113 hidden_size: 64, num_layers: 3, learning_rate: 0.00014420665633715622, optimizer_name: Adam, weight_decay: 9.245135601340798e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 15:52:31,537] Trial 109 finished with value: 0.47257383966244726 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 5.66628109352953e-06, 'weight_decay': 2.064351381301615e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 109: Test Accuracy = 0.4726
trial:114 hidden_size: 64, num_layers: 3, learning_rate: 5.91513461223835e-05, optimizer_name: Adam, weight_decay: 3.442552390986921e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 15:53:05,530] Trial 112 finished with value: 0.45952730385861923 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 4.0485635874918275e-05, 'weight_decay': 3.3784196725527723e-06, 'batch_size': 32}. Best is trial 45 with value: 0.5824833363908763.
Trial 112: Test Accuracy = 0.4595
trial:115 hidden_size: 64, num_layers: 3, learning_rate: 0.00021467400198071256, optimizer_name: Adam, weight_decay: 5.397331709804964e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
[I 2025-05-29 15:53:31,141] Trial 113 finished with value: 0.4953922827615728 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 0.00014420665633715622, 'weight_decay': 9.245135601340798e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 113: Test Accuracy = 0.4954
trial:116 hidden_size: 64, num_layers: 3, learning_rate: 0.00021004928343650492, optimizer_name: Adam, weight_decay: 5.471536335884914e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 114: Test Accuracy = 0.4825
[I 2025-05-29 15:53:45,950] Trial 114 finished with value: 0.48251391182046105 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 5.91513461223835e-05, 'weight_decay': 3.442552390986921e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:117 hidden_size: 128, num_layers: 3, learning_rate: 0.0002006842619354549, optimizer_name: Adam, weight_decay: 5.567831791654155e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
[I 2025-05-29 15:54:36,896] Trial 116 finished with value: 0.4738396624472574 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 0.00021004928343650492, 'weight_decay': 5.471536335884914e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 116: Test Accuracy = 0.4738
trial:118 hidden_size: 128, num_layers: 4, learning_rate: 1.7612922557856576e-05, optimizer_name: Adam, weight_decay: 2.6275372345091473e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 15:54:47,000] Trial 115 finished with value: 0.4232770745428973 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 0.00021467400198071256, 'weight_decay': 5.397331709804964e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 115: Test Accuracy = 0.4233
trial:119 hidden_size: 32, num_layers: 4, learning_rate: 1.9359498476930684e-05, optimizer_name: Adam, weight_decay: 2.4926040537397336e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
[I 2025-05-29 15:55:05,403] Trial 117 finished with value: 0.4515104262214884 and parameters: {'hidden_size': 128, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 0.0002006842619354549, 'weight_decay': 5.567831791654155e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 117: Test Accuracy = 0.4515
trial:120 hidden_size: 512, num_layers: 4, learning_rate: 1.874592565360945e-05, optimizer_name: Adam, weight_decay: 2.569842161293558e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 15:57:06,126] Trial 119 finished with value: 0.47956338286552924 and parameters: {'hidden_size': 32, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 1.9359498476930684e-05, 'weight_decay': 2.4926040537397336e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 119: Test Accuracy = 0.4796
trial:121 hidden_size: 512, num_layers: 3, learning_rate: 8.109426548452025e-05, optimizer_name: Adam, weight_decay: 1.2603229907962955e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 15:57:29,043] Trial 118 finished with value: 0.4799792087078823 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 1.7612922557856576e-05, 'weight_decay': 2.6275372345091473e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 118: Test Accuracy = 0.4800
trial:122 hidden_size: 512, num_layers: 3, learning_rate: 8.923025070071365e-05, optimizer_name: Adam, weight_decay: 1.3565665563343416e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
[I 2025-05-29 16:00:05,739] Trial 120 finished with value: 0.4547116736990155 and parameters: {'hidden_size': 512, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 1.874592565360945e-05, 'weight_decay': 2.569842161293558e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 120: Test Accuracy = 0.4547
trial:123 hidden_size: 256, num_layers: 3, learning_rate: 8.581141398283648e-05, optimizer_name: Adam, weight_decay: 1.2598036885033525e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
[I 2025-05-29 16:01:57,379] Trial 122 finished with value: 0.530960679997554 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 8.923025070071365e-05, 'weight_decay': 1.3565665563343416e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 122: Test Accuracy = 0.5310
trial:124 hidden_size: 512, num_layers: 3, learning_rate: 8.451157244932836e-05, optimizer_name: Adam, weight_decay: 1.3201779996114307e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
[I 2025-05-29 16:02:36,988] Trial 123 finished with value: 0.4991989237448786 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 8.581141398283648e-05, 'weight_decay': 1.2598036885033525e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 123: Test Accuracy = 0.4992
trial:125 hidden_size: 512, num_layers: 3, learning_rate: 4.747633239917501e-05, optimizer_name: Adam, weight_decay: 1.9950499748192297e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 28
[I 2025-05-29 16:03:13,308] Trial 121 finished with value: 0.4420503883079558 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 8.109426548452025e-05, 'weight_decay': 1.2603229907962955e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 121: Test Accuracy = 0.4421
trial:126 hidden_size: 256, num_layers: 3, learning_rate: 0.00011371114204562336, optimizer_name: Adam, weight_decay: 2.0110648331978613e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
[I 2025-05-29 16:06:43,708] Trial 125 finished with value: 0.45452822112150676 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 4.747633239917501e-05, 'weight_decay': 1.9950499748192297e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 125: Test Accuracy = 0.4545
trial:127 hidden_size: 512, num_layers: 3, learning_rate: 0.00010792058260509826, optimizer_name: Adam, weight_decay: 1.6048707722451486e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
[I 2025-05-29 16:08:22,761] Trial 126 finished with value: 0.4632850241545894 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 0.00011371114204562336, 'weight_decay': 2.0110648331978613e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 126: Test Accuracy = 0.4633
trial:128 hidden_size: 512, num_layers: 3, learning_rate: 1.0944169860638288e-05, optimizer_name: Adam, weight_decay: 1.0012630032254276e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 16:08:29,124] Trial 124 finished with value: 0.46552314560019575 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 8.451157244932836e-05, 'weight_decay': 1.3201779996114307e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 124: Test Accuracy = 0.4655
trial:129 hidden_size: 512, num_layers: 3, learning_rate: 0.0004289938347942635, optimizer_name: Adam, weight_decay: 1.6924366034544753e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
[I 2025-05-29 16:12:34,716] Trial 129 finished with value: 0.445731670029964 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 0.0004289938347942635, 'weight_decay': 1.6924366034544753e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 129: Test Accuracy = 0.4457
trial:130 hidden_size: 256, num_layers: 3, learning_rate: 5.271990201055737e-05, optimizer_name: Adam, weight_decay: 3.5241406012117257e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 16:12:52,981] Trial 127 finished with value: 0.48009233779734606 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 0.00010792058260509826, 'weight_decay': 1.6048707722451486e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 127: Test Accuracy = 0.4801
trial:131 hidden_size: 256, num_layers: 3, learning_rate: 3.624451081806662e-05, optimizer_name: Adam, weight_decay: 3.14673639615622e-06, batch_size: 32, label_smoothing: 0.3, factor: 1
[I 2025-05-29 16:14:19,486] Trial 128 finished with value: 0.44204733076499725 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 1.0944169860638288e-05, 'weight_decay': 1.0012630032254276e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 128: Test Accuracy = 0.4420
trial:132 hidden_size: 256, num_layers: 3, learning_rate: 3.713169677623988e-05, optimizer_name: Adam, weight_decay: 6.586304849828502e-06, batch_size: 32, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
[I 2025-05-29 16:15:03,638] Trial 130 finished with value: 0.4993640310646365 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 5.271990201055737e-05, 'weight_decay': 3.5241406012117257e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 130: Test Accuracy = 0.4994
trial:133 hidden_size: 256, num_layers: 3, learning_rate: 3.2596516038082136e-05, optimizer_name: Adam, weight_decay: 1.8683328391843971e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
[I 2025-05-29 16:15:06,798] Trial 131 finished with value: 0.44113618296337065 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 3.624451081806662e-05, 'weight_decay': 3.14673639615622e-06, 'batch_size': 32}. Best is trial 45 with value: 0.5824833363908763.
Trial 131: Test Accuracy = 0.4411
trial:134 hidden_size: 256, num_layers: 3, learning_rate: 2.999330257145665e-05, optimizer_name: Adam, weight_decay: 1.4920393231688057e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 16:17:34,071] Trial 132 finished with value: 0.4364826025805663 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 3.713169677623988e-05, 'weight_decay': 6.586304849828502e-06, 'batch_size': 32}. Best is trial 45 with value: 0.5824833363908763.
Trial 132: Test Accuracy = 0.4365
trial:135 hidden_size: 256, num_layers: 3, learning_rate: 2.3891862909422718e-05, optimizer_name: Adam, weight_decay: 1.489913914978627e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
[I 2025-05-29 16:18:55,557] Trial 133 finished with value: 0.4709197089219104 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 3.2596516038082136e-05, 'weight_decay': 1.8683328391843971e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 133: Test Accuracy = 0.4709
trial:136 hidden_size: 256, num_layers: 3, learning_rate: 2.3393696146956654e-05, optimizer_name: Adam, weight_decay: 1.4559725335993145e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
[I 2025-05-29 16:19:07,432] Trial 134 finished with value: 0.4672047942273589 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 2.999330257145665e-05, 'weight_decay': 1.4920393231688057e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 134: Test Accuracy = 0.4672
trial:137 hidden_size: 1024, num_layers: 2, learning_rate: 6.230279192652879e-05, optimizer_name: Adam, weight_decay: 2.295820030337506e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
Trial 135: Test Accuracy = 0.4441
[I 2025-05-29 16:23:38,437] Trial 135 finished with value: 0.4440744817464686 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 2.3891862909422718e-05, 'weight_decay': 1.489913914978627e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:138 hidden_size: 1024, num_layers: 3, learning_rate: 2.356889030740107e-06, optimizer_name: Adam, weight_decay: 2.3071130485240125e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 136: Test Accuracy = 0.4783
[I 2025-05-29 16:27:58,877] Trial 136 finished with value: 0.47830061762367765 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 2.3393696146956654e-05, 'weight_decay': 1.4559725335993145e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:139 hidden_size: 1024, num_layers: 2, learning_rate: 6.20932994238299e-05, optimizer_name: Adam, weight_decay: 2.278545199525027e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
Trial 137: Test Accuracy = 0.5194
[I 2025-05-29 16:31:30,588] Trial 137 finished with value: 0.5193725921849203 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 6.230279192652879e-05, 'weight_decay': 2.295820030337506e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:140 hidden_size: 1024, num_layers: 2, learning_rate: 5.5537538909202854e-05, optimizer_name: Adam, weight_decay: 3.8470548473908085e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 139: Test Accuracy = 0.5373
[I 2025-05-29 16:40:01,117] Trial 139 finished with value: 0.5373356570659819 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 6.20932994238299e-05, 'weight_decay': 2.278545199525027e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:141 hidden_size: 1024, num_layers: 2, learning_rate: 6.67811672055421e-05, optimizer_name: Adam, weight_decay: 3.905309014218907e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 140: Test Accuracy = 0.4288
[I 2025-05-29 16:42:46,058] Trial 140 finished with value: 0.4288356876414114 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 5.5537538909202854e-05, 'weight_decay': 3.8470548473908085e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:142 hidden_size: 1024, num_layers: 2, learning_rate: 0.00014830414287630807, optimizer_name: Adam, weight_decay: 7.776432350320728e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Trial 138: Test Accuracy = 0.4800
[I 2025-05-29 16:44:57,356] Trial 138 finished with value: 0.4800311869381764 and parameters: {'hidden_size': 1024, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 2.356889030740107e-06, 'weight_decay': 2.3071130485240125e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:143 hidden_size: 1024, num_layers: 2, learning_rate: 0.00015757872496044775, optimizer_name: Adam, weight_decay: 7.681676070927202e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 141: Test Accuracy = 0.5063
[I 2025-05-29 16:48:33,911] Trial 141 finished with value: 0.5063015960374243 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 6.67811672055421e-05, 'weight_decay': 3.905309014218907e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:144 hidden_size: 1024, num_layers: 2, learning_rate: 0.00014991153316823257, optimizer_name: Adam, weight_decay: 2.666257997890808e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 144: Test Accuracy = 0.5454
[I 2025-05-29 16:59:28,463] Trial 144 finished with value: 0.5453555922460711 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 0.00014991153316823257, 'weight_decay': 2.666257997890808e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:145 hidden_size: 1024, num_layers: 2, learning_rate: 0.00010834731030664073, optimizer_name: Adam, weight_decay: 2.756267421759102e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Trial 142: Test Accuracy = 0.4888
[I 2025-05-29 17:01:39,341] Trial 142 finished with value: 0.48877881734238365 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.00014830414287630807, 'weight_decay': 7.776432350320728e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:146 hidden_size: 1024, num_layers: 2, learning_rate: 0.00015450019137347787, optimizer_name: Adam, weight_decay: 2.7827617612220848e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Trial 143: Test Accuracy = 0.4627
[I 2025-05-29 17:03:34,035] Trial 143 finished with value: 0.4626674004769767 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 0.00015757872496044775, 'weight_decay': 7.681676070927202e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:147 hidden_size: 1024, num_layers: 2, learning_rate: 0.00011438166223284585, optimizer_name: Adam, weight_decay: 2.837069314922313e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 145: Test Accuracy = 0.5132
[I 2025-05-29 17:07:12,323] Trial 145 finished with value: 0.5132361034672537 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 0.00010834731030664073, 'weight_decay': 2.756267421759102e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:148 hidden_size: 1024, num_layers: 2, learning_rate: 7.164848028094578e-05, optimizer_name: Adam, weight_decay: 2.2031920243004695e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
Trial 146: Test Accuracy = 0.4730
[I 2025-05-29 17:17:10,116] Trial 146 finished with value: 0.47302329847734365 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 0.00015450019137347787, 'weight_decay': 2.7827617612220848e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:149 hidden_size: 1024, num_layers: 2, learning_rate: 6.478575295931085e-05, optimizer_name: Adam, weight_decay: 2.1716781796472683e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
[I 2025-05-29 17:21:39,904] Trial 147 finished with value: 0.44825414297070876 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 0.00011438166223284585, 'weight_decay': 2.837069314922313e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 147: Test Accuracy = 0.4483
trial:150 hidden_size: 1024, num_layers: 2, learning_rate: 0.00032747731661669424, optimizer_name: Adam, weight_decay: 2.1882109116149925e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
[I 2025-05-29 17:26:45,917] Trial 148 finished with value: 0.516975478505473 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 7.164848028094578e-05, 'weight_decay': 2.2031920243004695e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 148: Test Accuracy = 0.5170
trial:151 hidden_size: 1024, num_layers: 2, learning_rate: 0.0003341435236428683, optimizer_name: Adam, weight_decay: 1.2049191748304256e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 149: Test Accuracy = 0.4727
[I 2025-05-29 17:36:53,477] Trial 149 finished with value: 0.4727267168103712 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 6.478575295931085e-05, 'weight_decay': 2.1716781796472683e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
trial:152 hidden_size: 32, num_layers: 2, learning_rate: 4.806054720163461e-05, optimizer_name: Adam, weight_decay: 4.522403408991995e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
[I 2025-05-29 17:38:20,495] Trial 151 finished with value: 0.48583440347336876 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.0003341435236428683, 'weight_decay': 1.2049191748304256e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
Trial 151: Test Accuracy = 0.4858
trial:153 hidden_size: 1024, num_layers: 2, learning_rate: 7.503029935450465e-05, optimizer_name: Adam, weight_decay: 2.4038634491050404e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
[I 2025-05-29 17:40:26,048] Trial 150 finished with value: 0.5513911820461078 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.00032747731661669424, 'weight_decay': 2.1882109116149925e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
Trial 150: Test Accuracy = 0.5514
trial:154 hidden_size: 1024, num_layers: 2, learning_rate: 0.00025066394474382466, optimizer_name: Adam, weight_decay: 4.484566576985278e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 28
[I 2025-05-29 17:44:52,530] Trial 152 finished with value: 0.49104751421757475 and parameters: {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 4.806054720163461e-05, 'weight_decay': 4.522403408991995e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 152: Test Accuracy = 0.4910
trial:155 hidden_size: 1024, num_layers: 2, learning_rate: 0.0002796057437372313, optimizer_name: Adam, weight_decay: 2.4676647690956293e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
Trial 153: Test Accuracy = 0.5116
[I 2025-05-29 17:53:27,027] Trial 153 finished with value: 0.5115850302696753 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 7.503029935450465e-05, 'weight_decay': 2.4038634491050404e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:156 hidden_size: 1024, num_layers: 2, learning_rate: 0.00029003642462796037, optimizer_name: Adam, weight_decay: 3.214314622886313e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
[I 2025-05-29 17:55:48,129] Trial 154 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.00025066394474382466, 'weight_decay': 4.484566576985278e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
Trial 154: Test Accuracy = 0.3333
trial:157 hidden_size: 1024, num_layers: 2, learning_rate: 0.001628438266714901, optimizer_name: Adam, weight_decay: 3.322813588384977e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 155: Test Accuracy = 0.5455
[I 2025-05-29 17:58:28,684] Trial 155 finished with value: 0.5455176420228703 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.0002796057437372313, 'weight_decay': 2.4676647690956293e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
trial:158 hidden_size: 1024, num_layers: 2, learning_rate: 0.00027385138312798423, optimizer_name: Adam, weight_decay: 3.1331904948324517e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 157: Test Accuracy = 0.3333
[I 2025-05-29 18:05:10,598] Trial 157 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.001628438266714901, 'weight_decay': 3.322813588384977e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
trial:159 hidden_size: 1024, num_layers: 2, learning_rate: 0.0005633792174408507, optimizer_name: Adam, weight_decay: 1.9741508508447467e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
[I 2025-05-29 18:06:09,085] Trial 156 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.00029003642462796037, 'weight_decay': 3.214314622886313e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
Trial 156: Test Accuracy = 0.3333
trial:160 hidden_size: 1024, num_layers: 2, learning_rate: 0.0007715104966323789, optimizer_name: Adam, weight_decay: 2.7287086817121243e-05, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 158: Test Accuracy = 0.3958
[I 2025-05-29 18:09:44,730] Trial 158 finished with value: 0.3958142236898428 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.00027385138312798423, 'weight_decay': 3.1331904948324517e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
trial:161 hidden_size: 1024, num_layers: 2, learning_rate: 3.889764218552209e-06, optimizer_name: Adam, weight_decay: 1.9997589997781276e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 159: Test Accuracy = 0.3333
[I 2025-05-29 18:13:51,693] Trial 159 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.0005633792174408507, 'weight_decay': 1.9741508508447467e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:162 hidden_size: 128, num_layers: 2, learning_rate: 0.0007427227055760138, optimizer_name: Adam, weight_decay: 2.3316801794384753e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Trial 161: Test Accuracy = 0.4953
[I 2025-05-29 18:22:36,939] Trial 161 finished with value: 0.4953219592735278 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 3.889764218552209e-06, 'weight_decay': 1.9997589997781276e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
trial:163 hidden_size: 128, num_layers: 4, learning_rate: 1.387844036919123e-07, optimizer_name: Adam, weight_decay: 1.6530779089137321e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 160: Test Accuracy = 0.3333
[I 2025-05-29 18:22:46,039] Trial 160 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.0007715104966323789, 'weight_decay': 2.7287086817121243e-05, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
trial:164 hidden_size: 128, num_layers: 4, learning_rate: 0.0001729372575451811, optimizer_name: Adam, weight_decay: 2.5942977528313783e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 29
[I 2025-05-29 18:23:14,461] Trial 162 finished with value: 0.5324466458753746 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.0007427227055760138, 'weight_decay': 2.3316801794384753e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
Trial 162: Test Accuracy = 0.5324
trial:165 hidden_size: 128, num_layers: 2, learning_rate: 0.0010723364496896778, optimizer_name: Adam, weight_decay: 2.4944875214724177e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
[I 2025-05-29 18:24:43,202] Trial 164 finished with value: 0.45769277808353204 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 0.0001729372575451811, 'weight_decay': 2.5942977528313783e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
Trial 164: Test Accuracy = 0.4577
trial:166 hidden_size: 128, num_layers: 2, learning_rate: 0.0007765738532150569, optimizer_name: Adam, weight_decay: 1.6961521382237295e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
[I 2025-05-29 18:24:45,998] Trial 163 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 1.387844036919123e-07, 'weight_decay': 1.6530779089137321e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
Trial 163: Test Accuracy = 0.3333
trial:167 hidden_size: 128, num_layers: 2, learning_rate: 0.0010119311271806575, optimizer_name: Adam, weight_decay: 2.3544704458332626e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
[I 2025-05-29 18:25:15,707] Trial 165 finished with value: 0.5315263254448725 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.0010723364496896778, 'weight_decay': 2.4944875214724177e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
Trial 165: Test Accuracy = 0.5315
trial:168 hidden_size: 128, num_layers: 2, learning_rate: 0.0006561073002225118, optimizer_name: Adam, weight_decay: 2.541099670813349e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
[I 2025-05-29 18:25:27,210] Trial 167 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.0010119311271806575, 'weight_decay': 2.3544704458332626e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
Trial 167: Test Accuracy = 0.3333
trial:169 hidden_size: 128, num_layers: 2, learning_rate: 0.003617178115715378, optimizer_name: Adam, weight_decay: 3.552327158755971e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
[I 2025-05-29 18:26:15,276] Trial 168 finished with value: 0.43982449703418336 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.0006561073002225118, 'weight_decay': 2.541099670813349e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
Trial 168: Test Accuracy = 0.4398
trial:170 hidden_size: 128, num_layers: 2, learning_rate: 0.003792236406666779, optimizer_name: Adam, weight_decay: 3.6249352073290208e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
[I 2025-05-29 18:26:32,031] Trial 166 finished with value: 0.36294563688619824 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.0007765738532150569, 'weight_decay': 1.6961521382237295e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
Trial 166: Test Accuracy = 0.3629
trial:171 hidden_size: 128, num_layers: 2, learning_rate: 0.0003973085255092236, optimizer_name: Adam, weight_decay: 9.67475407125402e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
[I 2025-05-29 18:26:48,511] Trial 169 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.003617178115715378, 'weight_decay': 3.552327158755971e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
Trial 169: Test Accuracy = 0.3333
trial:172 hidden_size: 128, num_layers: 1, learning_rate: 0.00040003236661101144, optimizer_name: Adam, weight_decay: 1.016181220208999e-05, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
[I 2025-05-29 18:27:13,614] Trial 170 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.003792236406666779, 'weight_decay': 3.6249352073290208e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
Trial 170: Test Accuracy = 0.3333
trial:173 hidden_size: 128, num_layers: 2, learning_rate: 0.002425456898832653, optimizer_name: Adam, weight_decay: 2.9054713614773773e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
[I 2025-05-29 18:28:08,541] Trial 171 finished with value: 0.4521769705864367 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.0003973085255092236, 'weight_decay': 9.67475407125402e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
Trial 171: Test Accuracy = 0.4522
trial:174 hidden_size: 64, num_layers: 2, learning_rate: 0.0018583498584303043, optimizer_name: Adam, weight_decay: 2.192093135470955e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
[I 2025-05-29 18:28:14,970] Trial 173 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.002425456898832653, 'weight_decay': 2.9054713614773773e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
Trial 173: Test Accuracy = 0.3333
trial:175 hidden_size: 64, num_layers: 2, learning_rate: 0.0013493235899243918, optimizer_name: Adam, weight_decay: 2.170250235800763e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 28
[I 2025-05-29 18:28:30,910] Trial 172 finished with value: 0.4717238427199902 and parameters: {'hidden_size': 128, 'num_layers': 1, 'dropout': 0.5, 'learning_rate': 0.00040003236661101144, 'weight_decay': 1.016181220208999e-05, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
Trial 172: Test Accuracy = 0.4717
trial:176 hidden_size: 64, num_layers: 2, learning_rate: 0.0010971188577556731, optimizer_name: Adam, weight_decay: 2.1646524918800625e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 18:29:51,033] Trial 174 finished with value: 0.36781936036201307 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.0018583498584303043, 'weight_decay': 2.192093135470955e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
Trial 174: Test Accuracy = 0.3678
trial:177 hidden_size: 32, num_layers: 2, learning_rate: 0.0010216455097511725, optimizer_name: Adam, weight_decay: 1.8958758981879163e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 18:29:57,024] Trial 175 finished with value: 0.394147862777472 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.0013493235899243918, 'weight_decay': 2.170250235800763e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
Trial 175: Test Accuracy = 0.3941
trial:178 hidden_size: 32, num_layers: 4, learning_rate: 0.0010538337088604557, optimizer_name: Adam, weight_decay: 1.908466510520135e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 18:30:12,700] Trial 176 finished with value: 0.42027762490062986 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.0010971188577556731, 'weight_decay': 2.1646524918800625e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 176: Test Accuracy = 0.4203
trial:179 hidden_size: 1024, num_layers: 4, learning_rate: 5.3317718157958937e-08, optimizer_name: Adam, weight_decay: 1.8753969748242904e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 178: Test Accuracy = 0.4376
[I 2025-05-29 18:31:51,871] Trial 178 finished with value: 0.43755885770195074 and parameters: {'hidden_size': 32, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 0.0010538337088604557, 'weight_decay': 1.908466510520135e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:180 hidden_size: 1024, num_layers: 2, learning_rate: 0.0005013326099114507, optimizer_name: Adam, weight_decay: 2.6554695701232206e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
Trial 177: Test Accuracy = 0.4816
[I 2025-05-29 18:37:22,258] Trial 177 finished with value: 0.4816088791047514 and parameters: {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.0010216455097511725, 'weight_decay': 1.8958758981879163e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:181 hidden_size: 1024, num_layers: 4, learning_rate: 8.801903712761388e-05, optimizer_name: Adam, weight_decay: 2.505907779513629e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 179: Test Accuracy = 0.3361
[I 2025-05-29 18:39:31,446] Trial 179 finished with value: 0.3360759493670886 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 5.3317718157958937e-08, 'weight_decay': 1.8753969748242904e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:182 hidden_size: 1024, num_layers: 2, learning_rate: 9.511690999083619e-05, optimizer_name: Adam, weight_decay: 2.5211852258355694e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 180: Test Accuracy = 0.3333
[I 2025-05-29 18:41:29,095] Trial 180 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.0005013326099114507, 'weight_decay': 2.6554695701232206e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:183 hidden_size: 1024, num_layers: 3, learning_rate: 9.258710350596693e-05, optimizer_name: Adam, weight_decay: 1.3307031127397919e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 181: Test Accuracy = 0.3333
[I 2025-05-29 19:43:01,574] Trial 181 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 8.801903712761388e-05, 'weight_decay': 2.505907779513629e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:184 hidden_size: 256, num_layers: 3, learning_rate: 4.9382517504774965e-06, optimizer_name: Adam, weight_decay: 1.333475143607681e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 29
Trial 182: Test Accuracy = 0.4914
[I 2025-05-29 19:44:41,668] Trial 182 finished with value: 0.491368556228215 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.30000000000000004, 'learning_rate': 9.511690999083619e-05, 'weight_decay': 2.5211852258355694e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:185 hidden_size: 256, num_layers: 3, learning_rate: 5.47445660636247e-06, optimizer_name: Adam, weight_decay: 1.1693439302830745e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 19:45:51,337] Trial 183 finished with value: 0.506995658288999 and parameters: {'hidden_size': 1024, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 9.258710350596693e-05, 'weight_decay': 1.3307031127397919e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 183: Test Accuracy = 0.5070
trial:186 hidden_size: 256, num_layers: 3, learning_rate: 5.84190604953103e-06, optimizer_name: Adam, weight_decay: 1.6142336238901281e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
[I 2025-05-29 19:48:49,386] Trial 184 finished with value: 0.5123891640677551 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 4.9382517504774965e-06, 'weight_decay': 1.333475143607681e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 184: Test Accuracy = 0.5124
trial:187 hidden_size: 256, num_layers: 3, learning_rate: 4.439254329687938e-05, optimizer_name: Adam, weight_decay: 1.1519022702036823e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 19:49:17,405] Trial 185 finished with value: 0.5046474652968874 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 5.47445660636247e-06, 'weight_decay': 1.1693439302830745e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 185: Test Accuracy = 0.5046
trial:188 hidden_size: 64, num_layers: 3, learning_rate: 5.252881368563077e-05, optimizer_name: Adam, weight_decay: 1.0755908273521813e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 19:49:43,148] Trial 186 finished with value: 0.46837277563749774 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 5.84190604953103e-06, 'weight_decay': 1.6142336238901281e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 186: Test Accuracy = 0.4684
trial:189 hidden_size: 512, num_layers: 3, learning_rate: 5.409221010222414e-05, optimizer_name: Adam, weight_decay: 3.04743265782847e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
[I 2025-05-29 19:51:38,202] Trial 188 finished with value: 0.46660857335045564 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 5.252881368563077e-05, 'weight_decay': 1.0755908273521813e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 188: Test Accuracy = 0.4666
trial:190 hidden_size: 128, num_layers: 3, learning_rate: 0.0001215125455670776, optimizer_name: Adam, weight_decay: 3.000259854340182e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
[I 2025-05-29 19:51:51,623] Trial 187 finished with value: 0.3918088424142359 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 4.439254329687938e-05, 'weight_decay': 1.1519022702036823e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 187: Test Accuracy = 0.3918
trial:191 hidden_size: 512, num_layers: 2, learning_rate: 0.00013290576983150952, optimizer_name: Adam, weight_decay: 3.0720527414631375e-06, batch_size: 32, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
[I 2025-05-29 19:52:41,492] Trial 189 finished with value: 0.514969730324711 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 5.409221010222414e-05, 'weight_decay': 3.04743265782847e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 189: Test Accuracy = 0.5150
trial:192 hidden_size: 128, num_layers: 2, learning_rate: 0.00012387251336363458, optimizer_name: Adam, weight_decay: 1.737719567247022e-06, batch_size: 32, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
[I 2025-05-29 19:53:18,173] Trial 190 finished with value: 0.450076438573962 and parameters: {'hidden_size': 128, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 0.0001215125455670776, 'weight_decay': 3.000259854340182e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 190: Test Accuracy = 0.4501
trial:193 hidden_size: 1024, num_layers: 2, learning_rate: 7.305662818339301e-05, optimizer_name: Adam, weight_decay: 2.2292025104195204e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 191: Test Accuracy = 0.5426
[I 2025-05-29 19:55:09,489] Trial 191 finished with value: 0.5425548828961047 and parameters: {'hidden_size': 512, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 0.00013290576983150952, 'weight_decay': 3.0720527414631375e-06, 'batch_size': 32}. Best is trial 45 with value: 0.5824833363908763.
trial:194 hidden_size: 512, num_layers: 2, learning_rate: 0.00013247545035242547, optimizer_name: Adam, weight_decay: 3.977574049742052e-06, batch_size: 32, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 29
[I 2025-05-29 19:55:42,828] Trial 192 finished with value: 0.47434721457836476 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 0.00012387251336363458, 'weight_decay': 1.737719567247022e-06, 'batch_size': 32}. Best is trial 45 with value: 0.5824833363908763.
Trial 192: Test Accuracy = 0.4743
trial:195 hidden_size: 32, num_layers: 2, learning_rate: 0.00018939670670699012, optimizer_name: Adam, weight_decay: 2.352393951250878e-06, batch_size: 32, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
Trial 195: Test Accuracy = 0.4757
[I 2025-05-29 19:58:53,118] Trial 195 finished with value: 0.47573533908151405 and parameters: {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 0.00018939670670699012, 'weight_decay': 2.352393951250878e-06, 'batch_size': 32}. Best is trial 45 with value: 0.5824833363908763.
trial:196 hidden_size: 512, num_layers: 2, learning_rate: 6.993963760772151e-05, optimizer_name: Adam, weight_decay: 4.0072555920957575e-06, batch_size: 32, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
[I 2025-05-29 19:59:05,747] Trial 193 finished with value: 0.4959426404940989 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 7.305662818339301e-05, 'weight_decay': 2.2292025104195204e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 193: Test Accuracy = 0.4959
trial:197 hidden_size: 512, num_layers: 2, learning_rate: 0.00013387111919715936, optimizer_name: Adam, weight_decay: 2.8993387680200132e-06, batch_size: 32, label_smoothing: 0.3, factor: 1
[I 2025-05-29 20:00:19,238] Trial 194 finished with value: 0.5069987158319574 and parameters: {'hidden_size': 512, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 0.00013247545035242547, 'weight_decay': 3.977574049742052e-06, 'batch_size': 32}. Best is trial 45 with value: 0.5824833363908763.
Trial 194: Test Accuracy = 0.5070
trial:198 hidden_size: 512, num_layers: 2, learning_rate: 0.00020502907324900185, optimizer_name: Adam, weight_decay: 4.913458426472654e-06, batch_size: 32, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
[I 2025-05-29 20:00:30,157] Trial 196 finished with value: 0.4082217330153488 and parameters: {'hidden_size': 512, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 6.993963760772151e-05, 'weight_decay': 4.0072555920957575e-06, 'batch_size': 32}. Best is trial 45 with value: 0.5824833363908763.
Trial 196: Test Accuracy = 0.4082
trial:199 hidden_size: 512, num_layers: 2, learning_rate: 3.639583066745105e-05, optimizer_name: Adam, weight_decay: 2.883843463878537e-06, batch_size: 32, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
[I 2025-05-29 20:02:39,644] Trial 198 finished with value: 0.4809820827982633 and parameters: {'hidden_size': 512, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 0.00020502907324900185, 'weight_decay': 4.913458426472654e-06, 'batch_size': 32}. Best is trial 45 with value: 0.5824833363908763.
Trial 198: Test Accuracy = 0.4810
trial:200 hidden_size: 512, num_layers: 1, learning_rate: 3.3739606069967048e-06, optimizer_name: Adam, weight_decay: 6.176604076556577e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 29
[I 2025-05-29 20:03:10,005] Trial 197 finished with value: 0.4752124992356142 and parameters: {'hidden_size': 512, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 0.00013387111919715936, 'weight_decay': 2.8993387680200132e-06, 'batch_size': 32}. Best is trial 45 with value: 0.5824833363908763.
Trial 197: Test Accuracy = 0.4752
trial:201 hidden_size: 1024, num_layers: 1, learning_rate: 4.393060674222963e-05, optimizer_name: Adam, weight_decay: 3.4191889238184773e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Trial 199: Test Accuracy = 0.4228
[I 2025-05-29 20:04:53,430] Trial 199 finished with value: 0.42280621292729165 and parameters: {'hidden_size': 512, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 3.639583066745105e-05, 'weight_decay': 2.883843463878537e-06, 'batch_size': 32}. Best is trial 45 with value: 0.5824833363908763.
trial:202 hidden_size: 1024, num_layers: 1, learning_rate: 2.992271558263836e-06, optimizer_name: Adam, weight_decay: 6.606537318637357e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 201: Test Accuracy = 0.4648
[I 2025-05-29 20:09:12,917] Trial 201 finished with value: 0.4647893352901608 and parameters: {'hidden_size': 1024, 'num_layers': 1, 'dropout': 0.5, 'learning_rate': 4.393060674222963e-05, 'weight_decay': 3.4191889238184773e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:203 hidden_size: 1024, num_layers: 2, learning_rate: 7.50010322103267e-05, optimizer_name: Adam, weight_decay: 2.252395523415707e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Trial 200: Test Accuracy = 0.4920
[I 2025-05-29 20:10:09,379] Trial 200 finished with value: 0.4919556044762428 and parameters: {'hidden_size': 512, 'num_layers': 1, 'dropout': 0.4, 'learning_rate': 3.3739606069967048e-06, 'weight_decay': 6.176604076556577e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:204 hidden_size: 1024, num_layers: 2, learning_rate: 6.833826573089511e-05, optimizer_name: Adam, weight_decay: 2.1462382879043864e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Trial 202: Test Accuracy = 0.4861
[I 2025-05-29 20:16:00,115] Trial 202 finished with value: 0.48610346725371495 and parameters: {'hidden_size': 1024, 'num_layers': 1, 'dropout': 0.2, 'learning_rate': 2.992271558263836e-06, 'weight_decay': 6.606537318637357e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:205 hidden_size: 1024, num_layers: 2, learning_rate: 8.152035502543871e-05, optimizer_name: Adam, weight_decay: 2.0697514975796693e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Trial 203: Test Accuracy = 0.5017
[I 2025-05-29 20:26:49,356] Trial 203 finished with value: 0.5016847061701217 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 7.50010322103267e-05, 'weight_decay': 2.252395523415707e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:206 hidden_size: 1024, num_layers: 2, learning_rate: 5.7939162328302244e-05, optimizer_name: Adam, weight_decay: 2.104708992500584e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Trial 204: Test Accuracy = 0.4899
[I 2025-05-29 20:31:29,230] Trial 204 finished with value: 0.48986424509264354 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 6.833826573089511e-05, 'weight_decay': 2.1462382879043864e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:207 hidden_size: 1024, num_layers: 2, learning_rate: 0.0001003897065198372, optimizer_name: Adam, weight_decay: 1.441580723345431e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 29
[I 2025-05-29 20:34:28,735] Trial 205 finished with value: 0.49916529077233535 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 8.152035502543871e-05, 'weight_decay': 2.0697514975796693e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 205: Test Accuracy = 0.4992
trial:208 hidden_size: 256, num_layers: 3, learning_rate: 9.807603517763855e-05, optimizer_name: Adam, weight_decay: 1.654773367232489e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 206: Test Accuracy = 0.4825
[I 2025-05-29 20:35:27,040] Trial 206 finished with value: 0.4824986241056686 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 5.7939162328302244e-05, 'weight_decay': 2.104708992500584e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:209 hidden_size: 256, num_layers: 3, learning_rate: 9.263727730416856e-05, optimizer_name: Adam, weight_decay: 2.5520124262862423e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
[I 2025-05-29 20:41:31,977] Trial 208 finished with value: 0.35779673454412037 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 9.807603517763855e-05, 'weight_decay': 1.654773367232489e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
Trial 208: Test Accuracy = 0.3578
trial:210 hidden_size: 64, num_layers: 3, learning_rate: 0.00032044841173272173, optimizer_name: Adam, weight_decay: 2.5015122700812207e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
[I 2025-05-29 20:43:44,302] Trial 210 finished with value: 0.5032195927352779 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 0.00032044841173272173, 'weight_decay': 2.5015122700812207e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 210: Test Accuracy = 0.5032
trial:211 hidden_size: 256, num_layers: 4, learning_rate: 1.7293278640233006e-06, optimizer_name: Adam, weight_decay: 1.460810270930129e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
[I 2025-05-29 20:45:05,049] Trial 209 finished with value: 0.4388583134593041 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 9.263727730416856e-05, 'weight_decay': 2.5520124262862423e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
Trial 209: Test Accuracy = 0.4389
trial:212 hidden_size: 1024, num_layers: 4, learning_rate: 1.692713871800412e-06, optimizer_name: Adam, weight_decay: 1.4101058062159739e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Trial 207: Test Accuracy = 0.4136
[I 2025-05-29 20:45:07,336] Trial 207 finished with value: 0.41362746896593894 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 0.0001003897065198372, 'weight_decay': 1.441580723345431e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
trial:213 hidden_size: 512, num_layers: 3, learning_rate: 5.75245299789549e-05, optimizer_name: Adam, weight_decay: 3.2421460464006265e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
[I 2025-05-29 20:57:32,921] Trial 212 finished with value: 0.5516724759982877 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 1.692713871800412e-06, 'weight_decay': 1.4101058062159739e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 212: Test Accuracy = 0.5517
trial:214 hidden_size: 1024, num_layers: 4, learning_rate: 6.373029117413765e-07, optimizer_name: Adam, weight_decay: 1.8056028751597604e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 213: Test Accuracy = 0.5261
[I 2025-05-29 20:58:11,221] Trial 213 finished with value: 0.5260502660062374 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 5.75245299789549e-05, 'weight_decay': 3.2421460464006265e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:215 hidden_size: 512, num_layers: 4, learning_rate: 1.7985333937465142e-06, optimizer_name: Adam, weight_decay: 1.0264375335908086e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 21:02:51,779] Trial 211 finished with value: 0.47009722986607966 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 1.7293278640233006e-06, 'weight_decay': 1.460810270930129e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
Trial 211: Test Accuracy = 0.4701
trial:216 hidden_size: 512, num_layers: 3, learning_rate: 1.4621243017376688e-06, optimizer_name: Adam, weight_decay: 3.158376305695348e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 21:14:51,926] Trial 214 finished with value: 0.46191218736623246 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 6.373029117413765e-07, 'weight_decay': 1.8056028751597604e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 214: Test Accuracy = 0.4619
trial:217 hidden_size: 512, num_layers: 3, learning_rate: 9.260923478633913e-06, optimizer_name: Adam, weight_decay: 3.2538646848936313e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 21:16:19,350] Trial 216 finished with value: 0.4755243686173791 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 1.4621243017376688e-06, 'weight_decay': 3.158376305695348e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 216: Test Accuracy = 0.4755
trial:218 hidden_size: 512, num_layers: 4, learning_rate: 1.0110733372253746e-05, optimizer_name: Adam, weight_decay: 3.588646268688525e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 21:16:40,941] Trial 215 finished with value: 0.49008744572861246 and parameters: {'hidden_size': 512, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 1.7985333937465142e-06, 'weight_decay': 1.0264375335908086e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 215: Test Accuracy = 0.4901
trial:219 hidden_size: 128, num_layers: 4, learning_rate: 2.4523026444146466e-07, optimizer_name: Adam, weight_decay: 2.7353566235560403e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
[I 2025-05-29 21:18:55,775] Trial 219 finished with value: 0.2950070323488045 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 2.4523026444146466e-07, 'weight_decay': 2.7353566235560403e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 219: Test Accuracy = 0.2950
trial:220 hidden_size: 512, num_layers: 3, learning_rate: 8.571576587570774e-06, optimizer_name: Adam, weight_decay: 1.317788387813373e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
[I 2025-05-29 21:20:26,365] Trial 218 finished with value: 0.5520485537821807 and parameters: {'hidden_size': 512, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 1.0110733372253746e-05, 'weight_decay': 3.588646268688525e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 218: Test Accuracy = 0.5520
trial:221 hidden_size: 512, num_layers: 4, learning_rate: 8.536314966907811e-06, optimizer_name: Adam, weight_decay: 3.58785768661256e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
[I 2025-05-29 21:21:09,380] Trial 217 finished with value: 0.45195071240750934 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 9.260923478633913e-06, 'weight_decay': 3.2538646848936313e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 217: Test Accuracy = 0.4520
trial:222 hidden_size: 512, num_layers: 4, learning_rate: 4.5014954282574775e-05, optimizer_name: Adam, weight_decay: 4.230433129641135e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
[I 2025-05-29 21:24:03,061] Trial 220 finished with value: 0.48286858680364464 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 8.571576587570774e-06, 'weight_decay': 1.317788387813373e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 220: Test Accuracy = 0.4829
trial:223 hidden_size: 512, num_layers: 4, learning_rate: 1.006660705263168e-06, optimizer_name: Adam, weight_decay: 3.83768578681863e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
[I 2025-05-29 21:25:24,075] Trial 221 finished with value: 0.49010273344340494 and parameters: {'hidden_size': 512, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 8.536314966907811e-06, 'weight_decay': 3.58785768661256e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 221: Test Accuracy = 0.4901
trial:224 hidden_size: 512, num_layers: 4, learning_rate: 1.4865451444699622e-05, optimizer_name: Adam, weight_decay: 3.986326358998434e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
[I 2025-05-29 21:26:19,132] Trial 222 finished with value: 0.46205283434232247 and parameters: {'hidden_size': 512, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 4.5014954282574775e-05, 'weight_decay': 4.230433129641135e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 222: Test Accuracy = 0.4621
trial:225 hidden_size: 64, num_layers: 4, learning_rate: 2.3283143027803005e-06, optimizer_name: Adam, weight_decay: 2.741824126520373e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
[I 2025-05-29 21:27:57,513] Trial 225 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 2.3283143027803005e-06, 'weight_decay': 2.741824126520373e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 225: Test Accuracy = 0.3333
trial:226 hidden_size: 32, num_layers: 4, learning_rate: 3.186005398359044e-05, optimizer_name: Adam, weight_decay: 4.752967531567123e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
[I 2025-05-29 21:29:45,279] Trial 226 finished with value: 0.42180028129395214 and parameters: {'hidden_size': 32, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 3.186005398359044e-05, 'weight_decay': 4.752967531567123e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 226: Test Accuracy = 0.4218
trial:227 hidden_size: 512, num_layers: 3, learning_rate: 1.4568694653797127e-05, optimizer_name: Adam, weight_decay: 3.6447806629544687e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 21:32:26,963] Trial 224 finished with value: 0.47356142603803586 and parameters: {'hidden_size': 512, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 1.4865451444699622e-05, 'weight_decay': 3.986326358998434e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 224: Test Accuracy = 0.4736
trial:228 hidden_size: 256, num_layers: 3, learning_rate: 4.321779371715315e-06, optimizer_name: Adam, weight_decay: 2.4761621581886523e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 21:32:35,461] Trial 223 finished with value: 0.510829817158931 and parameters: {'hidden_size': 512, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 1.006660705263168e-06, 'weight_decay': 3.83768578681863e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 223: Test Accuracy = 0.5108
trial:229 hidden_size: 256, num_layers: 3, learning_rate: 1.1484753364805996e-05, optimizer_name: Adam, weight_decay: 2.533648067295354e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
[I 2025-05-29 21:34:42,484] Trial 227 finished with value: 0.5035834403473369 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 1.4568694653797127e-05, 'weight_decay': 3.6447806629544687e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 227: Test Accuracy = 0.5036
trial:230 hidden_size: 256, num_layers: 3, learning_rate: 5.743719090613463e-05, optimizer_name: Adam, weight_decay: 3.0097825713814104e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 21:37:06,990] Trial 228 finished with value: 0.5076193970525286 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 4.321779371715315e-06, 'weight_decay': 2.4761621581886523e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 228: Test Accuracy = 0.5076
trial:231 hidden_size: 128, num_layers: 3, learning_rate: 0.0001562529755323759, optimizer_name: Adam, weight_decay: 3.0393763180801072e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Trial 229: Test Accuracy = 0.5391
[I 2025-05-29 21:37:27,057] Trial 229 finished with value: 0.5391029168959823 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 1.1484753364805996e-05, 'weight_decay': 2.533648067295354e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:232 hidden_size: 128, num_layers: 3, learning_rate: 6.701151658275359e-06, optimizer_name: Adam, weight_decay: 3.0520906831278386e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 230: Test Accuracy = 0.4792
[I 2025-05-29 21:37:31,263] Trial 230 finished with value: 0.47922093805417965 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 5.743719090613463e-05, 'weight_decay': 3.0097825713814104e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:233 hidden_size: 256, num_layers: 3, learning_rate: 5.993860338855451e-06, optimizer_name: Adam, weight_decay: 1.9135174388202035e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
[I 2025-05-29 21:38:37,944] Trial 231 finished with value: 0.41798141013881246 and parameters: {'hidden_size': 128, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 0.0001562529755323759, 'weight_decay': 3.0393763180801072e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 231: Test Accuracy = 0.4180
trial:234 hidden_size: 256, num_layers: 3, learning_rate: 1.0765820304332054e-05, optimizer_name: Adam, weight_decay: 2.43055381705635e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 21:40:15,200] Trial 232 finished with value: 0.49263743655598363 and parameters: {'hidden_size': 128, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 6.701151658275359e-06, 'weight_decay': 3.0520906831278386e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 232: Test Accuracy = 0.4926
trial:235 hidden_size: 256, num_layers: 3, learning_rate: 1.2109155475306842e-05, optimizer_name: Adam, weight_decay: 2.4397898852516547e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 21:41:04,163] Trial 233 finished with value: 0.5085978107992417 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 5.993860338855451e-06, 'weight_decay': 1.9135174388202035e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 233: Test Accuracy = 0.5086
trial:236 hidden_size: 256, num_layers: 3, learning_rate: 1.0745181839224403e-05, optimizer_name: Adam, weight_decay: 2.4406895556146923e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
[I 2025-05-29 21:41:49,488] Trial 234 finished with value: 0.49893903259340794 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 1.0765820304332054e-05, 'weight_decay': 2.43055381705635e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 234: Test Accuracy = 0.4989
trial:237 hidden_size: 256, num_layers: 3, learning_rate: 2.2481514353130946e-05, optimizer_name: Adam, weight_decay: 1.957209308424941e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 29
[I 2025-05-29 21:44:18,524] Trial 235 finished with value: 0.43552559163456245 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 1.2109155475306842e-05, 'weight_decay': 2.4397898852516547e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 235: Test Accuracy = 0.4355
trial:238 hidden_size: 1024, num_layers: 3, learning_rate: 2.009122427916742e-05, optimizer_name: Adam, weight_decay: 1.5439039322763657e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 29
Trial 236: Test Accuracy = 0.4765
[I 2025-05-29 21:45:56,099] Trial 236 finished with value: 0.4765027823640922 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 1.0745181839224403e-05, 'weight_decay': 2.4406895556146923e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:239 hidden_size: 1024, num_layers: 3, learning_rate: 1.8977032846492244e-05, optimizer_name: Adam, weight_decay: 1.2046252826247672e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Trial 237: Test Accuracy = 0.4409
[I 2025-05-29 21:48:46,178] Trial 237 finished with value: 0.4409374426710695 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 2.2481514353130946e-05, 'weight_decay': 1.957209308424941e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:240 hidden_size: 1024, num_layers: 4, learning_rate: 5.8467247814056156e-05, optimizer_name: Adam, weight_decay: 1.6129143039794964e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 239: Test Accuracy = 0.5184
[I 2025-05-29 22:08:21,455] Trial 239 finished with value: 0.518394178438207 and parameters: {'hidden_size': 1024, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 1.8977032846492244e-05, 'weight_decay': 1.2046252826247672e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:241 hidden_size: 1024, num_layers: 3, learning_rate: 6.200238861280165e-05, optimizer_name: Adam, weight_decay: 1.5979338729167546e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Trial 238: Test Accuracy = 0.4689
[I 2025-05-29 22:12:16,469] Trial 238 finished with value: 0.46885892496789583 and parameters: {'hidden_size': 1024, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 2.009122427916742e-05, 'weight_decay': 1.5439039322763657e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:242 hidden_size: 1024, num_layers: 4, learning_rate: 5.4866378293653584e-05, optimizer_name: Adam, weight_decay: 2.7188548077844423e-06, batch_size: 10, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 241: Test Accuracy = 0.3333
[I 2025-05-29 23:15:24,978] Trial 241 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 1024, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 6.200238861280165e-05, 'weight_decay': 1.5979338729167546e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
trial:243 hidden_size: 1024, num_layers: 3, learning_rate: 1.7468903241288573e-05, optimizer_name: Adam, weight_decay: 1.1921507354789756e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-29 23:34:03,318] Trial 240 finished with value: 0.4997248211337369 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 5.8467247814056156e-05, 'weight_decay': 1.6129143039794964e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
Trial 240: Test Accuracy = 0.4997
trial:244 hidden_size: 1024, num_layers: 3, learning_rate: 1.6407585432856636e-05, optimizer_name: Adam, weight_decay: 1.1708869114525917e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Trial 243: Test Accuracy = 0.4793
[I 2025-05-30 00:36:55,045] Trial 243 finished with value: 0.4793340671436434 and parameters: {'hidden_size': 1024, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 1.7468903241288573e-05, 'weight_decay': 1.1921507354789756e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:245 hidden_size: 1024, num_layers: 3, learning_rate: 4.366738227173966e-05, optimizer_name: Adam, weight_decay: 1.2605243094161151e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 244: Test Accuracy = 0.4805
[I 2025-05-30 00:37:22,419] Trial 244 finished with value: 0.4804623004953219 and parameters: {'hidden_size': 1024, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 1.6407585432856636e-05, 'weight_decay': 1.1708869114525917e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:246 hidden_size: 64, num_layers: 3, learning_rate: 3.9317566612876935e-05, optimizer_name: Adam, weight_decay: 1.354131768892963e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 242: Test Accuracy = 0.3333
[I 2025-05-30 00:40:09,213] Trial 242 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 5.4866378293653584e-05, 'weight_decay': 2.7188548077844423e-06, 'batch_size': 10}. Best is trial 45 with value: 0.5824833363908763.
trial:247 hidden_size: 32, num_layers: 3, learning_rate: 0.00011163338316341673, optimizer_name: Adam, weight_decay: 1.3354622311182552e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
[I 2025-05-30 00:43:40,545] Trial 246 finished with value: 0.4742677184614444 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 3.9317566612876935e-05, 'weight_decay': 1.354131768892963e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
Trial 246: Test Accuracy = 0.4743
trial:248 hidden_size: 32, num_layers: 3, learning_rate: 2.8348787925320316e-05, optimizer_name: Adam, weight_decay: 1.0261745975039385e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Trial 247: Test Accuracy = 0.4708
[I 2025-05-30 00:45:46,056] Trial 247 finished with value: 0.47080963737540515 and parameters: {'hidden_size': 32, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 0.00011163338316341673, 'weight_decay': 1.3354622311182552e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:249 hidden_size: 1024, num_layers: 2, learning_rate: 0.0002466352338192184, optimizer_name: Adam, weight_decay: 1.0166727228556006e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Trial 248: Test Accuracy = 0.5032
[I 2025-05-30 00:49:59,902] Trial 248 finished with value: 0.5031890173056932 and parameters: {'hidden_size': 32, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 2.8348787925320316e-05, 'weight_decay': 1.0261745975039385e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:250 hidden_size: 1024, num_layers: 2, learning_rate: 0.00024683356355099327, optimizer_name: Adam, weight_decay: 2.07170798833352e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Trial 245: Test Accuracy = 0.3786
[I 2025-05-30 00:52:42,430] Trial 245 finished with value: 0.3786430624350272 and parameters: {'hidden_size': 1024, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 4.366738227173966e-05, 'weight_decay': 1.2605243094161151e-06, 'batch_size': 16}. Best is trial 45 with value: 0.5824833363908763.
trial:251 hidden_size: 256, num_layers: 2, learning_rate: 8.410862518684443e-05, optimizer_name: Adam, weight_decay: 5.768643055558032e-06, batch_size: 16, label_smoothing: 0.3, factor: 1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 28