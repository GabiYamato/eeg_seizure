{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "626d84bd",
   "metadata": {
    "id": "626d84bd"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ad51f8",
   "metadata": {
    "id": "29ad51f8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define the folder path\n",
    "folder_path = r\"D:\\PYTHONIG\\newwindow\\NOTEBOOKS_2025\\aprilmay2025\\data\\numpy\\optunadata\\STFT\"\n",
    "\n",
    "# Load the numpy files into the respective arrays with the correct capitalized naming\n",
    "eeg_fold_1 = np.load(os.path.join(folder_path, 'STFT_DATA_FOLD_fold_1.npy'))\n",
    "labels_fold_1 = np.load(os.path.join(folder_path, 'STFT_LABELS_FOLD_fold_1.npy'))\n",
    "patients_fold_1 = np.load(os.path.join(folder_path, 'STFT_PATIENTS_FOLD_fold_1.npy'))\n",
    "\n",
    "eeg_fold_2 = np.load(os.path.join(folder_path, 'STFT_DATA_FOLD_fold_2.npy'))\n",
    "labels_fold_2 = np.load(os.path.join(folder_path, 'STFT_LABELS_FOLD_fold_2.npy'))\n",
    "patients_fold_2 = np.load(os.path.join(folder_path, 'STFT_PATIENTS_FOLD_fold_2.npy'))\n",
    "\n",
    "eeg_fold_3 = np.load(os.path.join(folder_path, 'STFT_DATA_FOLD_fold_3.npy'))\n",
    "labels_fold_3 = np.load(os.path.join(folder_path, 'STFT_LABELS_FOLD_fold_3.npy'))\n",
    "patients_fold_3 = np.load(os.path.join(folder_path, 'STFT_PATIENTS_FOLD_fold_3.npy'))\n",
    "\n",
    "eeg_fold_4 = np.load(os.path.join(folder_path, 'STFT_DATA_FOLD_fold_4.npy'))\n",
    "labels_fold_4 = np.load(os.path.join(folder_path, 'STFT_LABELS_FOLD_fold_4.npy'))\n",
    "patients_fold_4 = np.load(os.path.join(folder_path, 'STFT_PATIENTS_FOLD_fold_4.npy'))\n",
    "\n",
    "eeg_fold_5 = np.load(os.path.join(folder_path, 'STFT_DATA_FOLD_fold_5.npy'))\n",
    "labels_fold_5 = np.load(os.path.join(folder_path, 'STFT_LABELS_FOLD_fold_5.npy'))\n",
    "patients_fold_5 = np.load(os.path.join(folder_path, 'STFT_PATIENTS_FOLD_fold_5.npy'))\n",
    "\n",
    "eeg_folds = [eeg_fold_1, eeg_fold_2, eeg_fold_3, eeg_fold_4, eeg_fold_5]\n",
    "labels_folds = [labels_fold_1, labels_fold_2, labels_fold_3, labels_fold_4, labels_fold_5]\n",
    "patients_folds = [patients_fold_1, patients_fold_2, patients_fold_3, patients_fold_4, patients_fold_5]\n",
    "\n",
    "for i in range(len(eeg_folds)):\n",
    "    eeg_folds[i] = eeg_folds[i].astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9831e02",
   "metadata": {
    "id": "f9831e02"
   },
   "outputs": [],
   "source": [
    "def data_balancer(data, labels, factor):\n",
    "    # Count the number of samples in each class\n",
    "    num_class_0 = np.sum(labels == 0)\n",
    "    num_class_1 = np.sum(labels == 1)\n",
    "    num_class_2 = np.sum(labels == 2)\n",
    "\n",
    "    # Find the minimum number of samples across all classes\n",
    "    min_samples = min(num_class_0, num_class_1, num_class_2)\n",
    "\n",
    "    # Calculate the number of samples to take from each class\n",
    "    samples_per_class = min_samples // factor\n",
    "\n",
    "    # Randomly sample 'samples_per_class' from each class\n",
    "    class_0_indices = np.random.choice(np.where(labels == 0)[0], samples_per_class, replace=False)\n",
    "    class_1_indices = np.random.choice(np.where(labels == 1)[0], samples_per_class, replace=False)\n",
    "    class_2_indices = np.random.choice(np.where(labels == 2)[0], samples_per_class, replace=False)\n",
    "\n",
    "    # Combine balanced indices\n",
    "    balanced_indices = np.concatenate((class_0_indices, class_1_indices, class_2_indices))\n",
    "\n",
    "    # Shuffle the balanced indices\n",
    "    np.random.shuffle(balanced_indices)\n",
    "\n",
    "    # Create balanced training data and labels\n",
    "    balanced_data = data[balanced_indices]\n",
    "    balanced_labels = labels[balanced_indices]\n",
    "\n",
    "    return balanced_data, balanced_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0497bd4e",
   "metadata": {
    "id": "0497bd4e"
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5):\n",
    "        \"\"\"\n",
    "        Initializes the early stopping mechanism based on divergence detection.\n",
    "\n",
    "        Args:\n",
    "            patience (int): Number of consecutive epochs with increasing validation loss\n",
    "                            before stopping.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "        self.best_model_state = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        \"\"\"\n",
    "        Checks if the validation loss is diverging and updates the state accordingly.\n",
    "\n",
    "        Args:\n",
    "            val_loss (float): Current epoch's validation loss.\n",
    "            model (torch.nn.Module): The model being trained.\n",
    "        \"\"\"\n",
    "        if self.best_loss is None or val_loss < self.best_loss:\n",
    "            # Improvement detected\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model_state = model.state_dict()\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            # Validation loss increased\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                print(f\"Divergence detected. Stopping training after {self.counter} epochs.\")\n",
    "                self.early_stop = True\n",
    "\n",
    "    def load_best_model(self, model):\n",
    "        \"\"\"\n",
    "        Restores the model to the state with the lowest validation loss.\n",
    "\n",
    "        Args:\n",
    "            model (torch.nn.Module): The model to restore.\n",
    "        \"\"\"\n",
    "        model.load_state_dict(self.best_model_state)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04c9bba8",
   "metadata": {
    "id": "04c9bba8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "debug_mode_flag = False\n",
    "# Set the device to GPU if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "debug_mode_flag = False\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LstmAttention(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout=0.3):\n",
    "        super(LstmAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=hidden_size * 2, num_heads=2, batch_first=True)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "        self.act = nn.Sigmoid() if num_classes == 1 else nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, input_size)\n",
    "        lstm_out, _ = self.lstm(x)  # (batch, seq, hidden*2)\n",
    "\n",
    "        # Apply attention: Q=K=V=lstm_out\n",
    "        attn_out, _ = self.attention(lstm_out, lstm_out, lstm_out)  # (batch, seq, hidden*2)\n",
    "\n",
    "        # Aggregate via mean pooling or use only last time step\n",
    "        pooled = attn_out.mean(dim=1)  # (batch, hidden*2)\n",
    "\n",
    "        out = self.dropout(pooled)\n",
    "        out = self.fc(out)\n",
    "        return self.act(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb53c211",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 118,
     "status": "ok",
     "timestamp": 1747776598293,
     "user": {
      "displayName": "Ryan Gabriel",
      "userId": "15533354653069607353"
     },
     "user_tz": -330
    },
    "id": "eb53c211",
    "outputId": "ba1ef9f9-c6c9-48e4-d709-e615639718b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([8, 224, 672])\n",
      "Output shape: torch.Size([8, 3])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# For spectrogram shape (224, 224, 3) reshaped to (224, 672)\n",
    "# 224 time steps, 672 features per time step\n",
    "input_size = 224 * 3  # 672\n",
    "hidden_size = 128\n",
    "num_layers = 1\n",
    "num_classes = 3\n",
    "\n",
    "model = LstmAttention(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, num_classes=num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# Test with correct input dimensions: (batch_size, seq_len, input_size)\n",
    "# We need to reshape our data from (batch, 224, 224, 3) to (batch, 224, 672)\n",
    "x = torch.randn(8, 224, 672).to(device)  # batch_size=8, seq_len=224, features=672\n",
    "output = model(x)\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")  # Expect: (8, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "psh7bqJLmK1u",
   "metadata": {
    "id": "psh7bqJLmK1u"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# pca = sklearn.decomposition.PCA(3)\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "fold_indices = np.arange(5)\n",
    "fold_indices = np.random.permutation(fold_indices)\n",
    "val_fold_indices = np.roll(fold_indices, 1)\n",
    "\n",
    "input_shape = 224*3\n",
    "num_classes = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f665b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a5f665b8",
    "outputId": "72b7174f-1d92-4492-8392-ccccf613c130"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\cudaenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-06-03 22:18:57,504] A new study created in memory with name: no-name-caa4473a-a634-4667-b7c7-156fed3d9ff1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:0 hidden_size: 32, num_layers: 2, learning_rate: 0.0017072686796075181, optimizer_name: Adam, weight_decay: 6.591950956140822e-06, batch_size: 10, label_smoothing: 0.3, factor: 1trial:1 hidden_size: 32, num_layers: 4, learning_rate: 5.4790368880734364e-06, optimizer_name: Adam, weight_decay: 0.00018226544397252048, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "trial:2 hidden_size: 64, num_layers: 4, learning_rate: 1.6372142086864276e-05, optimizer_name: Adam, weight_decay: 8.975823001977633e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:20:41,517] Trial 2 finished with value: 0.5974108961779273 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.1, 'learning_rate': 1.6372142086864276e-05, 'weight_decay': 8.975823001977633e-06, 'batch_size': 16}. Best is trial 2 with value: 0.5974108961779273.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2: Test Accuracy = 0.5974\n",
      "trial:3 hidden_size: 1024, num_layers: 2, learning_rate: 7.877736275948196e-08, optimizer_name: Adam, weight_decay: 0.0005039381270787882, batch_size: 10, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:20:43,043] Trial 1 finished with value: 0.3347701149425288 and parameters: {'hidden_size': 32, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 5.4790368880734364e-06, 'weight_decay': 0.00018226544397252048, 'batch_size': 16}. Best is trial 2 with value: 0.5974108961779273.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1: Test Accuracy = 0.3348\n",
      "trial:4 hidden_size: 1024, num_layers: 2, learning_rate: 0.0003497535077250173, optimizer_name: Adam, weight_decay: 5.434835805727326e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Trial 0: Test Accuracy = 0.6312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:20:43,632] Trial 0 finished with value: 0.6311725072423138 and parameters: {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.30000000000000004, 'learning_rate': 0.0017072686796075181, 'weight_decay': 6.591950956140822e-06, 'batch_size': 10}. Best is trial 0 with value: 0.6311725072423138.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:5 hidden_size: 1024, num_layers: 2, learning_rate: 8.213520243623387e-08, optimizer_name: Adam, weight_decay: 5.2045909155153546e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 21\n",
      "Trial 4: Test Accuracy = 0.5577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:33:20,744] Trial 4 finished with value: 0.557734323894963 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.4, 'learning_rate': 0.0003497535077250173, 'weight_decay': 5.434835805727326e-05, 'batch_size': 32}. Best is trial 0 with value: 0.6311725072423138.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:6 hidden_size: 1024, num_layers: 2, learning_rate: 0.00029289886801258936, optimizer_name: Adam, weight_decay: 0.0003187968756902681, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Trial 5: Test Accuracy = 0.5580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:40:44,702] Trial 5 finished with value: 0.5579581347537613 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.2, 'learning_rate': 8.213520243623387e-08, 'weight_decay': 5.2045909155153546e-05, 'batch_size': 16}. Best is trial 0 with value: 0.6311725072423138.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:7 hidden_size: 64, num_layers: 3, learning_rate: 7.3306597323752085e-06, optimizer_name: Adam, weight_decay: 7.131675617972682e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:44:01,636] Trial 6 finished with value: 0.3620689655172414 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.1, 'learning_rate': 0.00029289886801258936, 'weight_decay': 0.0003187968756902681, 'batch_size': 16}. Best is trial 0 with value: 0.6311725072423138.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6: Test Accuracy = 0.3621\n",
      "trial:8 hidden_size: 32, num_layers: 2, learning_rate: 1.0276360828245037e-06, optimizer_name: Adam, weight_decay: 1.7720921233414066e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Trial 7: Test Accuracy = 0.5561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:45:02,267] Trial 7 finished with value: 0.5560825156527428 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.1, 'learning_rate': 7.3306597323752085e-06, 'weight_decay': 7.131675617972682e-05, 'batch_size': 32}. Best is trial 0 with value: 0.6311725072423138.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:9 hidden_size: 1024, num_layers: 2, learning_rate: 3.7965881546261205e-08, optimizer_name: Adam, weight_decay: 0.00033685005010156453, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Trial 3: Test Accuracy = 0.4956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:46:34,655] Trial 3 finished with value: 0.49561274647229236 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 7.877736275948196e-08, 'weight_decay': 0.0005039381270787882, 'batch_size': 10}. Best is trial 0 with value: 0.6311725072423138.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:10 hidden_size: 64, num_layers: 2, learning_rate: 0.004436348192582233, optimizer_name: Adam, weight_decay: 1.5654196641684777e-05, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Trial 8: Test Accuracy = 0.3801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:49:17,344] Trial 8 finished with value: 0.3801291468087095 and parameters: {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.1, 'learning_rate': 1.0276360828245037e-06, 'weight_decay': 1.7720921233414066e-06, 'batch_size': 16}. Best is trial 0 with value: 0.6311725072423138.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:11 hidden_size: 32, num_layers: 1, learning_rate: 2.3019712555802252e-08, optimizer_name: Adam, weight_decay: 0.00022286709425447954, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:50:25,852] Trial 9 finished with value: 0.3589691617605831 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.2, 'learning_rate': 3.7965881546261205e-08, 'weight_decay': 0.00033685005010156453, 'batch_size': 10}. Best is trial 0 with value: 0.6311725072423138.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9: Test Accuracy = 0.3590\n",
      "trial:12 hidden_size: 256, num_layers: 1, learning_rate: 0.005734124955062117, optimizer_name: Adam, weight_decay: 7.552829453839455e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:50:30,921] Trial 10 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.1, 'learning_rate': 0.004436348192582233, 'weight_decay': 1.5654196641684777e-05, 'batch_size': 10}. Best is trial 0 with value: 0.6311725072423138.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10: Test Accuracy = 0.3333\n",
      "trial:13 hidden_size: 128, num_layers: 4, learning_rate: 0.00017081272204490827, optimizer_name: Adam, weight_decay: 6.023247749022524e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:50:52,889] Trial 11 finished with value: 0.37589159891598917 and parameters: {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.5, 'learning_rate': 2.3019712555802252e-08, 'weight_decay': 0.00022286709425447954, 'batch_size': 10}. Best is trial 0 with value: 0.6311725072423138.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11: Test Accuracy = 0.3759\n",
      "trial:14 hidden_size: 128, num_layers: 4, learning_rate: 0.00013608058235917592, optimizer_name: Adam, weight_decay: 6.1159054231276394e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:51:59,515] Trial 13 finished with value: 0.6149367348845902 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.00017081272204490827, 'weight_decay': 6.023247749022524e-06, 'batch_size': 10}. Best is trial 0 with value: 0.6311725072423138.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 13: Test Accuracy = 0.6149\n",
      "trial:15 hidden_size: 128, num_layers: 4, learning_rate: 0.006848254614045695, optimizer_name: Adam, weight_decay: 3.6140455830985797e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:52:14,523] Trial 14 finished with value: 0.6472549294458462 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.00013608058235917592, 'weight_decay': 6.1159054231276394e-06, 'batch_size': 16}. Best is trial 14 with value: 0.6472549294458462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14: Test Accuracy = 0.6473\n",
      "trial:16 hidden_size: 512, num_layers: 3, learning_rate: 0.005451774791408278, optimizer_name: Adam, weight_decay: 2.045305679521162e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:52:29,549] Trial 12 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 256, 'num_layers': 1, 'dropout': 0.4, 'learning_rate': 0.005734124955062117, 'weight_decay': 7.552829453839455e-06, 'batch_size': 10}. Best is trial 14 with value: 0.6472549294458462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12: Test Accuracy = 0.3333\n",
      "trial:17 hidden_size: 128, num_layers: 3, learning_rate: 0.0010369495774251026, optimizer_name: Adam, weight_decay: 1.9057043042034715e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n",
      "Trial 15: Test Accuracy = 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:53:07,924] Trial 15 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.006848254614045695, 'weight_decay': 3.6140455830985797e-06, 'batch_size': 10}. Best is trial 14 with value: 0.6472549294458462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:18 hidden_size: 512, num_layers: 3, learning_rate: 0.0008942489216756236, optimizer_name: Adam, weight_decay: 1.0054356811101351e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:54:16,339] Trial 16 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 0.005451774791408278, 'weight_decay': 2.045305679521162e-06, 'batch_size': 32}. Best is trial 14 with value: 0.6472549294458462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 16: Test Accuracy = 0.3333\n",
      "trial:19 hidden_size: 128, num_layers: 4, learning_rate: 8.74686518971228e-05, optimizer_name: Adam, weight_decay: 2.1740839232801422e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:54:45,603] Trial 17 finished with value: 0.6063612746472292 and parameters: {'hidden_size': 128, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 0.0010369495774251026, 'weight_decay': 1.9057043042034715e-06, 'batch_size': 32}. Best is trial 14 with value: 0.6472549294458462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 17: Test Accuracy = 0.6064\n",
      "trial:20 hidden_size: 512, num_layers: 4, learning_rate: 5.471751337544971e-05, optimizer_name: Adam, weight_decay: 1.632681027443046e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:56:44,776] Trial 18 finished with value: 0.5586998411363424 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 0.0008942489216756236, 'weight_decay': 1.0054356811101351e-06, 'batch_size': 32}. Best is trial 14 with value: 0.6472549294458462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 18: Test Accuracy = 0.5587\n",
      "trial:21 hidden_size: 256, num_layers: 4, learning_rate: 7.026846742741612e-05, optimizer_name: Adam, weight_decay: 1.4178574522182125e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 22\n",
      "Trial 19: Test Accuracy = 0.6487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:57:40,377] Trial 19 finished with value: 0.6486876927389964 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 8.74686518971228e-05, 'weight_decay': 2.1740839232801422e-05, 'batch_size': 16}. Best is trial 19 with value: 0.6486876927389964.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:22 hidden_size: 128, num_layers: 4, learning_rate: 4.279999024805935e-05, optimizer_name: Adam, weight_decay: 2.1183319942342697e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:59:14,300] Trial 20 finished with value: 0.45741379310344826 and parameters: {'hidden_size': 512, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 5.471751337544971e-05, 'weight_decay': 1.632681027443046e-05, 'batch_size': 16}. Best is trial 19 with value: 0.6486876927389964.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20: Test Accuracy = 0.4574\n",
      "trial:23 hidden_size: 128, num_layers: 4, learning_rate: 8.699852332987201e-05, optimizer_name: Adam, weight_decay: 2.396729840831087e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:59:45,057] Trial 21 finished with value: 0.6244436034015513 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 7.026846742741612e-05, 'weight_decay': 1.4178574522182125e-05, 'batch_size': 16}. Best is trial 19 with value: 0.6486876927389964.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 21: Test Accuracy = 0.6244\n",
      "trial:24 hidden_size: 128, num_layers: 4, learning_rate: 0.00129532492481726, optimizer_name: Adam, weight_decay: 2.82326352319412e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:59:59,319] Trial 22 finished with value: 0.6149805625642464 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 4.279999024805935e-05, 'weight_decay': 2.1183319942342697e-05, 'batch_size': 16}. Best is trial 19 with value: 0.6486876927389964.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 22: Test Accuracy = 0.6150\n",
      "trial:25 hidden_size: 128, num_layers: 4, learning_rate: 1.7154608566633323e-06, optimizer_name: Adam, weight_decay: 4.292635913555638e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 12\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 23:00:34,752] Trial 24 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00129532492481726, 'weight_decay': 2.82326352319412e-05, 'batch_size': 16}. Best is trial 19 with value: 0.6486876927389964.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 24: Test Accuracy = 0.3333\n",
      "trial:26 hidden_size: 32, num_layers: 1, learning_rate: 1.0965686121081143e-06, optimizer_name: Adam, weight_decay: 4.730693728328771e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 23:00:35,449] Trial 23 finished with value: 0.6407112419400057 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 8.699852332987201e-05, 'weight_decay': 2.396729840831087e-05, 'batch_size': 16}. Best is trial 19 with value: 0.6486876927389964.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 23: Test Accuracy = 0.6407\n",
      "trial:27 hidden_size: 128, num_layers: 4, learning_rate: 2.1959731410702454e-06, optimizer_name: Adam, weight_decay: 0.00011225660852951338, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 23:00:45,645] Trial 25 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 1.7154608566633323e-06, 'weight_decay': 4.292635913555638e-06, 'batch_size': 16}. Best is trial 19 with value: 0.6486876927389964.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25: Test Accuracy = 0.3333\n",
      "trial:28 hidden_size: 128, num_layers: 4, learning_rate: 2.120896824382109e-05, optimizer_name: Adam, weight_decay: 0.00011862321356098623, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n",
      "Trial 26: Test Accuracy = 0.3072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 23:01:16,188] Trial 26 finished with value: 0.3072421269040277 and parameters: {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.30000000000000004, 'learning_rate': 1.0965686121081143e-06, 'weight_decay': 4.730693728328771e-06, 'batch_size': 16}. Best is trial 19 with value: 0.6486876927389964.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:29 hidden_size: 128, num_layers: 4, learning_rate: 2.314766740516948e-05, optimizer_name: Adam, weight_decay: 0.00010839810392912045, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 23:02:25,320] Trial 27 finished with value: 0.3400266330249509 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 2.1959731410702454e-06, 'weight_decay': 0.00011225660852951338, 'batch_size': 16}. Best is trial 19 with value: 0.6486876927389964.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 27: Test Accuracy = 0.3400\n",
      "trial:30 hidden_size: 128, num_layers: 4, learning_rate: 1.6575369527510296e-05, optimizer_name: Adam, weight_decay: 3.559133551982077e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 23:02:35,490] Trial 28 finished with value: 0.5697380618633773 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 2.120896824382109e-05, 'weight_decay': 0.00011862321356098623, 'batch_size': 16}. Best is trial 19 with value: 0.6486876927389964.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 28: Test Accuracy = 0.5697\n",
      "trial:31 hidden_size: 128, num_layers: 4, learning_rate: 0.0001517848713006729, optimizer_name: Adam, weight_decay: 3.4389777830053566e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 23:02:43,972] Trial 29 finished with value: 0.6128489860760676 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 2.314766740516948e-05, 'weight_decay': 0.00010839810392912045, 'batch_size': 16}. Best is trial 19 with value: 0.6486876927389964.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 29: Test Accuracy = 0.6128\n",
      "trial:32 hidden_size: 128, num_layers: 4, learning_rate: 0.0001406884513893709, optimizer_name: Adam, weight_decay: 4.075266539637184e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 23:03:46,911] Trial 32 finished with value: 0.5133122138117933 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 0.0001406884513893709, 'weight_decay': 4.075266539637184e-05, 'batch_size': 16}. Best is trial 19 with value: 0.6486876927389964.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 32: Test Accuracy = 0.5133\n",
      "trial:33 hidden_size: 32, num_layers: 4, learning_rate: 0.001992365308528003, optimizer_name: Adam, weight_decay: 9.888591045538583e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 23:03:56,625] Trial 31 finished with value: 0.6408431922250256 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 0.0001517848713006729, 'weight_decay': 3.4389777830053566e-05, 'batch_size': 16}. Best is trial 19 with value: 0.6486876927389964.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 31: Test Accuracy = 0.6408\n",
      "trial:34 hidden_size: 128, num_layers: 4, learning_rate: 0.0005093398405987803, optimizer_name: Adam, weight_decay: 2.873745696147729e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 23:04:15,970] Trial 30 finished with value: 0.5957484347257266 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 1.6575369527510296e-05, 'weight_decay': 3.559133551982077e-05, 'batch_size': 16}. Best is trial 19 with value: 0.6486876927389964.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30: Test Accuracy = 0.5957\n",
      "trial:35 hidden_size: 128, num_layers: 4, learning_rate: 0.0003858427029795065, optimizer_name: Adam, weight_decay: 9.46488385293209e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 23:04:32,229] Trial 33 finished with value: 0.49403485655546203 and parameters: {'hidden_size': 32, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.001992365308528003, 'weight_decay': 9.888591045538583e-06, 'batch_size': 16}. Best is trial 19 with value: 0.6486876927389964.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 33: Test Accuracy = 0.4940\n",
      "trial:36 hidden_size: 128, num_layers: 4, learning_rate: 0.000354951777715869, optimizer_name: Adam, weight_decay: 2.4595061196631547e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 23:05:05,809] Trial 34 finished with value: 0.47845126623680034 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 0.0005093398405987803, 'weight_decay': 2.873745696147729e-05, 'batch_size': 16}. Best is trial 19 with value: 0.6486876927389964.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 34: Test Accuracy = 0.4785\n",
      "trial:37 hidden_size: 128, num_layers: 4, learning_rate: 0.00011534340069248928, optimizer_name: Adam, weight_decay: 1.1095997399483528e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 23:05:42,356] Trial 36 finished with value: 0.6796114381833473 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 0.000354951777715869, 'weight_decay': 2.4595061196631547e-05, 'batch_size': 16}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 36: Test Accuracy = 0.6796\n",
      "trial:38 hidden_size: 128, num_layers: 4, learning_rate: 0.0002129058627688505, optimizer_name: Adam, weight_decay: 1.0780595134109433e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 23:06:07,052] Trial 35 finished with value: 0.6129343986543314 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 0.0003858427029795065, 'weight_decay': 9.46488385293209e-06, 'batch_size': 16}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 35: Test Accuracy = 0.6129\n",
      "trial:39 hidden_size: 256, num_layers: 1, learning_rate: 0.00016909154465204545, optimizer_name: Adam, weight_decay: 6.455375561117768e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 23:06:39,789] Trial 38 finished with value: 0.6343399682272685 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 0.0002129058627688505, 'weight_decay': 1.0780595134109433e-05, 'batch_size': 16}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 38: Test Accuracy = 0.6343\n",
      "trial:40 hidden_size: 256, num_layers: 1, learning_rate: 0.00011260226090835876, optimizer_name: Adam, weight_decay: 5.314591226090502e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 23:07:05,907] Trial 37 finished with value: 0.5826200355107 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 0.00011534340069248928, 'weight_decay': 1.1095997399483528e-05, 'batch_size': 16}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 37: Test Accuracy = 0.5826\n",
      "trial:41 hidden_size: 256, num_layers: 1, learning_rate: 6.341925781038549e-06, optimizer_name: Adam, weight_decay: 7.525881382743296e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 23:08:07,836] Trial 39 finished with value: 0.6341068124474348 and parameters: {'hidden_size': 256, 'num_layers': 1, 'dropout': 0.30000000000000004, 'learning_rate': 0.00016909154465204545, 'weight_decay': 6.455375561117768e-05, 'batch_size': 16}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 39: Test Accuracy = 0.6341\n",
      "trial:42 hidden_size: 64, num_layers: 4, learning_rate: 0.002556047049614634, optimizer_name: Adam, weight_decay: 4.707524826308565e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 23:08:52,336] Trial 42 finished with value: 0.5087258200168209 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 0.002556047049614634, 'weight_decay': 4.707524826308565e-05, 'batch_size': 32}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 42: Test Accuracy = 0.5087\n",
      "trial:43 hidden_size: 128, num_layers: 4, learning_rate: 4.0278992379495585e-05, optimizer_name: Adam, weight_decay: 2.250388223971871e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 23:09:02,844] Trial 40 finished with value: 0.5215183627698345 and parameters: {'hidden_size': 256, 'num_layers': 1, 'dropout': 0.30000000000000004, 'learning_rate': 0.00011260226090835876, 'weight_decay': 5.314591226090502e-05, 'batch_size': 16}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 40: Test Accuracy = 0.5215\n",
      "trial:44 hidden_size: 128, num_layers: 4, learning_rate: 3.874200201587248e-05, optimizer_name: Adam, weight_decay: 2.2056393843305567e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 23:09:31,925] Trial 41 finished with value: 0.6177294645360247 and parameters: {'hidden_size': 256, 'num_layers': 1, 'dropout': 0.30000000000000004, 'learning_rate': 6.341925781038549e-06, 'weight_decay': 7.525881382743296e-05, 'batch_size': 16}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 41: Test Accuracy = 0.6177\n",
      "trial:45 hidden_size: 128, num_layers: 4, learning_rate: 3.6477264637030093e-05, optimizer_name: Adam, weight_decay: 3.034847128196134e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 23:10:11,637] Trial 44 finished with value: 0.5644552845528455 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 3.874200201587248e-05, 'weight_decay': 2.2056393843305567e-05, 'batch_size': 16}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 44: Test Accuracy = 0.5645\n",
      "trial:46 hidden_size: 1024, num_layers: 4, learning_rate: 0.0006413474196361755, optimizer_name: Adam, weight_decay: 2.4271508514003003e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 21\n",
      "Trial 43: Test Accuracy = 0.5870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 23:10:40,615] Trial 43 finished with value: 0.586965984487431 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 4.0278992379495585e-05, 'weight_decay': 2.250388223971871e-05, 'batch_size': 16}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:47 hidden_size: 1024, num_layers: 4, learning_rate: 0.0005497693495712762, optimizer_name: Adam, weight_decay: 3.263815347962499e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 23:26:21,807] Trial 45 finished with value: 0.575082328754322 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 3.6477264637030093e-05, 'weight_decay': 3.034847128196134e-05, 'batch_size': 16}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 45: Test Accuracy = 0.5751\n",
      "trial:48 hidden_size: 1024, num_layers: 2, learning_rate: 0.0004737409542207513, optimizer_name: Adam, weight_decay: 0.0008553931756326743, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 14\n",
      "Trial 46: Test Accuracy = 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:22:46,047] Trial 46 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 0.0006413474196361755, 'weight_decay': 2.4271508514003003e-05, 'batch_size': 16}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:49 hidden_size: 128, num_layers: 2, learning_rate: 0.0003313593754777599, optimizer_name: Adam, weight_decay: 3.028512004676242e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 12\n",
      "Trial 48: Test Accuracy = 0.5256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:32:47,688] Trial 48 finished with value: 0.5255942435286421 and parameters: {'hidden_size': 1024, 'num_layers': 2, 'dropout': 0.2, 'learning_rate': 0.0004737409542207513, 'weight_decay': 0.0008553931756326743, 'batch_size': 16}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:50 hidden_size: 64, num_layers: 3, learning_rate: 7.625612708009202e-05, optimizer_name: Adam, weight_decay: 6.359843766195179e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 18\n",
      "Trial 49: Test Accuracy = 0.6318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:34:38,382] Trial 49 finished with value: 0.6318095505092982 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.2, 'learning_rate': 0.0003313593754777599, 'weight_decay': 3.028512004676242e-06, 'batch_size': 16}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:51 hidden_size: 64, num_layers: 3, learning_rate: 2.937547596475475e-07, optimizer_name: Adam, weight_decay: 6.647064767130685e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:37:08,980] Trial 47 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 0.0005497693495712762, 'weight_decay': 3.263815347962499e-05, 'batch_size': 16}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 47: Test Accuracy = 0.3333\n",
      "trial:52 hidden_size: 64, num_layers: 3, learning_rate: 8.645228330675134e-05, optimizer_name: Adam, weight_decay: 6.464239371082903e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 28\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:38:18,707] Trial 50 finished with value: 0.5814552845528455 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 7.625612708009202e-05, 'weight_decay': 6.359843766195179e-06, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50: Test Accuracy = 0.5815\n",
      "Trial 52: Test Accuracy = 0.6523\n",
      "trial:53 hidden_size: 128, num_layers: 4, learning_rate: 0.00020747854579194954, optimizer_name: Adam, weight_decay: 1.3160039433125654e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:38:18,750] Trial 52 finished with value: 0.652276235865807 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 8.645228330675134e-05, 'weight_decay': 6.464239371082903e-06, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:54 hidden_size: 64, num_layers: 3, learning_rate: 8.590834459471299e-05, optimizer_name: Adam, weight_decay: 1.5388111459032937e-05, batch_size: 10, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:38:19,508] Trial 51 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.4, 'learning_rate': 2.937547596475475e-07, 'weight_decay': 6.647064767130685e-06, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 51: Test Accuracy = 0.3333\n",
      "trial:55 hidden_size: 64, num_layers: 3, learning_rate: 0.0002371304682733857, optimizer_name: Adam, weight_decay: 1.7368586223581065e-05, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:39:17,998] Trial 55 finished with value: 0.5262580132697878 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 0.0002371304682733857, 'weight_decay': 1.7368586223581065e-05, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 55: Test Accuracy = 0.5263\n",
      "trial:56 hidden_size: 64, num_layers: 3, learning_rate: 9.689467181109014e-06, optimizer_name: Adam, weight_decay: 2.989123734812484e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:39:35,959] Trial 54 finished with value: 0.6060828894495841 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 8.590834459471299e-05, 'weight_decay': 1.5388111459032937e-05, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 54: Test Accuracy = 0.6061\n",
      "trial:57 hidden_size: 512, num_layers: 3, learning_rate: 1.0795319176202706e-05, optimizer_name: Adam, weight_decay: 2.842406134253264e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 27\n",
      "Trial 53: Test Accuracy = 0.6465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:40:19,008] Trial 53 finished with value: 0.6464961218577703 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 0.00020747854579194954, 'weight_decay': 1.3160039433125654e-05, 'batch_size': 16}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:58 hidden_size: 512, num_layers: 3, learning_rate: 1.3253140617916108e-05, optimizer_name: Adam, weight_decay: 1.2743781829747891e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:42:39,540] Trial 57 finished with value: 0.6275032239977572 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 1.0795319176202706e-05, 'weight_decay': 2.842406134253264e-06, 'batch_size': 32}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 57: Test Accuracy = 0.6275\n",
      "trial:59 hidden_size: 128, num_layers: 3, learning_rate: 3.617062856582286e-06, optimizer_name: Adam, weight_decay: 1.2144991829701403e-05, batch_size: 10, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:42:41,998] Trial 56 finished with value: 0.5578319783197833 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 9.689467181109014e-06, 'weight_decay': 2.989123734812484e-06, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 56: Test Accuracy = 0.5578\n",
      "trial:60 hidden_size: 128, num_layers: 4, learning_rate: 0.0027042000706698826, optimizer_name: Adam, weight_decay: 4.72364905842374e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 20\n",
      "Trial 58: Test Accuracy = 0.6330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:43:03,852] Trial 58 finished with value: 0.6330292496028408 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 1.3253140617916108e-05, 'weight_decay': 1.2743781829747891e-05, 'batch_size': 32}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:61 hidden_size: 128, num_layers: 4, learning_rate: 0.0002715922701969456, optimizer_name: Adam, weight_decay: 7.611109323564164e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:43:33,924] Trial 60 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.0027042000706698826, 'weight_decay': 4.72364905842374e-06, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 60: Test Accuracy = 0.3333\n",
      "trial:62 hidden_size: 32, num_layers: 4, learning_rate: 0.0002209120475675084, optimizer_name: Adam, weight_decay: 7.145779838973686e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:44:30,023] Trial 61 finished with value: 0.6778531912905336 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.0002715922701969456, 'weight_decay': 7.611109323564164e-06, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 61: Test Accuracy = 0.6779\n",
      "trial:63 hidden_size: 128, num_layers: 4, learning_rate: 0.0009296370768553465, optimizer_name: Adam, weight_decay: 6.79639808205762e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:44:44,541] Trial 59 finished with value: 0.5406256424633212 and parameters: {'hidden_size': 128, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 3.617062856582286e-06, 'weight_decay': 1.2144991829701403e-05, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 59: Test Accuracy = 0.5406\n",
      "trial:64 hidden_size: 128, num_layers: 4, learning_rate: 0.0010474039391791833, optimizer_name: Adam, weight_decay: 8.150671924379531e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 21\n",
      "Trial 62: Test Accuracy = 0.5090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:44:59,307] Trial 62 finished with value: 0.508962807214279 and parameters: {'hidden_size': 32, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 0.0002209120475675084, 'weight_decay': 7.145779838973686e-06, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:65 hidden_size: 128, num_layers: 4, learning_rate: 0.0009863404712525277, optimizer_name: Adam, weight_decay: 8.080180719462717e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:45:37,076] Trial 63 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.0009296370768553465, 'weight_decay': 6.79639808205762e-06, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 63: Test Accuracy = 0.3333\n",
      "trial:66 hidden_size: 128, num_layers: 4, learning_rate: 0.0002661835077894434, optimizer_name: Adam, weight_decay: 8.462079148381886e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:45:58,705] Trial 65 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.0009863404712525277, 'weight_decay': 8.080180719462717e-06, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 65: Test Accuracy = 0.3333\n",
      "trial:67 hidden_size: 128, num_layers: 4, learning_rate: 0.00029203559715016005, optimizer_name: Adam, weight_decay: 1.823867186586222e-05, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 18\n",
      "Trial 64: Test Accuracy = 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:46:05,618] Trial 64 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.0010474039391791833, 'weight_decay': 8.150671924379531e-06, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:68 hidden_size: 128, num_layers: 4, learning_rate: 0.00032668469966269355, optimizer_name: Adam, weight_decay: 1.8510190598732588e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:46:51,901] Trial 66 finished with value: 0.6634806092888516 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.0002661835077894434, 'weight_decay': 8.462079148381886e-06, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 66: Test Accuracy = 0.6635\n",
      "trial:69 hidden_size: 128, num_layers: 2, learning_rate: 0.00031894779289627986, optimizer_name: Adam, weight_decay: 5.579947602322342e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:47:21,448] Trial 67 finished with value: 0.5530203719278572 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00029203559715016005, 'weight_decay': 1.823867186586222e-05, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 67: Test Accuracy = 0.5530\n",
      "trial:70 hidden_size: 128, num_layers: 2, learning_rate: 2.2486867216824943e-05, optimizer_name: Adam, weight_decay: 5.244080623471741e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 22\n",
      "Trial 68: Test Accuracy = 0.6564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:47:35,069] Trial 68 finished with value: 0.6564093075413512 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00032668469966269355, 'weight_decay': 1.8510190598732588e-05, 'batch_size': 16}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:71 hidden_size: 128, num_layers: 4, learning_rate: 0.0007389672905383629, optimizer_name: Adam, weight_decay: 5.142580740319233e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:48:40,431] Trial 69 finished with value: 0.6599081394262218 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.2, 'learning_rate': 0.00031894779289627986, 'weight_decay': 5.579947602322342e-06, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 69: Test Accuracy = 0.6599\n",
      "trial:72 hidden_size: 128, num_layers: 2, learning_rate: 1.1461771992496524e-08, optimizer_name: Adam, weight_decay: 5.10196636724772e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Trial 70: Test Accuracy = 0.6479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:49:21,053] Trial 70 finished with value: 0.647899168302028 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.30000000000000004, 'learning_rate': 2.2486867216824943e-05, 'weight_decay': 5.244080623471741e-06, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:73 hidden_size: 128, num_layers: 2, learning_rate: 2.8104181744528112e-05, optimizer_name: Adam, weight_decay: 5.194616770424561e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:49:27,938] Trial 71 finished with value: 0.4880611157835717 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.1, 'learning_rate': 0.0007389672905383629, 'weight_decay': 5.142580740319233e-06, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 71: Test Accuracy = 0.4881\n",
      "trial:74 hidden_size: 128, num_layers: 2, learning_rate: 5.304321425150978e-05, optimizer_name: Adam, weight_decay: 3.575414396504256e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:50:31,150] Trial 72 finished with value: 0.34146341463414637 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.1, 'learning_rate': 1.1461771992496524e-08, 'weight_decay': 5.10196636724772e-06, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 72: Test Accuracy = 0.3415\n",
      "trial:75 hidden_size: 128, num_layers: 2, learning_rate: 2.4966462420956674e-05, optimizer_name: Adam, weight_decay: 3.939293365535001e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:50:52,029] Trial 73 finished with value: 0.5834589290720493 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.1, 'learning_rate': 2.8104181744528112e-05, 'weight_decay': 5.194616770424561e-06, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 73: Test Accuracy = 0.5835\n",
      "trial:76 hidden_size: 128, num_layers: 2, learning_rate: 5.2466721439902334e-05, optimizer_name: Adam, weight_decay: 3.6344297328961843e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:51:12,859] Trial 74 finished with value: 0.5518550602747406 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.2, 'learning_rate': 5.304321425150978e-05, 'weight_decay': 3.575414396504256e-06, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 74: Test Accuracy = 0.5519\n",
      "trial:77 hidden_size: 32, num_layers: 2, learning_rate: 0.009927307071241013, optimizer_name: Adam, weight_decay: 4.051255844898238e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:51:46,824] Trial 75 finished with value: 0.5876501261564341 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.2, 'learning_rate': 2.4966462420956674e-05, 'weight_decay': 3.939293365535001e-06, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 75: Test Accuracy = 0.5877\n",
      "trial:78 hidden_size: 64, num_layers: 2, learning_rate: 6.554335439396766e-05, optimizer_name: Adam, weight_decay: 9.774010404355803e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:51:57,669] Trial 76 finished with value: 0.6032430613961312 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.2, 'learning_rate': 5.2466721439902334e-05, 'weight_decay': 3.6344297328961843e-06, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 76: Test Accuracy = 0.6032\n",
      "trial:79 hidden_size: 32, num_layers: 2, learning_rate: 0.0003417982009391599, optimizer_name: Adam, weight_decay: 1.4101591428992848e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:52:09,946] Trial 77 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.2, 'learning_rate': 0.009927307071241013, 'weight_decay': 4.051255844898238e-06, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 77: Test Accuracy = 0.3333\n",
      "trial:80 hidden_size: 64, num_layers: 2, learning_rate: 0.0004029463523841323, optimizer_name: Adam, weight_decay: 2.436140993364733e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:53:07,186] Trial 78 finished with value: 0.6231449397252593 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.2, 'learning_rate': 6.554335439396766e-05, 'weight_decay': 9.774010404355803e-06, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 78: Test Accuracy = 0.6231\n",
      "trial:81 hidden_size: 128, num_layers: 2, learning_rate: 0.00011846058950483967, optimizer_name: Adam, weight_decay: 1.453386893523596e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:53:09,947] Trial 80 finished with value: 0.5267433884683674 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.30000000000000004, 'learning_rate': 0.0004029463523841323, 'weight_decay': 2.436140993364733e-06, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 80: Test Accuracy = 0.5267\n",
      "trial:82 hidden_size: 128, num_layers: 1, learning_rate: 0.00010419466663730092, optimizer_name: Adam, weight_decay: 1.9302677301039966e-05, batch_size: 10, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:53:38,558] Trial 79 finished with value: 0.6616610597140454 and parameters: {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.2, 'learning_rate': 0.0003417982009391599, 'weight_decay': 1.4101591428992848e-06, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 79: Test Accuracy = 0.6617\n",
      "trial:83 hidden_size: 32, num_layers: 2, learning_rate: 0.0001221291742744143, optimizer_name: Adam, weight_decay: 1.1899511884528965e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:54:01,387] Trial 82 finished with value: 0.5137460984954677 and parameters: {'hidden_size': 128, 'num_layers': 1, 'dropout': 0.30000000000000004, 'learning_rate': 0.00010419466663730092, 'weight_decay': 1.9302677301039966e-05, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 82: Test Accuracy = 0.5137\n",
      "trial:84 hidden_size: 32, num_layers: 2, learning_rate: 0.0016024583443545134, optimizer_name: Adam, weight_decay: 1.6503428431524911e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:54:16,543] Trial 81 finished with value: 0.6226867582468928 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.30000000000000004, 'learning_rate': 0.00011846058950483967, 'weight_decay': 1.453386893523596e-06, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 81: Test Accuracy = 0.6227\n",
      "trial:85 hidden_size: 32, num_layers: 2, learning_rate: 0.00030349657846052964, optimizer_name: Adam, weight_decay: 1.1152773593222e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:55:21,332] Trial 83 finished with value: 0.5914819175777964 and parameters: {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.2, 'learning_rate': 0.0001221291742744143, 'weight_decay': 1.1899511884528965e-06, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 83: Test Accuracy = 0.5915\n",
      "trial:86 hidden_size: 32, num_layers: 2, learning_rate: 0.001361701396541454, optimizer_name: Adam, weight_decay: 1.7018422491774877e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:55:38,222] Trial 85 finished with value: 0.5691409214092141 and parameters: {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.2, 'learning_rate': 0.00030349657846052964, 'weight_decay': 1.1152773593222e-06, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 85: Test Accuracy = 0.5691\n",
      "trial:87 hidden_size: 32, num_layers: 2, learning_rate: 0.0001735652718241561, optimizer_name: Adam, weight_decay: 1.8895833513715605e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:55:42,993] Trial 84 finished with value: 0.3794471544715447 and parameters: {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.2, 'learning_rate': 0.0016024583443545134, 'weight_decay': 1.6503428431524911e-06, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 84: Test Accuracy = 0.3794\n",
      "trial:88 hidden_size: 512, num_layers: 2, learning_rate: 0.0006531534272798274, optimizer_name: Adam, weight_decay: 4.199403527522837e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:57:07,367] Trial 86 finished with value: 0.5312024109896272 and parameters: {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.2, 'learning_rate': 0.001361701396541454, 'weight_decay': 1.7018422491774877e-06, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 86: Test Accuracy = 0.5312\n",
      "trial:89 hidden_size: 256, num_layers: 4, learning_rate: 0.00016853301773692766, optimizer_name: Adam, weight_decay: 8.700525705795718e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:58:13,563] Trial 87 finished with value: 0.624159891598916 and parameters: {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.2, 'learning_rate': 0.0001735652718241561, 'weight_decay': 1.8895833513715605e-06, 'batch_size': 10}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 87: Test Accuracy = 0.6242\n",
      "trial:90 hidden_size: 256, num_layers: 4, learning_rate: 0.00046037658937661427, optimizer_name: Adam, weight_decay: 8.389509863697752e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:58:33,468] Trial 88 finished with value: 0.5003333333333333 and parameters: {'hidden_size': 512, 'num_layers': 2, 'dropout': 0.30000000000000004, 'learning_rate': 0.0006531534272798274, 'weight_decay': 4.199403527522837e-05, 'batch_size': 32}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 88: Test Accuracy = 0.5003\n",
      "trial:91 hidden_size: 256, num_layers: 4, learning_rate: 0.00044691827447890486, optimizer_name: Adam, weight_decay: 2.3045643935975854e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 00:58:46,409] Trial 89 finished with value: 0.6209555181758715 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.00016853301773692766, 'weight_decay': 8.700525705795718e-06, 'batch_size': 32}. Best is trial 36 with value: 0.6796114381833473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 89: Test Accuracy = 0.6210\n",
      "trial:92 hidden_size: 1024, num_layers: 4, learning_rate: 0.00044287928751262387, optimizer_name: Adam, weight_decay: 2.3355332615991396e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Trial 90: Test Accuracy = 0.7020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:05:09,865] Trial 90 finished with value: 0.701987851602654 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.00046037658937661427, 'weight_decay': 8.389509863697752e-06, 'batch_size': 32}. Best is trial 90 with value: 0.701987851602654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:93 hidden_size: 256, num_layers: 4, learning_rate: 0.00040277461374661815, optimizer_name: Adam, weight_decay: 1.4619148708845327e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:07:56,749] Trial 93 finished with value: 0.6710398093636109 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.00040277461374661815, 'weight_decay': 1.4619148708845327e-05, 'batch_size': 32}. Best is trial 90 with value: 0.701987851602654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 93: Test Accuracy = 0.6710\n",
      "trial:94 hidden_size: 256, num_layers: 4, learning_rate: 0.0004091601507842009, optimizer_name: Adam, weight_decay: 2.602106516288841e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:08:56,531] Trial 92 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.00044287928751262387, 'weight_decay': 2.3355332615991396e-06, 'batch_size': 10}. Best is trial 90 with value: 0.701987851602654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 92: Test Accuracy = 0.3333\n",
      "trial:95 hidden_size: 256, num_layers: 4, learning_rate: 0.00029209932200393945, optimizer_name: Adam, weight_decay: 1.561712256735164e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:10:12,746] Trial 94 finished with value: 0.4865678908513223 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.0004091601507842009, 'weight_decay': 2.602106516288841e-05, 'batch_size': 32}. Best is trial 90 with value: 0.701987851602654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 94: Test Accuracy = 0.4866\n",
      "trial:96 hidden_size: 256, num_layers: 4, learning_rate: 0.000279097820707761, optimizer_name: Adam, weight_decay: 1.1170324107115096e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:11:46,323] Trial 91 finished with value: 0.6082651154097748 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.00044691827447890486, 'weight_decay': 2.3045643935975854e-06, 'batch_size': 10}. Best is trial 90 with value: 0.701987851602654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 91: Test Accuracy = 0.6083\n",
      "trial:97 hidden_size: 256, num_layers: 4, learning_rate: 0.00024308920862881156, optimizer_name: Adam, weight_decay: 1.5290844247008258e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:12:06,760] Trial 95 finished with value: 0.5872767965610691 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.00029209932200393945, 'weight_decay': 1.561712256735164e-05, 'batch_size': 32}. Best is trial 90 with value: 0.701987851602654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 95: Test Accuracy = 0.5873\n",
      "trial:98 hidden_size: 256, num_layers: 4, learning_rate: 0.0007466650276013064, optimizer_name: Adam, weight_decay: 1.0669151599621761e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:12:28,663] Trial 96 finished with value: 0.6383282870759742 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.000279097820707761, 'weight_decay': 1.1170324107115096e-05, 'batch_size': 32}. Best is trial 90 with value: 0.701987851602654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 96: Test Accuracy = 0.6383\n",
      "trial:99 hidden_size: 256, num_layers: 4, learning_rate: 0.0007442262849524252, optimizer_name: Adam, weight_decay: 1.4181013683117141e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:13:28,805] Trial 97 finished with value: 0.6570993365106065 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.00024308920862881156, 'weight_decay': 1.5290844247008258e-05, 'batch_size': 32}. Best is trial 90 with value: 0.701987851602654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 97: Test Accuracy = 0.6571\n",
      "trial:100 hidden_size: 256, num_layers: 4, learning_rate: 0.0006928568797312765, optimizer_name: Adam, weight_decay: 1.490193095995181e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:14:34,872] Trial 99 finished with value: 0.5900328941220446 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0007442262849524252, 'weight_decay': 1.4181013683117141e-05, 'batch_size': 32}. Best is trial 90 with value: 0.701987851602654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 99: Test Accuracy = 0.5900\n",
      "trial:101 hidden_size: 256, num_layers: 4, learning_rate: 0.003293478172854135, optimizer_name: Adam, weight_decay: 1.9599795041855508e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:15:32,041] Trial 98 finished with value: 0.6738729090739183 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0007466650276013064, 'weight_decay': 1.0669151599621761e-05, 'batch_size': 32}. Best is trial 90 with value: 0.701987851602654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 98: Test Accuracy = 0.6739\n",
      "trial:102 hidden_size: 256, num_layers: 4, learning_rate: 0.004034711686121966, optimizer_name: Adam, weight_decay: 9.922616844968636e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:15:59,086] Trial 101 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.003293478172854135, 'weight_decay': 1.9599795041855508e-05, 'batch_size': 32}. Best is trial 90 with value: 0.701987851602654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 101: Test Accuracy = 0.3333\n",
      "trial:103 hidden_size: 256, num_layers: 4, learning_rate: 0.0012312324924573929, optimizer_name: Adam, weight_decay: 9.548064106312426e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:16:33,217] Trial 100 finished with value: 0.34878544061302685 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.0006928568797312765, 'weight_decay': 1.490193095995181e-05, 'batch_size': 32}. Best is trial 90 with value: 0.701987851602654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100: Test Accuracy = 0.3488\n",
      "trial:104 hidden_size: 256, num_layers: 4, learning_rate: 0.0019604835375104787, optimizer_name: Adam, weight_decay: 1.0642324466728681e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:16:45,807] Trial 102 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.004034711686121966, 'weight_decay': 9.922616844968636e-06, 'batch_size': 32}. Best is trial 90 with value: 0.701987851602654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 102: Test Accuracy = 0.3333\n",
      "trial:105 hidden_size: 256, num_layers: 4, learning_rate: 0.0005366857251641594, optimizer_name: Adam, weight_decay: 5.960779937159357e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n",
      "Trial 105: Test Accuracy = 0.3396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:18:36,110] Trial 105 finished with value: 0.33955555555555555 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0005366857251641594, 'weight_decay': 5.960779937159357e-06, 'batch_size': 32}. Best is trial 90 with value: 0.701987851602654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:106 hidden_size: 256, num_layers: 4, learning_rate: 0.0013078557400629056, optimizer_name: Adam, weight_decay: 7.702681577385865e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:18:43,609] Trial 104 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0019604835375104787, 'weight_decay': 1.0642324466728681e-05, 'batch_size': 32}. Best is trial 90 with value: 0.701987851602654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 104: Test Accuracy = 0.3333\n",
      "trial:107 hidden_size: 256, num_layers: 4, learning_rate: 0.00022415279484077954, optimizer_name: Adam, weight_decay: 7.402239952307714e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:19:30,061] Trial 103 finished with value: 0.5495979814970563 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0012312324924573929, 'weight_decay': 9.548064106312426e-06, 'batch_size': 32}. Best is trial 90 with value: 0.701987851602654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 103: Test Accuracy = 0.5496\n",
      "trial:108 hidden_size: 256, num_layers: 1, learning_rate: 0.00015278626990715617, optimizer_name: Adam, weight_decay: 7.302829410895338e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 12\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:20:04,250] Trial 106 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0013078557400629056, 'weight_decay': 7.702681577385865e-06, 'batch_size': 32}. Best is trial 90 with value: 0.701987851602654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 106: Test Accuracy = 0.3333\n",
      "trial:109 hidden_size: 256, num_layers: 1, learning_rate: 0.0002117972919789069, optimizer_name: Adam, weight_decay: 1.2602727542017043e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:20:04,679] Trial 107 finished with value: 0.5189549574806093 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.1, 'learning_rate': 0.00022415279484077954, 'weight_decay': 7.402239952307714e-06, 'batch_size': 32}. Best is trial 90 with value: 0.701987851602654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 107: Test Accuracy = 0.5190\n",
      "trial:110 hidden_size: 256, num_layers: 1, learning_rate: 0.00033228302203093535, optimizer_name: Adam, weight_decay: 5.865336440862533e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:21:16,186] Trial 109 finished with value: 0.6493635174282777 and parameters: {'hidden_size': 256, 'num_layers': 1, 'dropout': 0.30000000000000004, 'learning_rate': 0.0002117972919789069, 'weight_decay': 1.2602727542017043e-05, 'batch_size': 32}. Best is trial 90 with value: 0.701987851602654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 109: Test Accuracy = 0.6494\n",
      "trial:111 hidden_size: 64, num_layers: 3, learning_rate: 0.0005864257037135362, optimizer_name: Adam, weight_decay: 6.028870777283253e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:21:35,861] Trial 108 finished with value: 0.5690527988038502 and parameters: {'hidden_size': 256, 'num_layers': 1, 'dropout': 0.30000000000000004, 'learning_rate': 0.00015278626990715617, 'weight_decay': 7.302829410895338e-06, 'batch_size': 32}. Best is trial 90 with value: 0.701987851602654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 108: Test Accuracy = 0.5691\n",
      "trial:112 hidden_size: 64, num_layers: 4, learning_rate: 0.0003457860039763819, optimizer_name: Adam, weight_decay: 5.944172232271371e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:21:53,876] Trial 110 finished with value: 0.6354459396318102 and parameters: {'hidden_size': 256, 'num_layers': 1, 'dropout': 0.30000000000000004, 'learning_rate': 0.00033228302203093535, 'weight_decay': 5.865336440862533e-06, 'batch_size': 32}. Best is trial 90 with value: 0.701987851602654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 110: Test Accuracy = 0.6354\n",
      "trial:113 hidden_size: 256, num_layers: 1, learning_rate: 0.0002309401175013937, optimizer_name: Adam, weight_decay: 1.2281051767630243e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:22:36,783] Trial 111 finished with value: 0.49818876740491547 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 0.0005864257037135362, 'weight_decay': 6.028870777283253e-06, 'batch_size': 32}. Best is trial 90 with value: 0.701987851602654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 111: Test Accuracy = 0.4982\n",
      "trial:114 hidden_size: 256, num_layers: 1, learning_rate: 0.000230920767160593, optimizer_name: Adam, weight_decay: 1.2381186671143899e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Trial 112: Test Accuracy = 0.7099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:23:17,974] Trial 112 finished with value: 0.7098714138865526 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.0003457860039763819, 'weight_decay': 5.944172232271371e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:115 hidden_size: 64, num_layers: 4, learning_rate: 0.0003588941466744135, optimizer_name: Adam, weight_decay: 1.711482320445152e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:23:51,641] Trial 113 finished with value: 0.6076752639940192 and parameters: {'hidden_size': 256, 'num_layers': 1, 'dropout': 0.30000000000000004, 'learning_rate': 0.0002309401175013937, 'weight_decay': 1.2281051767630243e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 113: Test Accuracy = 0.6077\n",
      "trial:116 hidden_size: 64, num_layers: 4, learning_rate: 0.0008960376658882922, optimizer_name: Adam, weight_decay: 1.710399302940881e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:23:56,997] Trial 114 finished with value: 0.6146091019530885 and parameters: {'hidden_size': 256, 'num_layers': 1, 'dropout': 0.30000000000000004, 'learning_rate': 0.000230920767160593, 'weight_decay': 1.2381186671143899e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 114: Test Accuracy = 0.6146\n",
      "trial:117 hidden_size: 64, num_layers: 4, learning_rate: 0.000869453350035131, optimizer_name: Adam, weight_decay: 8.42054734328323e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:24:38,245] Trial 116 finished with value: 0.6184336977852537 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.0008960376658882922, 'weight_decay': 1.710399302940881e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 116: Test Accuracy = 0.6184\n",
      "trial:118 hidden_size: 64, num_layers: 4, learning_rate: 0.0003729428183885341, optimizer_name: Adam, weight_decay: 8.198629660539195e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:24:59,046] Trial 115 finished with value: 0.6155547145126624 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.0003588941466744135, 'weight_decay': 1.711482320445152e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 115: Test Accuracy = 0.6156\n",
      "trial:119 hidden_size: 64, num_layers: 4, learning_rate: 0.0005121235615705117, optimizer_name: Adam, weight_decay: 2.4863699229235828e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:25:10,185] Trial 117 finished with value: 0.4470155125689188 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.000869453350035131, 'weight_decay': 8.42054734328323e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 117: Test Accuracy = 0.4470\n",
      "trial:120 hidden_size: 64, num_layers: 4, learning_rate: 0.0005193770067657897, optimizer_name: Adam, weight_decay: 2.111592616639242e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:25:52,783] Trial 119 finished with value: 0.5798070273806187 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0005121235615705117, 'weight_decay': 2.4863699229235828e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 119: Test Accuracy = 0.5798\n",
      "trial:121 hidden_size: 512, num_layers: 4, learning_rate: 0.00010319496984675702, optimizer_name: Adam, weight_decay: 2.102581682942791e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:26:24,478] Trial 118 finished with value: 0.5687627324549107 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0003729428183885341, 'weight_decay': 8.198629660539195e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 118: Test Accuracy = 0.5688\n",
      "trial:122 hidden_size: 512, num_layers: 3, learning_rate: 9.92858961086148e-05, optimizer_name: Adam, weight_decay: 4.56480097276672e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:27:15,157] Trial 120 finished with value: 0.692112419400056 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0005193770067657897, 'weight_decay': 2.111592616639242e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 120: Test Accuracy = 0.6921\n",
      "trial:123 hidden_size: 64, num_layers: 4, learning_rate: 0.0001651058599423372, optimizer_name: Adam, weight_decay: 2.1550720833014445e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:28:54,153] Trial 123 finished with value: 0.6464629473880946 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0001651058599423372, 'weight_decay': 2.1550720833014445e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 123: Test Accuracy = 0.6465\n",
      "trial:124 hidden_size: 64, num_layers: 4, learning_rate: 0.0005739772228596213, optimizer_name: Adam, weight_decay: 2.7759520678330583e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:30:11,889] Trial 122 finished with value: 0.6232744603308102 and parameters: {'hidden_size': 512, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 9.92858961086148e-05, 'weight_decay': 4.56480097276672e-06, 'batch_size': 16}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 122: Test Accuracy = 0.6233\n",
      "trial:125 hidden_size: 64, num_layers: 4, learning_rate: 0.0005979720861181709, optimizer_name: Adam, weight_decay: 1.3810656574972015e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:30:20,502] Trial 121 finished with value: 0.4012327819829922 and parameters: {'hidden_size': 512, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00010319496984675702, 'weight_decay': 2.102581682942791e-05, 'batch_size': 16}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 121: Test Accuracy = 0.4012\n",
      "trial:126 hidden_size: 64, num_layers: 4, learning_rate: 0.0006048585323471839, optimizer_name: Adam, weight_decay: 2.918873135304649e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:30:42,743] Trial 124 finished with value: 0.6354317353518363 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0005739772228596213, 'weight_decay': 2.7759520678330583e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 124: Test Accuracy = 0.6354\n",
      "trial:127 hidden_size: 1024, num_layers: 4, learning_rate: 0.0002634656340841159, optimizer_name: Adam, weight_decay: 1.3828560237622399e-05, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n",
      "Trial 126: Test Accuracy = 0.5981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:32:22,129] Trial 126 finished with value: 0.5981423231473695 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0006048585323471839, 'weight_decay': 2.918873135304649e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:128 hidden_size: 128, num_layers: 4, learning_rate: 0.00029474602752875513, optimizer_name: Adam, weight_decay: 1.4509653916169768e-05, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 19\n",
      "Trial 125: Test Accuracy = 0.6107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:32:28,927] Trial 125 finished with value: 0.6106999345855528 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0005979720861181709, 'weight_decay': 1.3810656574972015e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:129 hidden_size: 1024, num_layers: 4, learning_rate: 0.0002861422021554633, optimizer_name: Adam, weight_decay: 3.470131276901892e-05, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n",
      "Trial 128: Test Accuracy = 0.6314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:58:37,895] Trial 128 finished with value: 0.6314091206429305 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.1, 'learning_rate': 0.00029474602752875513, 'weight_decay': 1.4509653916169768e-05, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:130 hidden_size: 1024, num_layers: 4, learning_rate: 0.00043452834042363324, optimizer_name: Adam, weight_decay: 3.5942726264404846e-05, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 11\n",
      "Trial 129: Test Accuracy = 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:11:41,290] Trial 129 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.0002861422021554633, 'weight_decay': 3.470131276901892e-05, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:131 hidden_size: 128, num_layers: 3, learning_rate: 0.0004158609968358037, optimizer_name: Adam, weight_decay: 1.1315185890789674e-05, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 18\n",
      "Trial 127: Test Accuracy = 0.5579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:26:55,659] Trial 127 finished with value: 0.5578871133538922 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0002634656340841159, 'weight_decay': 1.3828560237622399e-05, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:132 hidden_size: 128, num_layers: 3, learning_rate: 0.0004089489659155133, optimizer_name: Adam, weight_decay: 1.053381357200178e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 11\n",
      "Trial 132: Test Accuracy = 0.5135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:28:47,403] Trial 132 finished with value: 0.5135491075600411 and parameters: {'hidden_size': 128, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 0.0004089489659155133, 'weight_decay': 1.053381357200178e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:133 hidden_size: 256, num_layers: 1, learning_rate: 0.00015291342971087094, optimizer_name: Adam, weight_decay: 9.072025770386671e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 11\n",
      "Trial 130: Test Accuracy = 0.4510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:31:45,556] Trial 130 finished with value: 0.45097420801794225 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.00043452834042363324, 'weight_decay': 3.5942726264404846e-05, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:134 hidden_size: 256, num_layers: 1, learning_rate: 0.00018156865673393243, optimizer_name: Adam, weight_decay: 1.1498444933970403e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:31:58,423] Trial 131 finished with value: 0.517723483786562 and parameters: {'hidden_size': 128, 'num_layers': 3, 'dropout': 0.2, 'learning_rate': 0.0004158609968358037, 'weight_decay': 1.1315185890789674e-05, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 131: Test Accuracy = 0.5177\n",
      "trial:135 hidden_size: 256, num_layers: 1, learning_rate: 0.00019240791050939974, optimizer_name: Adam, weight_decay: 9.255224471595166e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:32:05,336] Trial 133 finished with value: 0.604451453135221 and parameters: {'hidden_size': 256, 'num_layers': 1, 'dropout': 0.30000000000000004, 'learning_rate': 0.00015291342971087094, 'weight_decay': 9.072025770386671e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 133: Test Accuracy = 0.6045\n",
      "trial:136 hidden_size: 32, num_layers: 1, learning_rate: 0.00020664395482728414, optimizer_name: Adam, weight_decay: 1.9137037352499786e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:32:57,531] Trial 134 finished with value: 0.5314614522007289 and parameters: {'hidden_size': 256, 'num_layers': 1, 'dropout': 0.30000000000000004, 'learning_rate': 0.00018156865673393243, 'weight_decay': 1.1498444933970403e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 134: Test Accuracy = 0.5315\n",
      "trial:137 hidden_size: 32, num_layers: 4, learning_rate: 3.8171352324735847e-07, optimizer_name: Adam, weight_decay: 1.7750085490647335e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:33:06,949] Trial 135 finished with value: 0.516993645453696 and parameters: {'hidden_size': 256, 'num_layers': 1, 'dropout': 0.30000000000000004, 'learning_rate': 0.00019240791050939974, 'weight_decay': 9.255224471595166e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 135: Test Accuracy = 0.5170\n",
      "trial:138 hidden_size: 32, num_layers: 4, learning_rate: 7.282086201837421e-05, optimizer_name: Adam, weight_decay: 6.857898701569615e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:33:45,154] Trial 138 finished with value: 0.5737074105223812 and parameters: {'hidden_size': 32, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 7.282086201837421e-05, 'weight_decay': 6.857898701569615e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 138: Test Accuracy = 0.5737\n",
      "trial:139 hidden_size: 128, num_layers: 4, learning_rate: 0.001108768542426481, optimizer_name: Adam, weight_decay: 1.7411673785235637e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:33:48,656] Trial 136 finished with value: 0.6058302027847865 and parameters: {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.30000000000000004, 'learning_rate': 0.00020664395482728414, 'weight_decay': 1.9137037352499786e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 136: Test Accuracy = 0.6058\n",
      "trial:140 hidden_size: 128, num_layers: 4, learning_rate: 0.0008286130518926572, optimizer_name: Adam, weight_decay: 1.5922264324395706e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:34:41,245] Trial 139 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.001108768542426481, 'weight_decay': 1.7411673785235637e-05, 'batch_size': 16}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 139: Test Accuracy = 0.3333\n",
      "trial:141 hidden_size: 256, num_layers: 4, learning_rate: 0.000798830462657578, optimizer_name: Adam, weight_decay: 0.00021887924892756642, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:34:43,240] Trial 137 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 32, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 3.8171352324735847e-07, 'weight_decay': 1.7750085490647335e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 137: Test Accuracy = 0.3333\n",
      "trial:142 hidden_size: 256, num_layers: 4, learning_rate: 0.00013475415119803074, optimizer_name: Adam, weight_decay: 5.358696986273993e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:36:21,849] Trial 140 finished with value: 0.6100756004111765 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 0.0008286130518926572, 'weight_decay': 1.5922264324395706e-05, 'batch_size': 16}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 140: Test Accuracy = 0.6101\n",
      "trial:143 hidden_size: 128, num_layers: 4, learning_rate: 0.0003265438587698336, optimizer_name: Adam, weight_decay: 2.597925402816427e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:36:55,163] Trial 141 finished with value: 0.6255637790860668 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 0.000798830462657578, 'weight_decay': 0.00021887924892756642, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 141: Test Accuracy = 0.6256\n",
      "trial:144 hidden_size: 128, num_layers: 4, learning_rate: 0.00012967306146142969, optimizer_name: Adam, weight_decay: 2.3472798806653953e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:38:32,639] Trial 144 finished with value: 0.6358158116063919 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 0.00012967306146142969, 'weight_decay': 2.3472798806653953e-05, 'batch_size': 16}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 144: Test Accuracy = 0.6358\n",
      "trial:145 hidden_size: 128, num_layers: 4, learning_rate: 0.00033972399352784176, optimizer_name: Adam, weight_decay: 1.2589392717843103e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Trial 143: Test Accuracy = 0.6198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:38:50,581] Trial 143 finished with value: 0.6198278665545276 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 0.0003265438587698336, 'weight_decay': 2.597925402816427e-05, 'batch_size': 16}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:146 hidden_size: 128, num_layers: 4, learning_rate: 0.0002360758082659926, optimizer_name: Adam, weight_decay: 5.61582596613326e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:39:38,350] Trial 145 finished with value: 0.5482717503037099 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 0.00033972399352784176, 'weight_decay': 1.2589392717843103e-05, 'batch_size': 16}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 145: Test Accuracy = 0.5483\n",
      "trial:147 hidden_size: 128, num_layers: 4, learning_rate: 0.0004684767908538044, optimizer_name: Adam, weight_decay: 2.1481519564033313e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:39:50,883] Trial 142 finished with value: 0.5578386132137184 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.5, 'learning_rate': 0.00013475415119803074, 'weight_decay': 5.358696986273993e-06, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 142: Test Accuracy = 0.5578\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 12\n",
      "trial:148 hidden_size: 128, num_layers: 4, learning_rate: 0.00024371260757646637, optimizer_name: Adam, weight_decay: 7.0096470264131885e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:39:52,678] Trial 146 finished with value: 0.627108961779273 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.4, 'learning_rate': 0.0002360758082659926, 'weight_decay': 5.61582596613326e-06, 'batch_size': 16}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 146: Test Accuracy = 0.6271\n",
      "trial:149 hidden_size: 128, num_layers: 4, learning_rate: 8.547224659701097e-05, optimizer_name: Adam, weight_decay: 6.611441629271758e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:40:35,082] Trial 147 finished with value: 0.5844941594243528 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0004684767908538044, 'weight_decay': 2.1481519564033313e-05, 'batch_size': 16}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 147: Test Accuracy = 0.5845\n",
      "trial:150 hidden_size: 64, num_layers: 2, learning_rate: 8.467916996380154e-05, optimizer_name: Adam, weight_decay: 6.633143164612221e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:41:36,299] Trial 148 finished with value: 0.5260400897112419 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00024371260757646637, 'weight_decay': 7.0096470264131885e-06, 'batch_size': 16}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 148: Test Accuracy = 0.5260\n",
      "trial:151 hidden_size: 64, num_layers: 2, learning_rate: 8.506386998584825e-05, optimizer_name: Adam, weight_decay: 1.0352057304460575e-05, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:41:46,004] Trial 149 finished with value: 0.6067836650780302 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 8.547224659701097e-05, 'weight_decay': 6.611441629271758e-06, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 149: Test Accuracy = 0.6068\n",
      "trial:152 hidden_size: 64, num_layers: 2, learning_rate: 0.0016546252083639433, optimizer_name: Adam, weight_decay: 8.631543247486604e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:42:17,515] Trial 150 finished with value: 0.6281892346509672 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.30000000000000004, 'learning_rate': 8.467916996380154e-05, 'weight_decay': 6.633143164612221e-06, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 150: Test Accuracy = 0.6282\n",
      "trial:153 hidden_size: 128, num_layers: 2, learning_rate: 5.0520176600967734e-05, optimizer_name: Adam, weight_decay: 3.2594468126672177e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:43:03,464] Trial 151 finished with value: 0.6130128025418186 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.30000000000000004, 'learning_rate': 8.506386998584825e-05, 'weight_decay': 1.0352057304460575e-05, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 151: Test Accuracy = 0.6130\n",
      "trial:154 hidden_size: 128, num_layers: 2, learning_rate: 5.627741914981839e-05, optimizer_name: Adam, weight_decay: 4.036440416694313e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:43:10,487] Trial 152 finished with value: 0.45815811606391926 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.30000000000000004, 'learning_rate': 0.0016546252083639433, 'weight_decay': 8.631543247486604e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 152: Test Accuracy = 0.4582\n",
      "trial:155 hidden_size: 128, num_layers: 2, learning_rate: 5.720518132059333e-05, optimizer_name: Adam, weight_decay: 3.713724390369218e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:43:30,008] Trial 153 finished with value: 0.6510281282123166 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.30000000000000004, 'learning_rate': 5.0520176600967734e-05, 'weight_decay': 3.2594468126672177e-06, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 153: Test Accuracy = 0.6510\n",
      "trial:156 hidden_size: 128, num_layers: 2, learning_rate: 0.00018692392239468534, optimizer_name: Adam, weight_decay: 0.0004612617415145854, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:44:09,665] Trial 155 finished with value: 0.6116506868516961 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.30000000000000004, 'learning_rate': 5.720518132059333e-05, 'weight_decay': 3.713724390369218e-06, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 155: Test Accuracy = 0.6117\n",
      "trial:157 hidden_size: 128, num_layers: 2, learning_rate: 4.762344869374359e-05, optimizer_name: Adam, weight_decay: 4.489199765564085e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:44:23,203] Trial 154 finished with value: 0.5716322773572563 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.30000000000000004, 'learning_rate': 5.627741914981839e-05, 'weight_decay': 4.036440416694313e-06, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 154: Test Accuracy = 0.5716\n",
      "trial:158 hidden_size: 256, num_layers: 3, learning_rate: 2.9291166023986908e-05, optimizer_name: Adam, weight_decay: 2.7317547155969414e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:45:13,513] Trial 156 finished with value: 0.5914407064760302 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.30000000000000004, 'learning_rate': 0.00018692392239468534, 'weight_decay': 0.0004612617415145854, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 156: Test Accuracy = 0.5914\n",
      "trial:159 hidden_size: 256, num_layers: 3, learning_rate: 0.0005093449403741882, optimizer_name: Adam, weight_decay: 2.869435697294634e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:46:33,922] Trial 157 finished with value: 0.6230938230071955 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.30000000000000004, 'learning_rate': 4.762344869374359e-05, 'weight_decay': 4.489199765564085e-06, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 157: Test Accuracy = 0.6231\n",
      "trial:160 hidden_size: 256, num_layers: 3, learning_rate: 0.0005196531156436982, optimizer_name: Adam, weight_decay: 3.331417366122165e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:47:48,565] Trial 159 finished with value: 0.6280633585646201 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 0.0005093449403741882, 'weight_decay': 2.869435697294634e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 159: Test Accuracy = 0.6281\n",
      "trial:161 hidden_size: 256, num_layers: 4, learning_rate: 0.0001284001024148961, optimizer_name: Adam, weight_decay: 7.881660918613084e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 25\n",
      "Trial 158: Test Accuracy = 0.5912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:49:16,802] Trial 158 finished with value: 0.5911894215493879 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 2.9291166023986908e-05, 'weight_decay': 2.7317547155969414e-06, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:162 hidden_size: 256, num_layers: 4, learning_rate: 0.00012971095776544272, optimizer_name: Adam, weight_decay: 7.716343627901369e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:49:18,112] Trial 160 finished with value: 0.4612084851883002 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.30000000000000004, 'learning_rate': 0.0005196531156436982, 'weight_decay': 3.331417366122165e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 160: Test Accuracy = 0.4612\n",
      "trial:163 hidden_size: 128, num_layers: 2, learning_rate: 1.5801121035056337e-05, optimizer_name: Adam, weight_decay: 5.071237661830387e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:50:25,566] Trial 161 finished with value: 0.6198508550602747 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.0001284001024148961, 'weight_decay': 7.881660918613084e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 161: Test Accuracy = 0.6199\n",
      "trial:164 hidden_size: 128, num_layers: 2, learning_rate: 1.618559321389867e-05, optimizer_name: Adam, weight_decay: 4.8304838228821955e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n",
      "Trial 162: Test Accuracy = 0.6709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:51:01,525] Trial 162 finished with value: 0.6709294458461826 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00012971095776544272, 'weight_decay': 7.716343627901369e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:165 hidden_size: 256, num_layers: 4, learning_rate: 0.00035088460153111575, optimizer_name: Adam, weight_decay: 1.2897269066092996e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:51:26,966] Trial 163 finished with value: 0.5667734791141015 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.30000000000000004, 'learning_rate': 1.5801121035056337e-05, 'weight_decay': 5.071237661830387e-06, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 163: Test Accuracy = 0.5668\n",
      "trial:166 hidden_size: 256, num_layers: 4, learning_rate: 0.0003437580275747499, optimizer_name: Adam, weight_decay: 9.22786000068556e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:52:57,531] Trial 164 finished with value: 0.5816576020932623 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.30000000000000004, 'learning_rate': 1.618559321389867e-05, 'weight_decay': 4.8304838228821955e-06, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 164: Test Accuracy = 0.5817\n",
      "trial:167 hidden_size: 256, num_layers: 4, learning_rate: 0.0003026958069228865, optimizer_name: Adam, weight_decay: 9.235996705856926e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:54:00,465] Trial 165 finished with value: 0.458811326044295 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00035088460153111575, 'weight_decay': 1.2897269066092996e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 165: Test Accuracy = 0.4588\n",
      "trial:168 hidden_size: 256, num_layers: 4, learning_rate: 0.00016976985603598006, optimizer_name: Adam, weight_decay: 1.438151090975599e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:54:29,928] Trial 166 finished with value: 0.6306550789645827 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0003437580275747499, 'weight_decay': 9.22786000068556e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 166: Test Accuracy = 0.6307\n",
      "trial:169 hidden_size: 256, num_layers: 4, learning_rate: 0.0002575771081656913, optimizer_name: Adam, weight_decay: 1.5285570738537358e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:55:11,609] Trial 167 finished with value: 0.6500773759461733 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0003026958069228865, 'weight_decay': 9.235996705856926e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 167: Test Accuracy = 0.6501\n",
      "trial:170 hidden_size: 256, num_layers: 4, learning_rate: 0.0002512608376031214, optimizer_name: Adam, weight_decay: 1.405257750384442e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:56:04,776] Trial 168 finished with value: 0.610388374918232 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00016976985603598006, 'weight_decay': 1.438151090975599e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 168: Test Accuracy = 0.6104\n",
      "trial:171 hidden_size: 256, num_layers: 4, learning_rate: 0.0002532230615844724, optimizer_name: Adam, weight_decay: 6.043635735461535e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:56:22,773] Trial 169 finished with value: 0.583600504625736 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0002575771081656913, 'weight_decay': 1.5285570738537358e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 169: Test Accuracy = 0.5836\n",
      "trial:172 hidden_size: 256, num_layers: 4, learning_rate: 0.0006923370574787187, optimizer_name: Adam, weight_decay: 8.046460881442933e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:58:23,715] Trial 170 finished with value: 0.5817888047845996 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0002512608376031214, 'weight_decay': 1.405257750384442e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 170: Test Accuracy = 0.5818\n",
      "trial:173 hidden_size: 256, num_layers: 4, learning_rate: 0.0006613266204299749, optimizer_name: Adam, weight_decay: 7.816654621857207e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:58:38,790] Trial 171 finished with value: 0.5458470236426501 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0002532230615844724, 'weight_decay': 6.043635735461535e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 171: Test Accuracy = 0.5458\n",
      "trial:174 hidden_size: 256, num_layers: 4, learning_rate: 0.00010881956338415986, optimizer_name: Adam, weight_decay: 7.962304579713443e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 02:59:57,840] Trial 172 finished with value: 0.6574853751985796 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0006923370574787187, 'weight_decay': 8.046460881442933e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 172: Test Accuracy = 0.6575\n",
      "trial:175 hidden_size: 256, num_layers: 4, learning_rate: 0.00039141933922970997, optimizer_name: Adam, weight_decay: 7.769019144445857e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:01:08,093] Trial 173 finished with value: 0.5488354359405663 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0006613266204299749, 'weight_decay': 7.816654621857207e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 173: Test Accuracy = 0.5488\n",
      "trial:176 hidden_size: 256, num_layers: 4, learning_rate: 0.0004254463208258696, optimizer_name: Adam, weight_decay: 9.252706367217385e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:02:15,803] Trial 174 finished with value: 0.684320063545463 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00010881956338415986, 'weight_decay': 7.962304579713443e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 174: Test Accuracy = 0.6843\n",
      "trial:177 hidden_size: 256, num_layers: 4, learning_rate: 0.0007214313611970147, optimizer_name: Adam, weight_decay: 1.0148407978335689e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:03:19,663] Trial 175 finished with value: 0.5491500794318288 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00039141933922970997, 'weight_decay': 7.769019144445857e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 175: Test Accuracy = 0.5492\n",
      "trial:178 hidden_size: 256, num_layers: 4, learning_rate: 0.0009237125819884835, optimizer_name: Adam, weight_decay: 9.881354145563013e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:04:01,286] Trial 176 finished with value: 0.5457265676105038 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0004254463208258696, 'weight_decay': 9.252706367217385e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 176: Test Accuracy = 0.5457\n",
      "trial:179 hidden_size: 256, num_layers: 4, learning_rate: 0.001032538608446601, optimizer_name: Adam, weight_decay: 1.0327432128610668e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:05:50,537] Trial 179 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.001032538608446601, 'weight_decay': 1.0327432128610668e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 179: Test Accuracy = 0.3333\n",
      "trial:180 hidden_size: 512, num_layers: 4, learning_rate: 0.0006692398099178771, optimizer_name: Adam, weight_decay: 6.4111529363805305e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:05:51,932] Trial 177 finished with value: 0.4041034482758621 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0007214313611970147, 'weight_decay': 1.0148407978335689e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 177: Test Accuracy = 0.4041\n",
      "trial:181 hidden_size: 64, num_layers: 4, learning_rate: 0.00012078118884596367, optimizer_name: Adam, weight_decay: 6.0541978182063625e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Trial 178: Test Accuracy = 0.5193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:07:02,522] Trial 178 finished with value: 0.519300252312868 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0009237125819884835, 'weight_decay': 9.881354145563013e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:182 hidden_size: 512, num_layers: 4, learning_rate: 0.00014877060366767612, optimizer_name: Adam, weight_decay: 6.540678687533801e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:09:01,978] Trial 182 finished with value: 0.6010354172507242 and parameters: {'hidden_size': 512, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00014877060366767612, 'weight_decay': 6.540678687533801e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 182: Test Accuracy = 0.6010\n",
      "trial:183 hidden_size: 256, num_layers: 4, learning_rate: 0.00019746247153352197, optimizer_name: Adam, weight_decay: 1.1857264817531319e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:09:14,534] Trial 181 finished with value: 0.6164693019343986 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00012078118884596367, 'weight_decay': 6.0541978182063625e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 181: Test Accuracy = 0.6165\n",
      "trial:184 hidden_size: 256, num_layers: 4, learning_rate: 0.00020007408631579895, optimizer_name: Adam, weight_decay: 1.1603383593157988e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:09:43,211] Trial 180 finished with value: 0.5855135034108961 and parameters: {'hidden_size': 512, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0006692398099178771, 'weight_decay': 6.4111529363805305e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 180: Test Accuracy = 0.5855\n",
      "trial:185 hidden_size: 256, num_layers: 4, learning_rate: 0.0003064738497994963, optimizer_name: Adam, weight_decay: 1.4971291090685274e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:11:22,585] Trial 185 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0003064738497994963, 'weight_decay': 1.4971291090685274e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 185: Test Accuracy = 0.3333\n",
      "trial:186 hidden_size: 256, num_layers: 4, learning_rate: 0.00020907979257938004, optimizer_name: Adam, weight_decay: 7.955938214397676e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:11:43,078] Trial 183 finished with value: 0.6643209980375665 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00019746247153352197, 'weight_decay': 1.1857264817531319e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 183: Test Accuracy = 0.6643\n",
      "trial:187 hidden_size: 256, num_layers: 4, learning_rate: 0.0001747177573936671, optimizer_name: Adam, weight_decay: 8.53717607648044e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:12:14,514] Trial 184 finished with value: 0.5823660405569573 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00020007408631579895, 'weight_decay': 1.1603383593157988e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 184: Test Accuracy = 0.5824\n",
      "trial:188 hidden_size: 32, num_layers: 4, learning_rate: 0.0004973930339291032, optimizer_name: Adam, weight_decay: 8.343205804723457e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:13:47,871] Trial 186 finished with value: 0.6606840482197925 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00020907979257938004, 'weight_decay': 7.955938214397676e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 186: Test Accuracy = 0.6607\n",
      "trial:189 hidden_size: 32, num_layers: 4, learning_rate: 0.00047419783996810835, optimizer_name: Adam, weight_decay: 7.776067611185591e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:14:03,743] Trial 187 finished with value: 0.5432250256985328 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0001747177573936671, 'weight_decay': 8.53717607648044e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 187: Test Accuracy = 0.5432\n",
      "trial:190 hidden_size: 32, num_layers: 4, learning_rate: 0.0005409137004964183, optimizer_name: Adam, weight_decay: 7.626100879992443e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:14:09,961] Trial 188 finished with value: 0.5724202410989627 and parameters: {'hidden_size': 32, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0004973930339291032, 'weight_decay': 8.343205804723457e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 188: Test Accuracy = 0.5724\n",
      "trial:191 hidden_size: 64, num_layers: 4, learning_rate: 0.00012502329044342128, optimizer_name: Adam, weight_decay: 7.684298320926852e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:15:25,266] Trial 190 finished with value: 0.4610597140454163 and parameters: {'hidden_size': 32, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0005409137004964183, 'weight_decay': 7.626100879992443e-06, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 190: Test Accuracy = 0.4611\n",
      "trial:192 hidden_size: 64, num_layers: 4, learning_rate: 0.00011531135355295594, optimizer_name: Adam, weight_decay: 7.269950435966323e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:15:28,145] Trial 189 finished with value: 0.5809694421082142 and parameters: {'hidden_size': 32, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00047419783996810835, 'weight_decay': 7.776067611185591e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 189: Test Accuracy = 0.5810\n",
      "trial:193 hidden_size: 256, num_layers: 4, learning_rate: 0.00030304674344200876, optimizer_name: Adam, weight_decay: 5.577356271784109e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:15:51,221] Trial 191 finished with value: 0.6758374918231942 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00012502329044342128, 'weight_decay': 7.684298320926852e-06, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 191: Test Accuracy = 0.6758\n",
      "trial:194 hidden_size: 64, num_layers: 4, learning_rate: 0.0001276978092069076, optimizer_name: Adam, weight_decay: 7.208969417729386e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:17:01,576] Trial 192 finished with value: 0.5984380898981403 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00011531135355295594, 'weight_decay': 7.269950435966323e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 192: Test Accuracy = 0.5984\n",
      "trial:195 hidden_size: 64, num_layers: 4, learning_rate: 9.963510912819165e-05, optimizer_name: Adam, weight_decay: 5.583922276158966e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:17:09,645] Trial 194 finished with value: 0.6477603027754416 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0001276978092069076, 'weight_decay': 7.208969417729386e-06, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 194: Test Accuracy = 0.6478\n",
      "trial:196 hidden_size: 64, num_layers: 4, learning_rate: 9.710446199015396e-05, optimizer_name: Adam, weight_decay: 5.299781972494979e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:18:06,785] Trial 193 finished with value: 0.6477442295112606 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00030304674344200876, 'weight_decay': 5.577356271784109e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 193: Test Accuracy = 0.6477\n",
      "Trial 195: Test Accuracy = 0.5978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:18:06,932] Trial 195 finished with value: 0.5978422577329221 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 9.963510912819165e-05, 'weight_decay': 5.583922276158966e-06, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:197 hidden_size: 64, num_layers: 4, learning_rate: 0.00010056190591801957, optimizer_name: Adam, weight_decay: 1.9125198209735857e-05, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "trial:198 hidden_size: 64, num_layers: 4, learning_rate: 0.0001748608016718541, optimizer_name: Adam, weight_decay: 1.1546801592312658e-05, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:19:00,583] Trial 196 finished with value: 0.6064744416409682 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 9.710446199015396e-05, 'weight_decay': 5.299781972494979e-06, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 196: Test Accuracy = 0.6065\n",
      "trial:199 hidden_size: 64, num_layers: 4, learning_rate: 0.000200831139711622, optimizer_name: Adam, weight_decay: 1.1278786995839947e-05, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:19:11,641] Trial 198 finished with value: 0.6532095131296142 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0001748608016718541, 'weight_decay': 1.1546801592312658e-05, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 198: Test Accuracy = 0.6532\n",
      "trial:200 hidden_size: 64, num_layers: 4, learning_rate: 4.63807188518904e-06, optimizer_name: Adam, weight_decay: 1.1159136727423253e-05, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:19:40,858] Trial 197 finished with value: 0.6119384169703767 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00010056190591801957, 'weight_decay': 1.9125198209735857e-05, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 197: Test Accuracy = 0.6119\n",
      "trial:201 hidden_size: 64, num_layers: 4, learning_rate: 0.00021703060258844664, optimizer_name: Adam, weight_decay: 1.1205519839952851e-05, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 18\n",
      "Trial 199: Test Accuracy = 0.5566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:20:45,620] Trial 199 finished with value: 0.5565797589010374 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.000200831139711622, 'weight_decay': 1.1278786995839947e-05, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:202 hidden_size: 64, num_layers: 4, learning_rate: 0.0003729455115097726, optimizer_name: Adam, weight_decay: 1.6057706079680742e-05, batch_size: 10, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:20:47,129] Trial 201 finished with value: 0.6080857863751051 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00021703060258844664, 'weight_decay': 1.1205519839952851e-05, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 201: Test Accuracy = 0.6081\n",
      "trial:203 hidden_size: 64, num_layers: 4, learning_rate: 0.00015665077046483482, optimizer_name: Adam, weight_decay: 8.62741334164287e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:20:55,043] Trial 200 finished with value: 0.5393537987104009 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 4.63807188518904e-06, 'weight_decay': 1.1159136727423253e-05, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 200: Test Accuracy = 0.5394\n",
      "trial:204 hidden_size: 64, num_layers: 4, learning_rate: 0.00015444315847810289, optimizer_name: Adam, weight_decay: 1.4144394103494034e-05, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:22:02,012] Trial 203 finished with value: 0.5266455471451267 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00015665077046483482, 'weight_decay': 8.62741334164287e-06, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 203: Test Accuracy = 0.5266\n",
      "trial:205 hidden_size: 256, num_layers: 4, learning_rate: 0.0003579555001287795, optimizer_name: Adam, weight_decay: 1.574261506052437e-05, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:22:23,498] Trial 202 finished with value: 0.49531735351836276 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0003729455115097726, 'weight_decay': 1.6057706079680742e-05, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 202: Test Accuracy = 0.4953\n",
      "trial:206 hidden_size: 256, num_layers: 4, learning_rate: 7.669898158245952e-05, optimizer_name: Adam, weight_decay: 1.307952957951259e-05, batch_size: 10, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:22:54,354] Trial 204 finished with value: 0.669376787216148 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00015444315847810289, 'weight_decay': 1.4144394103494034e-05, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 204: Test Accuracy = 0.6694\n",
      "trial:207 hidden_size: 64, num_layers: 4, learning_rate: 0.00026030362647079297, optimizer_name: Adam, weight_decay: 1.3732911887453741e-05, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:25:04,066] Trial 207 finished with value: 0.3974189328100177 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00026030362647079297, 'weight_decay': 1.3732911887453741e-05, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 207: Test Accuracy = 0.3974\n",
      "trial:208 hidden_size: 64, num_layers: 4, learning_rate: 0.0001574605956672458, optimizer_name: Adam, weight_decay: 1.346049472481873e-05, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:25:23,099] Trial 206 finished with value: 0.6205368657134848 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 7.669898158245952e-05, 'weight_decay': 1.307952957951259e-05, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 206: Test Accuracy = 0.6205\n",
      "trial:209 hidden_size: 64, num_layers: 4, learning_rate: 0.00016256371130010192, optimizer_name: Adam, weight_decay: 1.491695135812618e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:26:42,476] Trial 209 finished with value: 0.656696290066349 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00016256371130010192, 'weight_decay': 1.491695135812618e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 209: Test Accuracy = 0.6567\n",
      "trial:210 hidden_size: 64, num_layers: 4, learning_rate: 0.00015280981745527538, optimizer_name: Adam, weight_decay: 1.4927111301608868e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:26:49,789] Trial 205 finished with value: 0.35049789739276704 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0003579555001287795, 'weight_decay': 1.574261506052437e-05, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 205: Test Accuracy = 0.3505\n",
      "trial:211 hidden_size: 64, num_layers: 4, learning_rate: 0.00017189820098842924, optimizer_name: Adam, weight_decay: 1.9000663756056396e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:27:12,785] Trial 208 finished with value: 0.6560217736660126 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0001574605956672458, 'weight_decay': 1.346049472481873e-05, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 208: Test Accuracy = 0.6560\n",
      "trial:212 hidden_size: 64, num_layers: 4, learning_rate: 0.0002502441313560748, optimizer_name: Adam, weight_decay: 1.9560896806094337e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:28:20,001] Trial 210 finished with value: 0.6723627698345949 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00015280981745527538, 'weight_decay': 1.4927111301608868e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 210: Test Accuracy = 0.6724\n",
      "trial:213 hidden_size: 64, num_layers: 4, learning_rate: 0.00014394209797737186, optimizer_name: Adam, weight_decay: 2.0568340588825145e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:28:27,867] Trial 211 finished with value: 0.5945037846930193 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00017189820098842924, 'weight_decay': 1.9000663756056396e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 211: Test Accuracy = 0.5945\n",
      "trial:214 hidden_size: 64, num_layers: 4, learning_rate: 0.00024012495116516644, optimizer_name: Adam, weight_decay: 1.4001824316874762e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:28:40,469] Trial 212 finished with value: 0.5822640874684609 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0002502441313560748, 'weight_decay': 1.9560896806094337e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 212: Test Accuracy = 0.5823\n",
      "trial:215 hidden_size: 64, num_layers: 4, learning_rate: 0.00030346216231679987, optimizer_name: Adam, weight_decay: 1.4464039939827794e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:29:39,269] Trial 213 finished with value: 0.6155035977945987 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00014394209797737186, 'weight_decay': 2.0568340588825145e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 213: Test Accuracy = 0.6155\n",
      "trial:216 hidden_size: 64, num_layers: 4, learning_rate: 0.0002198792249524077, optimizer_name: Adam, weight_decay: 1.463658199499404e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:29:51,413] Trial 214 finished with value: 0.6681407345107934 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00024012495116516644, 'weight_decay': 1.4001824316874762e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 214: Test Accuracy = 0.6681\n",
      "trial:217 hidden_size: 64, num_layers: 4, learning_rate: 0.00033486220052791557, optimizer_name: Adam, weight_decay: 1.4410538731625438e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:29:56,227] Trial 215 finished with value: 0.591381553125876 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00030346216231679987, 'weight_decay': 1.4464039939827794e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 215: Test Accuracy = 0.5914\n",
      "trial:218 hidden_size: 256, num_layers: 4, learning_rate: 0.00024169417457968839, optimizer_name: Adam, weight_decay: 1.615135808274757e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:31:07,203] Trial 216 finished with value: 0.5786325577048874 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0002198792249524077, 'weight_decay': 1.463658199499404e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 216: Test Accuracy = 0.5786\n",
      "trial:219 hidden_size: 256, num_layers: 4, learning_rate: 0.00037462625058095277, optimizer_name: Adam, weight_decay: 2.4413422304732774e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:31:16,118] Trial 217 finished with value: 0.65991028875806 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00033486220052791557, 'weight_decay': 1.4410538731625438e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 217: Test Accuracy = 0.6599\n",
      "trial:220 hidden_size: 64, num_layers: 4, learning_rate: 0.0003898063573706531, optimizer_name: Adam, weight_decay: 1.6719108738307435e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:31:48,869] Trial 218 finished with value: 0.614506868516961 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00024169417457968839, 'weight_decay': 1.615135808274757e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 218: Test Accuracy = 0.6145\n",
      "trial:221 hidden_size: 64, num_layers: 4, learning_rate: 0.0004349278189850381, optimizer_name: Adam, weight_decay: 1.2500315634307332e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:33:13,163] Trial 221 finished with value: 0.6426218110456966 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0004349278189850381, 'weight_decay': 1.2500315634307332e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 221: Test Accuracy = 0.6426\n",
      "trial:222 hidden_size: 64, num_layers: 4, learning_rate: 0.0006231760909383639, optimizer_name: Adam, weight_decay: 9.860683207268065e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:33:18,274] Trial 220 finished with value: 0.5003541725072423 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0003898063573706531, 'weight_decay': 1.6719108738307435e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 220: Test Accuracy = 0.5004\n",
      "trial:223 hidden_size: 64, num_layers: 4, learning_rate: 0.00031172520057371297, optimizer_name: Adam, weight_decay: 1.7815563445947744e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:33:26,459] Trial 219 finished with value: 0.5322157742267078 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00037462625058095277, 'weight_decay': 2.4413422304732774e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 219: Test Accuracy = 0.5322\n",
      "trial:224 hidden_size: 1024, num_layers: 4, learning_rate: 0.0006047748158398073, optimizer_name: Adam, weight_decay: 9.57526096340571e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 14\n",
      "Trial 222: Test Accuracy = 0.6146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:34:59,932] Trial 222 finished with value: 0.6145647135781703 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0006231760909383639, 'weight_decay': 9.860683207268065e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:225 hidden_size: 64, num_layers: 4, learning_rate: 4.547542973132529e-08, optimizer_name: Adam, weight_decay: 1.786808111760631e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:37:11,042] Trial 224 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0006047748158398073, 'weight_decay': 9.57526096340571e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 224: Test Accuracy = 0.3333\n",
      "trial:226 hidden_size: 64, num_layers: 4, learning_rate: 0.00028967561991107113, optimizer_name: Adam, weight_decay: 1.754318053631827e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:37:12,371] Trial 223 finished with value: 0.5937072236239603 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00031172520057371297, 'weight_decay': 1.7815563445947744e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 223: Test Accuracy = 0.5937\n",
      "trial:227 hidden_size: 256, num_layers: 4, learning_rate: 8.041798335428069e-08, optimizer_name: Adam, weight_decay: 1.3792940566877644e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:38:02,675] Trial 226 finished with value: 0.6106608728156248 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00028967561991107113, 'weight_decay': 1.754318053631827e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 226: Test Accuracy = 0.6107\n",
      "trial:228 hidden_size: 256, num_layers: 4, learning_rate: 0.00020663642520347267, optimizer_name: Adam, weight_decay: 2.1911514382055888e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:38:11,878] Trial 225 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 4.547542973132529e-08, 'weight_decay': 1.786808111760631e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 225: Test Accuracy = 0.3333\n",
      "trial:229 hidden_size: 256, num_layers: 4, learning_rate: 0.00020601678097967096, optimizer_name: Adam, weight_decay: 1.4147278204236746e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 13\n",
      "Trial 228: Test Accuracy = 0.6240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:39:38,152] Trial 228 finished with value: 0.6240217736660125 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00020663642520347267, 'weight_decay': 2.1911514382055888e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:230 hidden_size: 256, num_layers: 4, learning_rate: 0.0004601812872228043, optimizer_name: Adam, weight_decay: 1.4695487252572575e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:39:52,307] Trial 229 finished with value: 0.7085526586300346 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00020601678097967096, 'weight_decay': 1.4147278204236746e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 229: Test Accuracy = 0.7086\n",
      "trial:231 hidden_size: 256, num_layers: 4, learning_rate: 0.00019524193425196035, optimizer_name: Adam, weight_decay: 1.3408593125167805e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:40:26,137] Trial 227 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 8.041798335428069e-08, 'weight_decay': 1.3792940566877644e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 227: Test Accuracy = 0.3333\n",
      "trial:232 hidden_size: 256, num_layers: 4, learning_rate: 0.00012785050738249864, optimizer_name: Adam, weight_decay: 1.2322589303952058e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:41:28,915] Trial 231 finished with value: 0.5952262405382674 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00019524193425196035, 'weight_decay': 1.3408593125167805e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 231: Test Accuracy = 0.5952\n",
      "trial:233 hidden_size: 256, num_layers: 4, learning_rate: 0.00012468865059007243, optimizer_name: Adam, weight_decay: 1.5908673740596646e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 19\n",
      "Trial 230: Test Accuracy = 0.6113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:42:03,309] Trial 230 finished with value: 0.6113324922904401 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0004601812872228043, 'weight_decay': 1.4695487252572575e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:234 hidden_size: 256, num_layers: 4, learning_rate: 0.00026353808825014836, optimizer_name: Adam, weight_decay: 1.2029263972933979e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:43:02,907] Trial 232 finished with value: 0.6209137463788431 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00012785050738249864, 'weight_decay': 1.2322589303952058e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 232: Test Accuracy = 0.6209\n",
      "trial:235 hidden_size: 256, num_layers: 4, learning_rate: 0.0002621558553398917, optimizer_name: Adam, weight_decay: 8.682650243188786e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:43:16,768] Trial 233 finished with value: 0.5989428090832633 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00012468865059007243, 'weight_decay': 1.5908673740596646e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 233: Test Accuracy = 0.5989\n",
      "trial:236 hidden_size: 256, num_layers: 4, learning_rate: 0.00025504470908496306, optimizer_name: Adam, weight_decay: 1.106027997869576e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:43:57,959] Trial 234 finished with value: 0.4817092795065882 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00026353808825014836, 'weight_decay': 1.2029263972933979e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 234: Test Accuracy = 0.4817\n",
      "trial:237 hidden_size: 128, num_layers: 4, learning_rate: 0.00034544272100613983, optimizer_name: Adam, weight_decay: 8.928235364239545e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:45:21,955] Trial 237 finished with value: 0.38881646575086437 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00034544272100613983, 'weight_decay': 8.928235364239545e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 237: Test Accuracy = 0.3888\n",
      "trial:238 hidden_size: 256, num_layers: 4, learning_rate: 0.00020574554404062206, optimizer_name: Adam, weight_decay: 1.0702252109250146e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:45:28,927] Trial 236 finished with value: 0.665757779646762 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00025504470908496306, 'weight_decay': 1.106027997869576e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 236: Test Accuracy = 0.6658\n",
      "trial:239 hidden_size: 256, num_layers: 4, learning_rate: 0.00017697378877676314, optimizer_name: Adam, weight_decay: 1.020462169951967e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:46:07,284] Trial 235 finished with value: 0.5082848331931595 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0002621558553398917, 'weight_decay': 8.682650243188786e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 235: Test Accuracy = 0.5083\n",
      "trial:240 hidden_size: 256, num_layers: 4, learning_rate: 0.00019638129878126815, optimizer_name: Adam, weight_decay: 1.0551120015756339e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:47:37,733] Trial 238 finished with value: 0.5615649004765909 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00020574554404062206, 'weight_decay': 1.0702252109250146e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 238: Test Accuracy = 0.5616\n",
      "trial:241 hidden_size: 256, num_layers: 4, learning_rate: 0.0001487472833487665, optimizer_name: Adam, weight_decay: 6.971365852353821e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:47:45,443] Trial 240 finished with value: 0.6390809270161667 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00019638129878126815, 'weight_decay': 1.0551120015756339e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 240: Test Accuracy = 0.6391\n",
      "trial:242 hidden_size: 256, num_layers: 4, learning_rate: 0.0001667453140535747, optimizer_name: Adam, weight_decay: 1.0022271626546467e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:48:25,984] Trial 239 finished with value: 0.4776673208111391 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00017697378877676314, 'weight_decay': 1.020462169951967e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 239: Test Accuracy = 0.4777\n",
      "trial:243 hidden_size: 256, num_layers: 4, learning_rate: 0.00044462266768218264, optimizer_name: Adam, weight_decay: 6.945553815231691e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:49:17,886] Trial 242 finished with value: 0.6813972525932156 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0001667453140535747, 'weight_decay': 1.0022271626546467e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 242: Test Accuracy = 0.6814\n",
      "trial:244 hidden_size: 256, num_layers: 4, learning_rate: 0.00014695413784839478, optimizer_name: Adam, weight_decay: 7.222971316759224e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 18\n",
      "Trial 241: Test Accuracy = 0.5610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:49:53,004] Trial 241 finished with value: 0.5609666386319035 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0001487472833487665, 'weight_decay': 6.971365852353821e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:245 hidden_size: 256, num_layers: 4, learning_rate: 0.00025310846441665844, optimizer_name: Adam, weight_decay: 8.170094070799219e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:51:33,826] Trial 244 finished with value: 0.5198599196336792 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00014695413784839478, 'weight_decay': 7.222971316759224e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 244: Test Accuracy = 0.5199\n",
      "trial:246 hidden_size: 256, num_layers: 4, learning_rate: 0.0002489691051911659, optimizer_name: Adam, weight_decay: 8.057072935055647e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:51:47,478] Trial 245 finished with value: 0.6466246145220073 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00025310846441665844, 'weight_decay': 8.170094070799219e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 245: Test Accuracy = 0.6466\n",
      "trial:247 hidden_size: 256, num_layers: 4, learning_rate: 0.00046405380899392016, optimizer_name: Adam, weight_decay: 1.1725229656353009e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:51:54,117] Trial 243 finished with value: 0.6107289038407625 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00044462266768218264, 'weight_decay': 6.945553815231691e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 243: Test Accuracy = 0.6107\n",
      "trial:248 hidden_size: 256, num_layers: 4, learning_rate: 0.0003284305334655996, optimizer_name: Adam, weight_decay: 0.0001325142084226051, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:53:54,068] Trial 247 finished with value: 0.6576317166619942 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00046405380899392016, 'weight_decay': 1.1725229656353009e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 247: Test Accuracy = 0.6576\n",
      "trial:249 hidden_size: 256, num_layers: 4, learning_rate: 0.0007115314613551308, optimizer_name: Adam, weight_decay: 0.0001401517888707313, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:54:14,355] Trial 248 finished with value: 0.6063342678254369 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0003284305334655996, 'weight_decay': 0.0001325142084226051, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 248: Test Accuracy = 0.6063\n",
      "trial:250 hidden_size: 256, num_layers: 4, learning_rate: 0.0006670084107232444, optimizer_name: Adam, weight_decay: 1.2056254609424631e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:55:06,135] Trial 246 finished with value: 0.6584735071488647 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0002489691051911659, 'weight_decay': 8.057072935055647e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 246: Test Accuracy = 0.6585\n",
      "trial:251 hidden_size: 256, num_layers: 4, learning_rate: 0.0007293715878398611, optimizer_name: Adam, weight_decay: 9.17112270655457e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:56:23,076] Trial 249 finished with value: 0.6144574338846837 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.1, 'learning_rate': 0.0007115314613551308, 'weight_decay': 0.0001401517888707313, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 249: Test Accuracy = 0.6145\n",
      "trial:252 hidden_size: 256, num_layers: 4, learning_rate: 0.0005794014315352803, optimizer_name: Adam, weight_decay: 8.990649567797524e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:56:46,312] Trial 251 finished with value: 0.538091299878516 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0007293715878398611, 'weight_decay': 9.17112270655457e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 251: Test Accuracy = 0.5381\n",
      "trial:253 hidden_size: 256, num_layers: 4, learning_rate: 0.0005097467884136117, optimizer_name: Adam, weight_decay: 8.627840994735429e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:56:50,665] Trial 250 finished with value: 0.6876740491542847 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0006670084107232444, 'weight_decay': 1.2056254609424631e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 250: Test Accuracy = 0.6877\n",
      "trial:254 hidden_size: 256, num_layers: 4, learning_rate: 0.0005091047010360976, optimizer_name: Adam, weight_decay: 1.1800377095257878e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:57:56,576] Trial 252 finished with value: 0.39476245210727967 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0005794014315352803, 'weight_decay': 8.990649567797524e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 252: Test Accuracy = 0.3948\n",
      "trial:255 hidden_size: 32, num_layers: 4, learning_rate: 0.0004262403063802958, optimizer_name: Adam, weight_decay: 1.2158334742212456e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:58:31,437] Trial 254 finished with value: 0.376708438463695 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0005091047010360976, 'weight_decay': 1.1800377095257878e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254: Test Accuracy = 0.3767\n",
      "trial:256 hidden_size: 32, num_layers: 4, learning_rate: 0.0003331652524327183, optimizer_name: Adam, weight_decay: 1.0276180936375457e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:59:43,661] Trial 253 finished with value: 0.6584304270628913 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0005097467884136117, 'weight_decay': 8.627840994735429e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 253: Test Accuracy = 0.6584\n",
      "trial:257 hidden_size: 32, num_layers: 4, learning_rate: 0.00037608190102980205, optimizer_name: Adam, weight_decay: 1.014446561293052e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 03:59:53,846] Trial 255 finished with value: 0.5989246799364545 and parameters: {'hidden_size': 32, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0004262403063802958, 'weight_decay': 1.2158334742212456e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 255: Test Accuracy = 0.5989\n",
      "trial:258 hidden_size: 256, num_layers: 4, learning_rate: 0.0003060046266072325, optimizer_name: Adam, weight_decay: 9.738060699276011e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:00:18,756] Trial 256 finished with value: 0.612020839173909 and parameters: {'hidden_size': 32, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0003331652524327183, 'weight_decay': 1.0276180936375457e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 256: Test Accuracy = 0.6120\n",
      "trial:259 hidden_size: 256, num_layers: 4, learning_rate: 0.00026950920068461094, optimizer_name: Adam, weight_decay: 8.352307217574557e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:00:59,708] Trial 257 finished with value: 0.6031223250163537 and parameters: {'hidden_size': 32, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00037608190102980205, 'weight_decay': 1.014446561293052e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 257: Test Accuracy = 0.6031\n",
      "trial:260 hidden_size: 256, num_layers: 4, learning_rate: 0.00024413588870277463, optimizer_name: Adam, weight_decay: 7.95862121126534e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:02:40,355] Trial 258 finished with value: 0.5460407438557144 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0003060046266072325, 'weight_decay': 9.738060699276011e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 258: Test Accuracy = 0.5460\n",
      "trial:261 hidden_size: 256, num_layers: 4, learning_rate: 0.0002261453364611623, optimizer_name: Adam, weight_decay: 7.589033254677353e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:02:43,653] Trial 259 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00026950920068461094, 'weight_decay': 8.352307217574557e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 259: Test Accuracy = 0.3333\n",
      "trial:262 hidden_size: 256, num_layers: 4, learning_rate: 0.0009798021696544412, optimizer_name: Adam, weight_decay: 7.645896768519808e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:03:48,875] Trial 260 finished with value: 0.6290007475936829 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00024413588870277463, 'weight_decay': 7.95862121126534e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 260: Test Accuracy = 0.6290\n",
      "trial:263 hidden_size: 1024, num_layers: 4, learning_rate: 0.0009520547760223004, optimizer_name: Adam, weight_decay: 6.279807036164371e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 16\n",
      "Trial 262: Test Accuracy = 0.7011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:05:46,546] Trial 262 finished with value: 0.7011011120456031 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0009798021696544412, 'weight_decay': 7.645896768519808e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:264 hidden_size: 512, num_layers: 2, learning_rate: 0.0014135548120042815, optimizer_name: Adam, weight_decay: 6.2704083724779184e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:06:34,004] Trial 261 finished with value: 0.5785712550228951 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0002261453364611623, 'weight_decay': 7.589033254677353e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 261: Test Accuracy = 0.5786\n",
      "trial:265 hidden_size: 512, num_layers: 2, learning_rate: 0.0010049034950287558, optimizer_name: Adam, weight_decay: 1.3320714474995898e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n",
      "Trial 263: Test Accuracy = 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:09:15,498] Trial 263 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0009520547760223004, 'weight_decay': 6.279807036164371e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:266 hidden_size: 512, num_layers: 2, learning_rate: 0.0012393968064619157, optimizer_name: Adam, weight_decay: 6.69973551388354e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:10:14,944] Trial 264 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 512, 'num_layers': 2, 'dropout': 0.2, 'learning_rate': 0.0014135548120042815, 'weight_decay': 6.2704083724779184e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 264: Test Accuracy = 0.3333\n",
      "trial:267 hidden_size: 64, num_layers: 4, learning_rate: 0.00012506956477944528, optimizer_name: Adam, weight_decay: 1.3140792933677858e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:10:49,370] Trial 265 finished with value: 0.44679123446406876 and parameters: {'hidden_size': 512, 'num_layers': 2, 'dropout': 0.2, 'learning_rate': 0.0010049034950287558, 'weight_decay': 1.3320714474995898e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 265: Test Accuracy = 0.4468\n",
      "trial:268 hidden_size: 64, num_layers: 4, learning_rate: 0.000120159924912491, optimizer_name: Adam, weight_decay: 6.9157128542482424e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:11:06,803] Trial 266 finished with value: 0.6193109989720587 and parameters: {'hidden_size': 512, 'num_layers': 2, 'dropout': 0.2, 'learning_rate': 0.0012393968064619157, 'weight_decay': 6.69973551388354e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 266: Test Accuracy = 0.6193\n",
      "trial:269 hidden_size: 64, num_layers: 4, learning_rate: 0.00011153594588999617, optimizer_name: Adam, weight_decay: 2.115176827870656e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:11:44,300] Trial 267 finished with value: 0.5800679375759276 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00012506956477944528, 'weight_decay': 1.3140792933677858e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 267: Test Accuracy = 0.5801\n",
      "trial:270 hidden_size: 256, num_layers: 4, learning_rate: 0.00018407404164598134, optimizer_name: Adam, weight_decay: 1.063233787401681e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:12:01,774] Trial 269 finished with value: 0.5243380992430614 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00011153594588999617, 'weight_decay': 2.115176827870656e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 269: Test Accuracy = 0.5243\n",
      "trial:271 hidden_size: 256, num_layers: 4, learning_rate: 0.00019357964623623126, optimizer_name: Adam, weight_decay: 2.842689800313062e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:12:32,765] Trial 268 finished with value: 0.6081181198018877 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.000120159924912491, 'weight_decay': 6.9157128542482424e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 268: Test Accuracy = 0.6081\n",
      "trial:272 hidden_size: 256, num_layers: 4, learning_rate: 0.00018854941130155817, optimizer_name: Adam, weight_decay: 1.0112285239739796e-05, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:13:48,870] Trial 271 finished with value: 0.5817298383328661 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00019357964623623126, 'weight_decay': 2.842689800313062e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 271: Test Accuracy = 0.5817\n",
      "trial:273 hidden_size: 256, num_layers: 4, learning_rate: 0.00018327515379728922, optimizer_name: Adam, weight_decay: 1.1140060939561143e-05, batch_size: 10, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:14:57,588] Trial 270 finished with value: 0.657906083543594 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00018407404164598134, 'weight_decay': 1.063233787401681e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 270: Test Accuracy = 0.6579\n",
      "trial:274 hidden_size: 128, num_layers: 4, learning_rate: 0.0003479144239208265, optimizer_name: Adam, weight_decay: 9.011503270348107e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:15:30,917] Trial 272 finished with value: 0.622669096346136 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00018854941130155817, 'weight_decay': 1.0112285239739796e-05, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 272: Test Accuracy = 0.6227\n",
      "trial:275 hidden_size: 128, num_layers: 4, learning_rate: 0.001960226622375752, optimizer_name: Adam, weight_decay: 7.68740230319061e-06, batch_size: 10, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:16:09,176] Trial 273 finished with value: 0.515362769834595 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00018327515379728922, 'weight_decay': 1.1140060939561143e-05, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 273: Test Accuracy = 0.5154\n",
      "trial:276 hidden_size: 128, num_layers: 4, learning_rate: 0.0003522664417399384, optimizer_name: Adam, weight_decay: 8.002550306575385e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:16:49,318] Trial 275 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.001960226622375752, 'weight_decay': 7.68740230319061e-06, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 275: Test Accuracy = 0.3333\n",
      "trial:277 hidden_size: 64, num_layers: 4, learning_rate: 1.8102561391432215e-06, optimizer_name: Adam, weight_decay: 8.268590401778688e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 23\n",
      "Trial 274: Test Accuracy = 0.6456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:16:57,148] Trial 274 finished with value: 0.6456016260162601 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0003479144239208265, 'weight_decay': 9.011503270348107e-06, 'batch_size': 10}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:278 hidden_size: 64, num_layers: 4, learning_rate: 7.320669465968164e-05, optimizer_name: Adam, weight_decay: 1.4362845229860929e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:17:33,936] Trial 276 finished with value: 0.6915039715914402 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0003522664417399384, 'weight_decay': 8.002550306575385e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 276: Test Accuracy = 0.6915\n",
      "trial:279 hidden_size: 128, num_layers: 4, learning_rate: 0.0008295291198224503, optimizer_name: Adam, weight_decay: 1.4755545349667482e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:18:04,000] Trial 277 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 1.8102561391432215e-06, 'weight_decay': 8.268590401778688e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 277: Test Accuracy = 0.3333\n",
      "trial:280 hidden_size: 128, num_layers: 4, learning_rate: 6.902394440047707e-07, optimizer_name: Adam, weight_decay: 1.4203848072485889e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:18:16,713] Trial 278 finished with value: 0.6523206242407252 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 7.320669465968164e-05, 'weight_decay': 1.4362845229860929e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 278: Test Accuracy = 0.6523\n",
      "trial:281 hidden_size: 128, num_layers: 4, learning_rate: 0.0008123391521054648, optimizer_name: Adam, weight_decay: 5.9584434103915e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:18:50,469] Trial 279 finished with value: 0.662417157275021 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0008295291198224503, 'weight_decay': 1.4755545349667482e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 279: Test Accuracy = 0.6624\n",
      "trial:282 hidden_size: 128, num_layers: 4, learning_rate: 0.0008456899350491674, optimizer_name: Adam, weight_decay: 1.6343130204177907e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:19:43,322] Trial 281 finished with value: 0.4981119521540043 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.0008123391521054648, 'weight_decay': 5.9584434103915e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 281: Test Accuracy = 0.4981\n",
      "trial:283 hidden_size: 128, num_layers: 4, learning_rate: 0.0008164948421083534, optimizer_name: Adam, weight_decay: 1.633926465807679e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:19:43,855] Trial 280 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 6.902394440047707e-07, 'weight_decay': 1.4203848072485889e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 280: Test Accuracy = 0.3333\n",
      "trial:284 hidden_size: 128, num_layers: 4, learning_rate: 0.0008033262467933941, optimizer_name: Adam, weight_decay: 1.6527370374785176e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:20:29,690] Trial 282 finished with value: 0.5781882067096533 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.0008456899350491674, 'weight_decay': 1.6343130204177907e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 282: Test Accuracy = 0.5782\n",
      "trial:285 hidden_size: 128, num_layers: 4, learning_rate: 0.0006009969463299965, optimizer_name: Adam, weight_decay: 1.1821608536050822e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 14\n",
      "Trial 283: Test Accuracy = 0.4532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:20:34,320] Trial 283 finished with value: 0.4531692365199514 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0008164948421083534, 'weight_decay': 1.633926465807679e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:286 hidden_size: 128, num_layers: 4, learning_rate: 0.0005779278606490696, optimizer_name: Adam, weight_decay: 1.1786355165202883e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:21:09,640] Trial 284 finished with value: 0.5692698813195028 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0008033262467933941, 'weight_decay': 1.6527370374785176e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 284: Test Accuracy = 0.5693\n",
      "trial:287 hidden_size: 64, num_layers: 4, learning_rate: 0.000549359918057512, optimizer_name: Adam, weight_decay: 1.2469904512601246e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:21:39,432] Trial 285 finished with value: 0.4525761143818335 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0006009969463299965, 'weight_decay': 1.1821608536050822e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 285: Test Accuracy = 0.4526\n",
      "trial:288 hidden_size: 64, num_layers: 4, learning_rate: 0.0011605528205257249, optimizer_name: Adam, weight_decay: 6.775061368266823e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:21:53,015] Trial 287 finished with value: 0.623769647696477 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.000549359918057512, 'weight_decay': 1.2469904512601246e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 287: Test Accuracy = 0.6238\n",
      "trial:289 hidden_size: 1024, num_layers: 4, learning_rate: 0.0011957142756846356, optimizer_name: Adam, weight_decay: 3.258199574475112e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 25\n",
      "Trial 286: Test Accuracy = 0.5846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:22:09,830] Trial 286 finished with value: 0.5846240538267452 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0005779278606490696, 'weight_decay': 1.1786355165202883e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:290 hidden_size: 64, num_layers: 4, learning_rate: 0.00039995282559765797, optimizer_name: Adam, weight_decay: 3.271052246544088e-05, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:24:38,595] Trial 288 finished with value: 0.6574802354920101 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0011605528205257249, 'weight_decay': 6.775061368266823e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 288: Test Accuracy = 0.6575\n",
      "trial:291 hidden_size: 1024, num_layers: 4, learning_rate: 0.00040113530416975227, optimizer_name: Adam, weight_decay: 9.532821243102885e-06, batch_size: 16, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 04:30:17,347] Trial 290 finished with value: 0.6279533688440333 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00039995282559765797, 'weight_decay': 3.271052246544088e-05, 'batch_size': 16}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 290: Test Accuracy = 0.6280\n",
      "trial:292 hidden_size: 1024, num_layers: 4, learning_rate: 0.00041510153306002166, optimizer_name: Adam, weight_decay: 2.3035007016820056e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 14\n",
      "Trial 289: Test Accuracy = 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 05:41:40,034] Trial 289 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0011957142756846356, 'weight_decay': 3.258199574475112e-05, 'batch_size': 16}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:293 hidden_size: 256, num_layers: 4, learning_rate: 0.00041282910425827516, optimizer_name: Adam, weight_decay: 1.0899003849816869e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n",
      "Trial 292: Test Accuracy = 0.3434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 06:03:18,328] Trial 292 finished with value: 0.34339080459770116 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00041510153306002166, 'weight_decay': 2.3035007016820056e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:294 hidden_size: 256, num_layers: 4, learning_rate: 0.00030202275172069864, optimizer_name: Adam, weight_decay: 9.574893133132388e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n",
      "Trial 291: Test Accuracy = 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 06:03:56,397] Trial 291 finished with value: 0.3333333333333333 and parameters: {'hidden_size': 1024, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00040113530416975227, 'weight_decay': 9.532821243102885e-06, 'batch_size': 16}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:295 hidden_size: 256, num_layers: 4, learning_rate: 9.940875233036612e-05, optimizer_name: Adam, weight_decay: 1.9690632883507983e-05, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 06:05:04,448] Trial 293 finished with value: 0.6634995794785534 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00041282910425827516, 'weight_decay': 1.0899003849816869e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 293: Test Accuracy = 0.6635\n",
      "trial:296 hidden_size: 256, num_layers: 4, learning_rate: 8.892747719330699e-05, optimizer_name: Adam, weight_decay: 1.1333722931793527e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 06:07:06,868] Trial 294 finished with value: 0.5800920474721988 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.00030202275172069864, 'weight_decay': 9.574893133132388e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 294: Test Accuracy = 0.5801\n",
      "trial:297 hidden_size: 256, num_layers: 1, learning_rate: 0.00014678198501497477, optimizer_name: Adam, weight_decay: 1.0201404362256364e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 06:07:20,212] Trial 295 finished with value: 0.6164550976544249 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 9.940875233036612e-05, 'weight_decay': 1.9690632883507983e-05, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 295: Test Accuracy = 0.6165\n",
      "trial:298 hidden_size: 256, num_layers: 4, learning_rate: 0.0001537122181035339, optimizer_name: Adam, weight_decay: 1.2911800711037775e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 06:07:30,229] Trial 296 finished with value: 0.6221564339781329 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 8.892747719330699e-05, 'weight_decay': 1.1333722931793527e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 296: Test Accuracy = 0.6222\n",
      "trial:299 hidden_size: 256, num_layers: 4, learning_rate: 0.00015823926337075371, optimizer_name: Adam, weight_decay: 1.0046251309207093e-06, batch_size: 32, label_smoothing: 0.3, factor: 1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 06:09:05,772] Trial 297 finished with value: 0.5915074292122231 and parameters: {'hidden_size': 256, 'num_layers': 1, 'dropout': 0.2, 'learning_rate': 0.00014678198501497477, 'weight_decay': 1.0201404362256364e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 297: Test Accuracy = 0.5915\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 06:09:34,220] Trial 298 finished with value: 0.5670592467993646 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.0001537122181035339, 'weight_decay': 1.2911800711037775e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 298: Test Accuracy = 0.5671\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 06:09:43,274] Trial 299 finished with value: 0.5654681805438745 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.2, 'learning_rate': 0.00015823926337075371, 'weight_decay': 1.0046251309207093e-06, 'batch_size': 32}. Best is trial 112 with value: 0.7098714138865526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 299: Test Accuracy = 0.5655\n",
      "Best hyperparameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.30000000000000004, 'learning_rate': 0.0003457860039763819, 'weight_decay': 5.944172232271371e-06, 'batch_size': 32}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "def objective(trial):\n",
    "    # Hyperparameter suggestions\n",
    "    hidden_size = trial.suggest_categorical(\"hidden_size\", [32,64,128,256,512,1024])\n",
    "    num_layers = trial.suggest_categorical(\"num_layers\", [1, 2, 3, 4])\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5, step=0.1)\n",
    "\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-8, 1e-2, log=True)\n",
    "    optimizer_name = \"Adam\"\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [10, 16, 32])\n",
    "    label_smoothing = 0.3\n",
    "    factor = 1\n",
    "\n",
    "    print(f\"trial:{trial.number} hidden_size: {hidden_size}, num_layers: {num_layers}, learning_rate: {learning_rate}, optimizer_name: {optimizer_name}, weight_decay: {weight_decay}, batch_size: {batch_size}, label_smoothing: {label_smoothing}, factor: {factor}\")\n",
    "\n",
    "    # Run only for 1 fold (fold 0)\n",
    "    test_fold_idx = 0\n",
    "    test_fold = fold_indices[test_fold_idx]\n",
    "    remaining_folds = [fold_indices[i] for i in range(5) if i != test_fold_idx]\n",
    "    val_fold_idx = test_fold_idx % 4\n",
    "    val_fold = remaining_folds[val_fold_idx]\n",
    "    train_folds = [fold for fold in remaining_folds if fold != val_fold]\n",
    "\n",
    "    # Prepare data with correct reshaping\n",
    "    train_data = np.concatenate([eeg_folds[j] for j in train_folds])\n",
    "    train_data = train_data.reshape(train_data.shape[0], train_data.shape[1], train_data.shape[2]*train_data.shape[3])\n",
    "    train_labels = np.concatenate([labels_folds[j] for j in train_folds])\n",
    "\n",
    "    val_data = eeg_folds[val_fold]\n",
    "    val_data = val_data.reshape(val_data.shape[0], val_data.shape[1], val_data.shape[2]*val_data.shape[3])\n",
    "    val_labels = labels_folds[val_fold]\n",
    "\n",
    "    test_data = eeg_folds[test_fold]\n",
    "    test_data = test_data.reshape(test_data.shape[0], test_data.shape[1], test_data.shape[2]*test_data.shape[3])\n",
    "    test_labels = labels_folds[test_fold]\n",
    "\n",
    "    balanced_train_data, balanced_train_labels = data_balancer(train_data, train_labels, factor=factor)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_dataset = TensorDataset(torch.tensor(balanced_train_data, dtype=torch.float32),\n",
    "                                  torch.tensor(balanced_train_labels, dtype=torch.long))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=1, pin_memory=True)\n",
    "\n",
    "    val_dataset = TensorDataset(torch.tensor(val_data, dtype=torch.float32),\n",
    "                                torch.tensor(val_labels, dtype=torch.long))\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=1, pin_memory=True)\n",
    "\n",
    "    test_dataset = TensorDataset(torch.tensor(test_data, dtype=torch.float32),\n",
    "                                 torch.tensor(test_labels, dtype=torch.long))\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=1, pin_memory=True)\n",
    "\n",
    "    # Initialize model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = LstmAttention(\n",
    "        input_size=672,  # Fixed input size: 224*3\n",
    "        hidden_size=hidden_size,\n",
    "        num_layers=num_layers,\n",
    "        num_classes=num_classes,\n",
    "        dropout=dropout\n",
    "    ).to(device)  # Move model to device immediately after creation\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "    optimizer_cls = {\"Adam\": optim.Adam, \"AdamW\": optim.AdamW, \"SGD\": optim.SGD}\n",
    "    optimizer = optimizer_cls[optimizer_name](model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=10)\n",
    "\n",
    "    epochs = 30\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_labels in val_loader:\n",
    "                val_inputs, val_labels = val_inputs.to(device, non_blocking=True), val_labels.to(device, non_blocking=True)\n",
    "                val_outputs = model(val_inputs)\n",
    "                loss = criterion(val_outputs, val_labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        early_stopping(val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "    early_stopping.load_best_model(model)\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = balanced_accuracy_score(all_labels, all_preds)\n",
    "    print(f\"Trial {trial.number}: Test Accuracy = {accuracy:.4f}\")\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    trial.report(accuracy, step=0)\n",
    "\n",
    "    if trial.should_prune():\n",
    "        raise optuna.TrialPruned()\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Start Optuna Study\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=optuna.samplers.TPESampler(),\n",
    "    pruner=optuna.pruners.MedianPruner(n_warmup_steps=5)\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=300, n_jobs=3) \n",
    "\n",
    "# Best result\n",
    "print(\"Best hyperparameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb2090e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3250846a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1wsVLiiebraTQaPsj9O9sap_UyjGLTS4y",
     "timestamp": 1747774865523
    }
   ]
  },
  "kernelspec": {
   "display_name": "cudaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
