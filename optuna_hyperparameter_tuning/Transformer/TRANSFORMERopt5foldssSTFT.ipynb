{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "626d84bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "\n",
    "from torchinfo import summary\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ad51f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define the folder path\n",
    "folder_path = r\"D:\\PYTHONIG\\newwindow\\NOTEBOOKS_2025\\aprilmay2025\\data\\numpy\\optunadata\\STFT\"\n",
    "\n",
    "# Load the numpy files into the respective arrays with the correct capitalized naming\n",
    "eeg_fold_1 = np.load(os.path.join(folder_path, 'STFT_DATA_FOLD_fold_1.npy'))\n",
    "labels_fold_1 = np.load(os.path.join(folder_path, 'STFT_LABELS_FOLD_fold_1.npy'))\n",
    "patients_fold_1 = np.load(os.path.join(folder_path, 'STFT_PATIENTS_FOLD_fold_1.npy'))\n",
    "\n",
    "eeg_fold_2 = np.load(os.path.join(folder_path, 'STFT_DATA_FOLD_fold_2.npy'))\n",
    "labels_fold_2 = np.load(os.path.join(folder_path, 'STFT_LABELS_FOLD_fold_2.npy'))\n",
    "patients_fold_2 = np.load(os.path.join(folder_path, 'STFT_PATIENTS_FOLD_fold_2.npy'))\n",
    "\n",
    "eeg_fold_3 = np.load(os.path.join(folder_path, 'STFT_DATA_FOLD_fold_3.npy'))\n",
    "labels_fold_3 = np.load(os.path.join(folder_path, 'STFT_LABELS_FOLD_fold_3.npy'))\n",
    "patients_fold_3 = np.load(os.path.join(folder_path, 'STFT_PATIENTS_FOLD_fold_3.npy'))\n",
    "\n",
    "eeg_fold_4 = np.load(os.path.join(folder_path, 'STFT_DATA_FOLD_fold_4.npy'))\n",
    "labels_fold_4 = np.load(os.path.join(folder_path, 'STFT_LABELS_FOLD_fold_4.npy'))\n",
    "patients_fold_4 = np.load(os.path.join(folder_path, 'STFT_PATIENTS_FOLD_fold_4.npy'))\n",
    "\n",
    "eeg_fold_5 = np.load(os.path.join(folder_path, 'STFT_DATA_FOLD_fold_5.npy'))\n",
    "labels_fold_5 = np.load(os.path.join(folder_path, 'STFT_LABELS_FOLD_fold_5.npy'))\n",
    "patients_fold_5 = np.load(os.path.join(folder_path, 'STFT_PATIENTS_FOLD_fold_5.npy'))\n",
    "\n",
    "eeg_folds = [eeg_fold_1, eeg_fold_2, eeg_fold_3, eeg_fold_4, eeg_fold_5]\n",
    "labels_folds = [labels_fold_1, labels_fold_2, labels_fold_3, labels_fold_4, labels_fold_5]\n",
    "patients_folds = [patients_fold_1, patients_fold_2, patients_fold_3, patients_fold_4, patients_fold_5]\n",
    "\n",
    "for i in range(len(eeg_folds)):\n",
    "    eeg_folds[i] = eeg_folds[i].astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9831e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_balancer(data, labels, factor):\n",
    "    # Count the number of samples in each class\n",
    "    num_class_0 = np.sum(labels == 0)\n",
    "    num_class_1 = np.sum(labels == 1)\n",
    "    num_class_2 = np.sum(labels == 2)\n",
    "\n",
    "    # Find the minimum number of samples across all classes\n",
    "    min_samples = min(num_class_0, num_class_1, num_class_2)\n",
    "\n",
    "    # Calculate the number of samples to take from each class\n",
    "    samples_per_class = min_samples // factor\n",
    "\n",
    "    # Randomly sample 'samples_per_class' from each class\n",
    "    class_0_indices = np.random.choice(np.where(labels == 0)[0], samples_per_class, replace=False)\n",
    "    class_1_indices = np.random.choice(np.where(labels == 1)[0], samples_per_class, replace=False)\n",
    "    class_2_indices = np.random.choice(np.where(labels == 2)[0], samples_per_class, replace=False)\n",
    "\n",
    "    # Combine balanced indices\n",
    "    balanced_indices = np.concatenate((class_0_indices, class_1_indices, class_2_indices))\n",
    "\n",
    "    # Shuffle the balanced indices\n",
    "    np.random.shuffle(balanced_indices)\n",
    "\n",
    "    # Create balanced training data and labels\n",
    "    balanced_data = data[balanced_indices]\n",
    "    balanced_labels = labels[balanced_indices]\n",
    "\n",
    "    return balanced_data, balanced_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0497bd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5):\n",
    "        \"\"\"\n",
    "        Initializes the early stopping mechanism based on divergence detection.\n",
    "\n",
    "        Args:\n",
    "            patience (int): Number of consecutive epochs with increasing validation loss\n",
    "                            before stopping.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "        self.best_model_state = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        \"\"\"\n",
    "        Checks if the validation loss is diverging and updates the state accordingly.\n",
    "\n",
    "        Args:\n",
    "            val_loss (float): Current epoch's validation loss.\n",
    "            model (torch.nn.Module): The model being trained.\n",
    "        \"\"\"\n",
    "        if self.best_loss is None or val_loss < self.best_loss:\n",
    "            # Improvement detected\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model_state = model.state_dict()\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            # Validation loss increased\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                print(f\"Divergence detected. Stopping training after {self.counter} epochs.\")\n",
    "                self.early_stop = True\n",
    "\n",
    "    def load_best_model(self, model):\n",
    "        \"\"\"\n",
    "        Restores the model to the state with the lowest validation loss.\n",
    "\n",
    "        Args:\n",
    "            model (torch.nn.Module): The model to restore.\n",
    "        \"\"\"\n",
    "        model.load_state_dict(self.best_model_state)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04c9bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "debug_mode_flag = False\n",
    "# Set the device to GPU if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "debug_mode_flag = False\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, dropout_rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=num_heads)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(embed_dim, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, embed_dim)\n",
    "        )\n",
    "        self.layernorm1 = nn.LayerNorm(embed_dim)\n",
    "        self.layernorm2 = nn.LayerNorm(embed_dim)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_output, _ = self.att(x, x, x)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_shape, num_classes, embed_dim=64, num_heads=2, ff_dim=64, num_transformer_blocks=2,dropout_rate=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.reshape = nn.Flatten(start_dim=2)  # Reshaping as in TensorFlow's Reshape\n",
    "        self.embedding = nn.Linear(input_shape[1] * input_shape[2], embed_dim)\n",
    "        self.transformer_blocks = nn.ModuleList(\n",
    "            [TransformerBlock(embed_dim, num_heads, ff_dim,dropout_rate=dropout_rate) for _ in range(num_transformer_blocks)]\n",
    "        )\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.reshape(x)\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(1, 0, 2)  # PyTorch uses (seq_len, batch, embed_dim) format for transformers\n",
    "        for transformer_block in self.transformer_blocks:\n",
    "            x = transformer_block(x)\n",
    "        x = x.permute(1, 2, 0)  # Back to (batch, embed_dim, seq_len)\n",
    "        x = self.global_avg_pool(x).squeeze(-1)\n",
    "        x = self.dropout(x)\n",
    "        return self.classifier(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb53c211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model  = TransformerModel(input_shape=(224,224,3),num_classes=3) # declare model here\n",
    "randomdata = torch.randn((1,224,224,3))\n",
    "output = model(randomdata)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5c4cb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# pca = sklearn.decomposition.PCA(3)\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "fold_indices = np.arange(5)\n",
    "fold_indices = np.random.permutation(fold_indices)\n",
    "val_fold_indices = np.roll(fold_indices, 1)\n",
    "\n",
    "input_shape = (3,224,224)\n",
    "num_classes = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5f665b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\cudaenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-06-03 18:26:45,519] A new study created in memory with name: no-name-24ddd026-02af-4a62-baf1-635b7d7ea6a8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: num_heads=1, num_transformer_blocks=1, learning_rate=0.0013193336254679069, optimizer=AdamW, weight_decay=4.347817447849854e-06, batch_size=32,factor=1Hyperparameters: num_heads=1, num_transformer_blocks=1, learning_rate=0.00679358174295443, optimizer=Adam, weight_decay=0.0006566370702890061, batch_size=16,factor=1\n",
      "\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 18:27:40,753] Trial 1 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 2048, 'dropout_rate': 0.43263635416977186, 'embed_dim': 2048, 'learning_rate': 0.0013193336254679069, 'optimizer': 'AdamW', 'weight_decay': 4.347817447849854e-06, 'batch_size': 32, 'num_heads': 1, 'num_transformer_blocks': 1}. Best is trial 1 with value: 0.3333333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1, Fold 1: Test Accuracy = 0.3333\n",
      "Hyperparameters: num_heads=1, num_transformer_blocks=32, learning_rate=0.04807875297313321, optimizer=AdamW, weight_decay=3.484426353895784e-06, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 19\n",
      "Trial 0, Fold 1: Test Accuracy = 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 18:31:10,133] Trial 0 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 256, 'dropout_rate': 0.43362332700336836, 'embed_dim': 1024, 'learning_rate': 0.00679358174295443, 'optimizer': 'Adam', 'weight_decay': 0.0006566370702890061, 'batch_size': 16, 'num_heads': 1, 'num_transformer_blocks': 1}. Best is trial 1 with value: 0.3333333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: num_heads=2, num_transformer_blocks=4, learning_rate=0.008186968632148342, optimizer=AdamW, weight_decay=3.204216421393228e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 12\n",
      "Trial 2, Fold 1: Test Accuracy = 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 18:44:32,662] Trial 2 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 256, 'dropout_rate': 0.1738276010475397, 'embed_dim': 2048, 'learning_rate': 0.04807875297313321, 'optimizer': 'AdamW', 'weight_decay': 3.484426353895784e-06, 'batch_size': 32, 'num_heads': 1, 'num_transformer_blocks': 32}. Best is trial 1 with value: 0.3333333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: num_heads=16, num_transformer_blocks=8, learning_rate=1.5750531398696317e-06, optimizer=AdamW, weight_decay=0.00010553449421366309, batch_size=16,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 19\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 18\n",
      "Trial 3, Fold 1: Test Accuracy = 0.3333\n",
      "Trial 4, Fold 1: Test Accuracy = 0.5130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 18:47:50,442] Trial 4 finished with value: 0.5130330810204654 and parameters: {'ff_dim': 1024, 'dropout_rate': 0.1394854895462511, 'embed_dim': 64, 'learning_rate': 1.5750531398696317e-06, 'optimizer': 'AdamW', 'weight_decay': 0.00010553449421366309, 'batch_size': 16, 'num_heads': 16, 'num_transformer_blocks': 8}. Best is trial 4 with value: 0.5130330810204654.\n",
      "[I 2025-06-03 18:47:50,459] Trial 3 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 32, 'dropout_rate': 0.27530344424204845, 'embed_dim': 1024, 'learning_rate': 0.008186968632148342, 'optimizer': 'AdamW', 'weight_decay': 3.204216421393228e-05, 'batch_size': 10, 'num_heads': 2, 'num_transformer_blocks': 4}. Best is trial 4 with value: 0.5130330810204654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=1.2583875745165507e-05, optimizer=AdamW, weight_decay=2.589471277662896e-05, batch_size=32,factor=1\n",
      "Hyperparameters: num_heads=4, num_transformer_blocks=16, learning_rate=8.375511762014259e-05, optimizer=Adam, weight_decay=0.000544808017025773, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 18:49:33,758] Trial 6 finished with value: 0.3568858050649472 and parameters: {'ff_dim': 256, 'dropout_rate': 0.324941841283681, 'embed_dim': 256, 'learning_rate': 8.375511762014259e-05, 'optimizer': 'Adam', 'weight_decay': 0.000544808017025773, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 16}. Best is trial 4 with value: 0.5130330810204654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6, Fold 1: Test Accuracy = 0.3569\n",
      "Hyperparameters: num_heads=16, num_transformer_blocks=8, learning_rate=7.693678195784438e-06, optimizer=Adam, weight_decay=0.00011078363714101272, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 18:49:39,172] Trial 5 finished with value: 0.5881394262218484 and parameters: {'ff_dim': 128, 'dropout_rate': 0.3692721063835519, 'embed_dim': 256, 'learning_rate': 1.2583875745165507e-05, 'optimizer': 'AdamW', 'weight_decay': 2.589471277662896e-05, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 5 with value: 0.5881394262218484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5, Fold 1: Test Accuracy = 0.5881\n",
      "Hyperparameters: num_heads=1, num_transformer_blocks=32, learning_rate=0.0970330469435641, optimizer=AdamW, weight_decay=1.4287596891987518e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 18:51:08,108] Trial 7 finished with value: 0.56460685917204 and parameters: {'ff_dim': 32, 'dropout_rate': 0.3445514801480976, 'embed_dim': 512, 'learning_rate': 7.693678195784438e-06, 'optimizer': 'Adam', 'weight_decay': 0.00011078363714101272, 'batch_size': 32, 'num_heads': 16, 'num_transformer_blocks': 8}. Best is trial 5 with value: 0.5881394262218484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7, Fold 1: Test Accuracy = 0.5646\n",
      "Hyperparameters: num_heads=1, num_transformer_blocks=4, learning_rate=0.0105406404344277, optimizer=Adam, weight_decay=1.38414468782579e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 18:51:15,994] Trial 8 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 512, 'dropout_rate': 0.3328680691280972, 'embed_dim': 32, 'learning_rate': 0.0970330469435641, 'optimizer': 'AdamW', 'weight_decay': 1.4287596891987518e-06, 'batch_size': 10, 'num_heads': 1, 'num_transformer_blocks': 32}. Best is trial 5 with value: 0.5881394262218484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8, Fold 1: Test Accuracy = 0.3333\n",
      "Hyperparameters: num_heads=1, num_transformer_blocks=1, learning_rate=0.0001237607747730718, optimizer=AdamW, weight_decay=0.00013490139993485483, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 18:52:17,035] Trial 9 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 1024, 'dropout_rate': 0.4766191822073682, 'embed_dim': 64, 'learning_rate': 0.0105406404344277, 'optimizer': 'Adam', 'weight_decay': 1.38414468782579e-06, 'batch_size': 10, 'num_heads': 1, 'num_transformer_blocks': 4}. Best is trial 5 with value: 0.5881394262218484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9, Fold 1: Test Accuracy = 0.3333\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=2, learning_rate=1.4825323936761478e-07, optimizer=AdamW, weight_decay=1.4042817096237775e-05, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 18:52:20,188] Trial 10 finished with value: 0.5484235118213251 and parameters: {'ff_dim': 64, 'dropout_rate': 0.425025272326211, 'embed_dim': 32, 'learning_rate': 0.0001237607747730718, 'optimizer': 'AdamW', 'weight_decay': 0.00013490139993485483, 'batch_size': 10, 'num_heads': 1, 'num_transformer_blocks': 1}. Best is trial 5 with value: 0.5881394262218484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10, Fold 1: Test Accuracy = 0.5484\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=8.054615135714524e-07, optimizer=Adam, weight_decay=2.8311792140434e-05, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 18:54:09,924] Trial 11 finished with value: 0.43820605550883096 and parameters: {'ff_dim': 128, 'dropout_rate': 0.2282748135637853, 'embed_dim': 256, 'learning_rate': 1.4825323936761478e-07, 'optimizer': 'AdamW', 'weight_decay': 1.4042817096237775e-05, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 2}. Best is trial 5 with value: 0.5881394262218484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11, Fold 1: Test Accuracy = 0.4382\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=9.828119315447494e-06, optimizer=Adam, weight_decay=7.190269039180811e-05, batch_size=32,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 18:54:28,938] Trial 12 finished with value: 0.5846976918045043 and parameters: {'ff_dim': 128, 'dropout_rate': 0.2483319449786801, 'embed_dim': 512, 'learning_rate': 8.054615135714524e-07, 'optimizer': 'Adam', 'weight_decay': 2.8311792140434e-05, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 5 with value: 0.5881394262218484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12, Fold 1: Test Accuracy = 0.5847\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=2.8651652621528425e-06, optimizer=Adam, weight_decay=2.2876768104774008e-05, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 18:55:49,344] Trial 13 finished with value: 0.5875227548827212 and parameters: {'ff_dim': 32, 'dropout_rate': 0.35571723810745565, 'embed_dim': 512, 'learning_rate': 9.828119315447494e-06, 'optimizer': 'Adam', 'weight_decay': 7.190269039180811e-05, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 5 with value: 0.5881394262218484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 13, Fold 1: Test Accuracy = 0.5875\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=1.7769287351742334e-05, optimizer=Adam, weight_decay=4.3021903523266696e-05, batch_size=32,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 18:56:36,450] Trial 14 finished with value: 0.5810396224651901 and parameters: {'ff_dim': 128, 'dropout_rate': 0.25076649982390004, 'embed_dim': 128, 'learning_rate': 2.8651652621528425e-06, 'optimizer': 'Adam', 'weight_decay': 2.2876768104774008e-05, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 5 with value: 0.5881394262218484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14, Fold 1: Test Accuracy = 0.5810\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=3.461539792790534e-05, optimizer=Adam, weight_decay=0.0002545677491856814, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 18:56:41,542] Trial 15 finished with value: 0.5656072329688814 and parameters: {'ff_dim': 128, 'dropout_rate': 0.3829465076196591, 'embed_dim': 128, 'learning_rate': 1.7769287351742334e-05, 'optimizer': 'Adam', 'weight_decay': 4.3021903523266696e-05, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 5 with value: 0.5881394262218484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15, Fold 1: Test Accuracy = 0.5656\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=2, learning_rate=0.00010986100171511135, optimizer=AdamW, weight_decay=8.739723735712548e-06, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 18:58:17,112] Trial 16 finished with value: 0.5919292589477619 and parameters: {'ff_dim': 32, 'dropout_rate': 0.37836353824573477, 'embed_dim': 512, 'learning_rate': 3.461539792790534e-05, 'optimizer': 'Adam', 'weight_decay': 0.0002545677491856814, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 16 with value: 0.5919292589477619.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 16, Fold 1: Test Accuracy = 0.5919\n",
      "Hyperparameters: num_heads=4, num_transformer_blocks=16, learning_rate=0.0001178661737332715, optimizer=AdamW, weight_decay=0.0002722351003260034, batch_size=16,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 18:58:43,241] Trial 17 finished with value: 0.5204137931034483 and parameters: {'ff_dim': 32, 'dropout_rate': 0.37371446721344487, 'embed_dim': 256, 'learning_rate': 0.00010986100171511135, 'optimizer': 'AdamW', 'weight_decay': 8.739723735712548e-06, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 2}. Best is trial 16 with value: 0.5919292589477619.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 17, Fold 1: Test Accuracy = 0.5204\n",
      "Hyperparameters: num_heads=4, num_transformer_blocks=16, learning_rate=0.0004081248932659297, optimizer=Adam, weight_decay=0.0002608156045259721, batch_size=16,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 18:59:18,044] Trial 18 finished with value: 0.5492045603214654 and parameters: {'ff_dim': 512, 'dropout_rate': 0.3922491742392207, 'embed_dim': 256, 'learning_rate': 0.0001178661737332715, 'optimizer': 'AdamW', 'weight_decay': 0.0002722351003260034, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 16}. Best is trial 16 with value: 0.5919292589477619.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 18, Fold 1: Test Accuracy = 0.5492\n",
      "Hyperparameters: num_heads=2, num_transformer_blocks=8, learning_rate=0.0007563807668614231, optimizer=Adam, weight_decay=0.0002934494374891318, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 11\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:00:09,767] Trial 20 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 64, 'dropout_rate': 0.48754295458125907, 'embed_dim': 512, 'learning_rate': 0.0007563807668614231, 'optimizer': 'Adam', 'weight_decay': 0.0002934494374891318, 'batch_size': 32, 'num_heads': 2, 'num_transformer_blocks': 8}. Best is trial 16 with value: 0.5919292589477619.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20, Fold 1: Test Accuracy = 0.3333\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=2.853105348794372e-07, optimizer=Adam, weight_decay=0.00022740508011197526, batch_size=16,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:00:10,146] Trial 19 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 64, 'dropout_rate': 0.4958121341284249, 'embed_dim': 256, 'learning_rate': 0.0004081248932659297, 'optimizer': 'Adam', 'weight_decay': 0.0002608156045259721, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 16}. Best is trial 16 with value: 0.5919292589477619.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 19, Fold 1: Test Accuracy = 0.3333\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=2.665825201952351e-05, optimizer=Adam, weight_decay=5.516487755530608e-05, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:01:31,248] Trial 22 finished with value: 0.5435378936547987 and parameters: {'ff_dim': 32, 'dropout_rate': 0.30665238904471165, 'embed_dim': 512, 'learning_rate': 2.665825201952351e-05, 'optimizer': 'Adam', 'weight_decay': 5.516487755530608e-05, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 16 with value: 0.5919292589477619.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 22, Fold 1: Test Accuracy = 0.5435\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=6.383854380731627e-06, optimizer=Adam, weight_decay=8.656933512509698e-05, batch_size=32,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:02:36,835] Trial 21 finished with value: 0.5520170077562845 and parameters: {'ff_dim': 2048, 'dropout_rate': 0.29781919974826393, 'embed_dim': 512, 'learning_rate': 2.853105348794372e-07, 'optimizer': 'Adam', 'weight_decay': 0.00022740508011197526, 'batch_size': 16, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 16 with value: 0.5919292589477619.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 21, Fold 1: Test Accuracy = 0.5520\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=6.6810291475187645e-06, optimizer=Adam, weight_decay=7.171869442970251e-05, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:03:43,518] Trial 23 finished with value: 0.5422499766376974 and parameters: {'ff_dim': 32, 'dropout_rate': 0.36831839487237095, 'embed_dim': 512, 'learning_rate': 6.383854380731627e-06, 'optimizer': 'Adam', 'weight_decay': 8.656933512509698e-05, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 16 with value: 0.5919292589477619.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 23, Fold 1: Test Accuracy = 0.5422\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=1.9946131783322012e-05, optimizer=Adam, weight_decay=1.2461233524659157e-05, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:04:24,826] Trial 24 finished with value: 0.5105493879076722 and parameters: {'ff_dim': 32, 'dropout_rate': 0.37126941384032125, 'embed_dim': 512, 'learning_rate': 6.6810291475187645e-06, 'optimizer': 'Adam', 'weight_decay': 7.171869442970251e-05, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 16 with value: 0.5919292589477619.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 24, Fold 1: Test Accuracy = 0.5105\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=3.9184066289991565e-05, optimizer=Adam, weight_decay=2.0147478549329628e-05, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:04:57,911] Trial 25 finished with value: 0.54753826745164 and parameters: {'ff_dim': 32, 'dropout_rate': 0.40691749661151494, 'embed_dim': 512, 'learning_rate': 1.9946131783322012e-05, 'optimizer': 'Adam', 'weight_decay': 1.2461233524659157e-05, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 16 with value: 0.5919292589477619.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25, Fold 1: Test Accuracy = 0.5475\n",
      "Hyperparameters: num_heads=2, num_transformer_blocks=2, learning_rate=3.8834055973784724e-05, optimizer=AdamW, weight_decay=0.0009153467137366323, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:05:31,843] Trial 26 finished with value: 0.6503238949630876 and parameters: {'ff_dim': 32, 'dropout_rate': 0.4099952333473971, 'embed_dim': 512, 'learning_rate': 3.9184066289991565e-05, 'optimizer': 'Adam', 'weight_decay': 2.0147478549329628e-05, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26, Fold 1: Test Accuracy = 0.6503\n",
      "Hyperparameters: num_heads=2, num_transformer_blocks=4, learning_rate=5.258486107197146e-05, optimizer=AdamW, weight_decay=0.0009970642366440889, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:06:10,640] Trial 27 finished with value: 0.4874581814783665 and parameters: {'ff_dim': 128, 'dropout_rate': 0.3508962316260365, 'embed_dim': 64, 'learning_rate': 3.8834055973784724e-05, 'optimizer': 'AdamW', 'weight_decay': 0.0009153467137366323, 'batch_size': 32, 'num_heads': 2, 'num_transformer_blocks': 2}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 27, Fold 1: Test Accuracy = 0.4875\n",
      "Hyperparameters: num_heads=16, num_transformer_blocks=4, learning_rate=0.0002954607860354472, optimizer=AdamW, weight_decay=6.927121073224244e-06, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:06:43,309] Trial 28 finished with value: 0.5501085879824316 and parameters: {'ff_dim': 128, 'dropout_rate': 0.43918549983202815, 'embed_dim': 64, 'learning_rate': 5.258486107197146e-05, 'optimizer': 'AdamW', 'weight_decay': 0.0009970642366440889, 'batch_size': 32, 'num_heads': 2, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 28, Fold 1: Test Accuracy = 0.5501\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=32, learning_rate=0.00027951500401996425, optimizer=Adam, weight_decay=5.48089923804259e-06, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:07:01,553] Trial 29 finished with value: 0.47816792823100646 and parameters: {'ff_dim': 512, 'dropout_rate': 0.46050759585520085, 'embed_dim': 1024, 'learning_rate': 0.0002954607860354472, 'optimizer': 'AdamW', 'weight_decay': 6.927121073224244e-06, 'batch_size': 32, 'num_heads': 16, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 29, Fold 1: Test Accuracy = 0.4782\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=32, learning_rate=0.00167039924591795, optimizer=Adam, weight_decay=1.8696214179322713e-05, batch_size=16,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:07:51,902] Trial 30 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 512, 'dropout_rate': 0.4055456629761428, 'embed_dim': 128, 'learning_rate': 0.00027951500401996425, 'optimizer': 'Adam', 'weight_decay': 5.48089923804259e-06, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 32}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30, Fold 1: Test Accuracy = 0.3333\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=1.20114594047942e-05, optimizer=Adam, weight_decay=1.691727670649004e-05, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:08:17,841] Trial 31 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 1024, 'dropout_rate': 0.4169491407232981, 'embed_dim': 32, 'learning_rate': 0.00167039924591795, 'optimizer': 'Adam', 'weight_decay': 1.8696214179322713e-05, 'batch_size': 16, 'num_heads': 8, 'num_transformer_blocks': 32}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 31, Fold 1: Test Accuracy = 0.3333\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=1, learning_rate=1.0832884746780947e-05, optimizer=Adam, weight_decay=3.9571476864810075e-05, batch_size=32,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:10:02,661] Trial 32 finished with value: 0.5051187739463602 and parameters: {'ff_dim': 32, 'dropout_rate': 0.3085809134278773, 'embed_dim': 512, 'learning_rate': 1.20114594047942e-05, 'optimizer': 'Adam', 'weight_decay': 1.691727670649004e-05, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 32, Fold 1: Test Accuracy = 0.5051\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=2.8234511617658198e-06, optimizer=Adam, weight_decay=0.00017212732399228282, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:10:17,986] Trial 33 finished with value: 0.589484440706476 and parameters: {'ff_dim': 32, 'dropout_rate': 0.4420138205390315, 'embed_dim': 512, 'learning_rate': 1.0832884746780947e-05, 'optimizer': 'Adam', 'weight_decay': 3.9571476864810075e-05, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 1}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 33, Fold 1: Test Accuracy = 0.5895\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=1, learning_rate=2.3251809269924285e-06, optimizer=Adam, weight_decay=2.3727545265504024e-06, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 18\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:11:30,237] Trial 34 finished with value: 0.5415654611718531 and parameters: {'ff_dim': 2048, 'dropout_rate': 0.45154090602438723, 'embed_dim': 512, 'learning_rate': 2.8234511617658198e-06, 'optimizer': 'Adam', 'weight_decay': 0.00017212732399228282, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 34, Fold 1: Test Accuracy = 0.5416\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=1, learning_rate=1.2138972626989682e-06, optimizer=Adam, weight_decay=4.275895045137623e-05, batch_size=32,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:11:31,647] Trial 35 finished with value: 0.57123483786562 and parameters: {'ff_dim': 2048, 'dropout_rate': 0.4566001048602476, 'embed_dim': 2048, 'learning_rate': 2.3251809269924285e-06, 'optimizer': 'Adam', 'weight_decay': 2.3727545265504024e-06, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 1}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 35, Fold 1: Test Accuracy = 0.5712\n",
      "Hyperparameters: num_heads=16, num_transformer_blocks=1, learning_rate=5.611915525237646e-05, optimizer=AdamW, weight_decay=3.583660228762311e-05, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:12:52,372] Trial 37 finished with value: 0.4992127838519765 and parameters: {'ff_dim': 256, 'dropout_rate': 0.39798523932290236, 'embed_dim': 2048, 'learning_rate': 5.611915525237646e-05, 'optimizer': 'AdamW', 'weight_decay': 3.583660228762311e-05, 'batch_size': 32, 'num_heads': 16, 'num_transformer_blocks': 1}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 37, Fold 1: Test Accuracy = 0.4992\n",
      "Hyperparameters: num_heads=4, num_transformer_blocks=1, learning_rate=1.1161912843931452e-06, optimizer=Adam, weight_decay=0.000414233460777398, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:13:26,357] Trial 36 finished with value: 0.5768641248481451 and parameters: {'ff_dim': 256, 'dropout_rate': 0.4662807857082775, 'embed_dim': 2048, 'learning_rate': 1.2138972626989682e-06, 'optimizer': 'Adam', 'weight_decay': 4.275895045137623e-05, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 1}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 36, Fold 1: Test Accuracy = 0.5769\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=1, learning_rate=4.342119573967396e-07, optimizer=Adam, weight_decay=1.055988602980755e-05, batch_size=10,factor=1\n",
      "Trial 38, Fold 1: Test Accuracy = 0.5655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:15:24,244] Trial 38 finished with value: 0.5654959349593496 and parameters: {'ff_dim': 32, 'dropout_rate': 0.10166195663993813, 'embed_dim': 256, 'learning_rate': 1.1161912843931452e-06, 'optimizer': 'Adam', 'weight_decay': 0.000414233460777398, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 1}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: num_heads=1, num_transformer_blocks=1, learning_rate=0.003404100809208248, optimizer=AdamW, weight_decay=1.0365345849494139e-05, batch_size=32,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:16:04,174] Trial 39 finished with value: 0.5933844500513971 and parameters: {'ff_dim': 32, 'dropout_rate': 0.4334423186210287, 'embed_dim': 1024, 'learning_rate': 4.342119573967396e-07, 'optimizer': 'Adam', 'weight_decay': 1.055988602980755e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 1}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 39, Fold 1: Test Accuracy = 0.5934\n",
      "Hyperparameters: num_heads=1, num_transformer_blocks=1, learning_rate=5.827358066427951e-07, optimizer=Adam, weight_decay=3.1703449730300798e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:16:49,675] Trial 40 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 32, 'dropout_rate': 0.4356615826519961, 'embed_dim': 1024, 'learning_rate': 0.003404100809208248, 'optimizer': 'AdamW', 'weight_decay': 1.0365345849494139e-05, 'batch_size': 32, 'num_heads': 1, 'num_transformer_blocks': 1}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 40, Fold 1: Test Accuracy = 0.3333\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=1, learning_rate=4.553325086585026e-07, optimizer=Adam, weight_decay=2.3880727047067904e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:18:28,035] Trial 41 finished with value: 0.5140932623119334 and parameters: {'ff_dim': 32, 'dropout_rate': 0.4378412177633219, 'embed_dim': 1024, 'learning_rate': 5.827358066427951e-07, 'optimizer': 'Adam', 'weight_decay': 3.1703449730300798e-06, 'batch_size': 10, 'num_heads': 1, 'num_transformer_blocks': 1}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 41, Fold 1: Test Accuracy = 0.5141\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=1, learning_rate=3.625518171447465e-07, optimizer=Adam, weight_decay=2.2825359494028837e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:18:34,638] Trial 42 finished with value: 0.5461626016260163 and parameters: {'ff_dim': 32, 'dropout_rate': 0.425881064436517, 'embed_dim': 1024, 'learning_rate': 4.553325086585026e-07, 'optimizer': 'Adam', 'weight_decay': 2.3880727047067904e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 1}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 42, Fold 1: Test Accuracy = 0.5462\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=1, learning_rate=1.1533543249169794e-07, optimizer=Adam, weight_decay=8.141500549058788e-06, batch_size=10,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:20:55,382] Trial 43 finished with value: 0.6279325296701243 and parameters: {'ff_dim': 32, 'dropout_rate': 0.41853152648379743, 'embed_dim': 1024, 'learning_rate': 3.625518171447465e-07, 'optimizer': 'Adam', 'weight_decay': 2.2825359494028837e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 1}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 43, Fold 1: Test Accuracy = 0.6279\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=1, learning_rate=2.2642327719247237e-07, optimizer=Adam, weight_decay=7.782325917807199e-06, batch_size=10,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:21:02,026] Trial 44 finished with value: 0.5382738996355481 and parameters: {'ff_dim': 32, 'dropout_rate': 0.32993800819965863, 'embed_dim': 1024, 'learning_rate': 1.1533543249169794e-07, 'optimizer': 'Adam', 'weight_decay': 8.141500549058788e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 1}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 44, Fold 1: Test Accuracy = 0.5383\n",
      "Hyperparameters: num_heads=16, num_transformer_blocks=1, learning_rate=1.9341478330529375e-07, optimizer=Adam, weight_decay=5.379037611203741e-06, batch_size=10,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:23:23,113] Trial 45 finished with value: 0.5602399775721896 and parameters: {'ff_dim': 32, 'dropout_rate': 0.47655697323436064, 'embed_dim': 1024, 'learning_rate': 2.2642327719247237e-07, 'optimizer': 'Adam', 'weight_decay': 7.782325917807199e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 1}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 45, Fold 1: Test Accuracy = 0.5602\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=1, learning_rate=3.4398216475610645e-07, optimizer=Adam, weight_decay=4.3924727014694645e-06, batch_size=10,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:23:29,691] Trial 46 finished with value: 0.5666112512849266 and parameters: {'ff_dim': 32, 'dropout_rate': 0.4726099936009171, 'embed_dim': 1024, 'learning_rate': 1.9341478330529375e-07, 'optimizer': 'Adam', 'weight_decay': 5.379037611203741e-06, 'batch_size': 10, 'num_heads': 16, 'num_transformer_blocks': 1}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 46, Fold 1: Test Accuracy = 0.5666\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=1, learning_rate=3.5287372684269858e-06, optimizer=Adam, weight_decay=1.3677150368012854e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:24:40,058] Trial 48 finished with value: 0.5822595084571535 and parameters: {'ff_dim': 1024, 'dropout_rate': 0.41576433577066946, 'embed_dim': 1024, 'learning_rate': 3.5287372684269858e-06, 'optimizer': 'Adam', 'weight_decay': 1.3677150368012854e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 1}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 48, Fold 1: Test Accuracy = 0.5823\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=16, learning_rate=4.14795649448384e-07, optimizer=Adam, weight_decay=1.9985968023079202e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:25:46,612] Trial 47 finished with value: 0.6157637603962246 and parameters: {'ff_dim': 32, 'dropout_rate': 0.18991275507279126, 'embed_dim': 1024, 'learning_rate': 3.4398216475610645e-07, 'optimizer': 'Adam', 'weight_decay': 4.3924727014694645e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 1}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 47, Fold 1: Test Accuracy = 0.6158\n",
      "Hyperparameters: num_heads=2, num_transformer_blocks=16, learning_rate=3.739499550402986e-07, optimizer=Adam, weight_decay=1.0077895513902973e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:28:29,676] Trial 49 finished with value: 0.5930750397159145 and parameters: {'ff_dim': 32, 'dropout_rate': 0.18850310956085298, 'embed_dim': 512, 'learning_rate': 4.14795649448384e-07, 'optimizer': 'Adam', 'weight_decay': 1.9985968023079202e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 16}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 49, Fold 1: Test Accuracy = 0.5931\n",
      "Hyperparameters: num_heads=2, num_transformer_blocks=16, learning_rate=4.2083934470617656e-07, optimizer=Adam, weight_decay=1.0356845590549609e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:29:26,212] Trial 50 finished with value: 0.45633632370806465 and parameters: {'ff_dim': 32, 'dropout_rate': 0.17302053032340522, 'embed_dim': 1024, 'learning_rate': 3.739499550402986e-07, 'optimizer': 'Adam', 'weight_decay': 1.0077895513902973e-06, 'batch_size': 10, 'num_heads': 2, 'num_transformer_blocks': 16}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50, Fold 1: Test Accuracy = 0.4563\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=16, learning_rate=6.617178019962192e-07, optimizer=Adam, weight_decay=3.7200997074946538e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:31:44,888] Trial 52 finished with value: 0.532384450051397 and parameters: {'ff_dim': 32, 'dropout_rate': 0.19032028142593085, 'embed_dim': 1024, 'learning_rate': 6.617178019962192e-07, 'optimizer': 'Adam', 'weight_decay': 3.7200997074946538e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 16}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 52, Fold 1: Test Accuracy = 0.5324\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=16, learning_rate=1.0213711046317437e-07, optimizer=Adam, weight_decay=1.8089038765256737e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:32:54,577] Trial 51 finished with value: 0.5278336604055696 and parameters: {'ff_dim': 32, 'dropout_rate': 0.1676923443266727, 'embed_dim': 1024, 'learning_rate': 4.2083934470617656e-07, 'optimizer': 'Adam', 'weight_decay': 1.0356845590549609e-06, 'batch_size': 10, 'num_heads': 2, 'num_transformer_blocks': 16}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 51, Fold 1: Test Accuracy = 0.5278\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=16, learning_rate=1.0821198519733549e-07, optimizer=Adam, weight_decay=1.8749543463885696e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:34:26,591] Trial 54 finished with value: 0.4704742547425475 and parameters: {'ff_dim': 32, 'dropout_rate': 0.20824101522508315, 'embed_dim': 512, 'learning_rate': 1.0821198519733549e-07, 'optimizer': 'Adam', 'weight_decay': 1.8749543463885696e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 16}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 54, Fold 1: Test Accuracy = 0.4705\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=2, learning_rate=1.2625061741701271e-06, optimizer=Adam, weight_decay=2.401513996993152e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:35:28,608] Trial 55 finished with value: 0.47289309410335484 and parameters: {'ff_dim': 32, 'dropout_rate': 0.14787752956419836, 'embed_dim': 32, 'learning_rate': 1.2625061741701271e-06, 'optimizer': 'Adam', 'weight_decay': 2.401513996993152e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 2}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 55, Fold 1: Test Accuracy = 0.4729\n",
      "Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=1.6663032825634256e-06, optimizer=Adam, weight_decay=2.853862767129088e-05, batch_size=10,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:35:52,123] Trial 53 finished with value: 0.5629708438463695 and parameters: {'ff_dim': 32, 'dropout_rate': 0.199530710048429, 'embed_dim': 1024, 'learning_rate': 1.0213711046317437e-07, 'optimizer': 'Adam', 'weight_decay': 1.8089038765256737e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 16}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 53, Fold 1: Test Accuracy = 0.5630\n",
      "Hyperparameters: num_heads=4, num_transformer_blocks=32, learning_rate=0.015153032751670879, optimizer=Adam, weight_decay=2.952502661327173e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:37:02,337] Trial 56 finished with value: 0.6046225586393795 and parameters: {'ff_dim': 64, 'dropout_rate': 0.25055779759014646, 'embed_dim': 128, 'learning_rate': 1.6663032825634256e-06, 'optimizer': 'Adam', 'weight_decay': 2.853862767129088e-05, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 56, Fold 1: Test Accuracy = 0.6046\n",
      "Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=1.8690547136723197e-06, optimizer=Adam, weight_decay=2.8630830655423218e-05, batch_size=10,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:39:09,978] Trial 58 finished with value: 0.5486459209419681 and parameters: {'ff_dim': 64, 'dropout_rate': 0.26660911931759146, 'embed_dim': 128, 'learning_rate': 1.8690547136723197e-06, 'optimizer': 'Adam', 'weight_decay': 2.8630830655423218e-05, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 58, Fold 1: Test Accuracy = 0.5486\n",
      "Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=2.581504202302649e-07, optimizer=Adam, weight_decay=1.0153192415747231e-05, batch_size=10,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:39:30,357] Trial 57 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 64, 'dropout_rate': 0.11363580890658802, 'embed_dim': 128, 'learning_rate': 0.015153032751670879, 'optimizer': 'Adam', 'weight_decay': 2.952502661327173e-05, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 32}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 57, Fold 1: Test Accuracy = 0.3333\n",
      "Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=4.40649301523081e-06, optimizer=Adam, weight_decay=1.0594513213225922e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:41:18,476] Trial 60 finished with value: 0.5152482011027008 and parameters: {'ff_dim': 64, 'dropout_rate': 0.2426213165456769, 'embed_dim': 128, 'learning_rate': 4.40649301523081e-06, 'optimizer': 'Adam', 'weight_decay': 1.0594513213225922e-05, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 60, Fold 1: Test Accuracy = 0.5152\n",
      "Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=2.459777055158588e-07, optimizer=Adam, weight_decay=5.3815643039539686e-05, batch_size=10,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:41:19,358] Trial 59 finished with value: 0.49253882814690214 and parameters: {'ff_dim': 64, 'dropout_rate': 0.24492987801230306, 'embed_dim': 128, 'learning_rate': 2.581504202302649e-07, 'optimizer': 'Adam', 'weight_decay': 1.0153192415747231e-05, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 59, Fold 1: Test Accuracy = 0.4925\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=7.731106374922111e-07, optimizer=Adam, weight_decay=5.078661020233088e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:42:10,683] Trial 61 finished with value: 0.44040164470610216 and parameters: {'ff_dim': 64, 'dropout_rate': 0.21375582831259232, 'embed_dim': 128, 'learning_rate': 2.459777055158588e-07, 'optimizer': 'Adam', 'weight_decay': 5.3815643039539686e-05, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 61, Fold 1: Test Accuracy = 0.4404\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=6.182086795526218e-07, optimizer=Adam, weight_decay=1.4490168817168576e-05, batch_size=16,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:43:05,153] Trial 62 finished with value: 0.5088796374170639 and parameters: {'ff_dim': 256, 'dropout_rate': 0.21804568481358025, 'embed_dim': 512, 'learning_rate': 7.731106374922111e-07, 'optimizer': 'Adam', 'weight_decay': 5.078661020233088e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 62, Fold 1: Test Accuracy = 0.5089\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=1.0245579354630048e-06, optimizer=Adam, weight_decay=1.4211807696911252e-05, batch_size=16,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:43:59,143] Trial 64 finished with value: 0.5124765909728063 and parameters: {'ff_dim': 32, 'dropout_rate': 0.2816025257651576, 'embed_dim': 64, 'learning_rate': 1.0245579354630048e-06, 'optimizer': 'Adam', 'weight_decay': 1.4211807696911252e-05, 'batch_size': 16, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 64, Fold 1: Test Accuracy = 0.5125\n",
      "Hyperparameters: num_heads=1, num_transformer_blocks=2, learning_rate=1.6491436740924953e-07, optimizer=Adam, weight_decay=2.4132496610128134e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:44:07,700] Trial 63 finished with value: 0.5673505279880385 and parameters: {'ff_dim': 256, 'dropout_rate': 0.22479139857831773, 'embed_dim': 512, 'learning_rate': 6.182086795526218e-07, 'optimizer': 'Adam', 'weight_decay': 1.4490168817168576e-05, 'batch_size': 16, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 63, Fold 1: Test Accuracy = 0.5674\n",
      "Hyperparameters: num_heads=1, num_transformer_blocks=2, learning_rate=1.738938466859771e-07, optimizer=Adam, weight_decay=6.444609661100409e-06, batch_size=10,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:46:20,089] Trial 65 finished with value: 0.5961892346509673 and parameters: {'ff_dim': 1024, 'dropout_rate': 0.14879695603286605, 'embed_dim': 512, 'learning_rate': 1.6491436740924953e-07, 'optimizer': 'Adam', 'weight_decay': 2.4132496610128134e-05, 'batch_size': 10, 'num_heads': 1, 'num_transformer_blocks': 2}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 65, Fold 1: Test Accuracy = 0.5962\n",
      "Hyperparameters: num_heads=1, num_transformer_blocks=2, learning_rate=3.3949307493517304e-07, optimizer=Adam, weight_decay=5.671048086980873e-06, batch_size=10,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:46:28,427] Trial 66 finished with value: 0.5648139426221849 and parameters: {'ff_dim': 1024, 'dropout_rate': 0.18463336543785225, 'embed_dim': 512, 'learning_rate': 1.738938466859771e-07, 'optimizer': 'Adam', 'weight_decay': 6.444609661100409e-06, 'batch_size': 10, 'num_heads': 1, 'num_transformer_blocks': 2}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 66, Fold 1: Test Accuracy = 0.5648\n",
      "Hyperparameters: num_heads=1, num_transformer_blocks=2, learning_rate=1.5705910551650474e-06, optimizer=Adam, weight_decay=2.460113454854987e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:47:17,316] Trial 68 finished with value: 0.5497986169516867 and parameters: {'ff_dim': 1024, 'dropout_rate': 0.15600228963548435, 'embed_dim': 32, 'learning_rate': 1.5705910551650474e-06, 'optimizer': 'Adam', 'weight_decay': 2.460113454854987e-05, 'batch_size': 10, 'num_heads': 1, 'num_transformer_blocks': 2}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 68, Fold 1: Test Accuracy = 0.5498\n",
      "Hyperparameters: num_heads=1, num_transformer_blocks=2, learning_rate=3.8066154906123707e-07, optimizer=Adam, weight_decay=2.1607519636068256e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:48:05,048] Trial 67 finished with value: 0.46980104663115596 and parameters: {'ff_dim': 1024, 'dropout_rate': 0.13080360279367703, 'embed_dim': 32, 'learning_rate': 3.3949307493517304e-07, 'optimizer': 'Adam', 'weight_decay': 5.671048086980873e-06, 'batch_size': 10, 'num_heads': 1, 'num_transformer_blocks': 2}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 67, Fold 1: Test Accuracy = 0.4698\n",
      "Hyperparameters: num_heads=1, num_transformer_blocks=2, learning_rate=1.8988986532584934e-07, optimizer=Adam, weight_decay=2.1575210101274153e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 24\n",
      "Trial 69, Fold 1: Test Accuracy = 0.5109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:49:37,204] Trial 69 finished with value: 0.5108570227081581 and parameters: {'ff_dim': 1024, 'dropout_rate': 0.12104121978112173, 'embed_dim': 1024, 'learning_rate': 3.8066154906123707e-07, 'optimizer': 'Adam', 'weight_decay': 2.1607519636068256e-05, 'batch_size': 10, 'num_heads': 1, 'num_transformer_blocks': 2}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: num_heads=16, num_transformer_blocks=1, learning_rate=1.6944516326100323e-07, optimizer=Adam, weight_decay=3.3777879555769647e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:50:41,794] Trial 70 finished with value: 0.5885112606298477 and parameters: {'ff_dim': 512, 'dropout_rate': 0.12488269155640457, 'embed_dim': 512, 'learning_rate': 1.8988986532584934e-07, 'optimizer': 'Adam', 'weight_decay': 2.1575210101274153e-05, 'batch_size': 10, 'num_heads': 1, 'num_transformer_blocks': 2}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 70, Fold 1: Test Accuracy = 0.5885\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=1, learning_rate=2.2713059958322237e-05, optimizer=Adam, weight_decay=3.0704520101675116e-05, batch_size=10,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:51:50,605] Trial 71 finished with value: 0.5153164190262592 and parameters: {'ff_dim': 512, 'dropout_rate': 0.26395975036678393, 'embed_dim': 512, 'learning_rate': 1.6944516326100323e-07, 'optimizer': 'Adam', 'weight_decay': 3.3777879555769647e-05, 'batch_size': 10, 'num_heads': 16, 'num_transformer_blocks': 1}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 71, Fold 1: Test Accuracy = 0.5153\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=0.00017521562259736195, optimizer=Adam, weight_decay=9.491173605103781e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:51:58,148] Trial 72 finished with value: 0.5903233342678255 and parameters: {'ff_dim': 32, 'dropout_rate': 0.16144930245784128, 'embed_dim': 512, 'learning_rate': 2.2713059958322237e-05, 'optimizer': 'Adam', 'weight_decay': 3.0704520101675116e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 1}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 72, Fold 1: Test Accuracy = 0.5903\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=0.00019622734839111033, optimizer=Adam, weight_decay=1.2102702408809436e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 11\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:52:57,564] Trial 73 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 32, 'dropout_rate': 0.3831535484906924, 'embed_dim': 512, 'learning_rate': 0.00017521562259736195, 'optimizer': 'Adam', 'weight_decay': 9.491173605103781e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 73, Fold 1: Test Accuracy = 0.3333\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=32, learning_rate=4.171663988772657e-05, optimizer=Adam, weight_decay=7.216875064799785e-05, batch_size=10,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 19:52:59,289] Trial 74 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 2048, 'dropout_rate': 0.38610563872324294, 'embed_dim': 512, 'learning_rate': 0.00019622734839111033, 'optimizer': 'Adam', 'weight_decay': 1.2102702408809436e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 74, Fold 1: Test Accuracy = 0.3333\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=32, learning_rate=3.451215557102573e-05, optimizer=Adam, weight_decay=1.650678888629788e-05, batch_size=16,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 11\n",
      "Trial 76, Fold 1: Test Accuracy = 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:14:22,841] Trial 76 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 32, 'dropout_rate': 0.14035938411672724, 'embed_dim': 2048, 'learning_rate': 3.451215557102573e-05, 'optimizer': 'Adam', 'weight_decay': 1.650678888629788e-05, 'batch_size': 16, 'num_heads': 8, 'num_transformer_blocks': 32}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: num_heads=4, num_transformer_blocks=16, learning_rate=7.563166897984704e-05, optimizer=Adam, weight_decay=6.379979425103414e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 20\n",
      "Trial 75, Fold 1: Test Accuracy = 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:16:47,996] Trial 75 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 2048, 'dropout_rate': 0.35902762039026387, 'embed_dim': 512, 'learning_rate': 4.171663988772657e-05, 'optimizer': 'Adam', 'weight_decay': 7.216875064799785e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 32}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: num_heads=4, num_transformer_blocks=16, learning_rate=6.472079970351775e-05, optimizer=AdamW, weight_decay=4.6883295380148534e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:18:27,212] Trial 77 finished with value: 0.5878024483693113 and parameters: {'ff_dim': 32, 'dropout_rate': 0.4086516953935701, 'embed_dim': 64, 'learning_rate': 7.563166897984704e-05, 'optimizer': 'Adam', 'weight_decay': 6.379979425103414e-05, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 16}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 77, Fold 1: Test Accuracy = 0.5878\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=1, learning_rate=5.858041296904111e-06, optimizer=AdamW, weight_decay=3.7841260412373264e-05, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:18:52,542] Trial 78 finished with value: 0.572986543313709 and parameters: {'ff_dim': 128, 'dropout_rate': 0.18821425607897033, 'embed_dim': 64, 'learning_rate': 6.472079970351775e-05, 'optimizer': 'AdamW', 'weight_decay': 4.6883295380148534e-05, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 16}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 78, Fold 1: Test Accuracy = 0.5730\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=1, learning_rate=0.0006942061789980255, optimizer=Adam, weight_decay=0.00012933261394143845, batch_size=32,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:20:23,074] Trial 79 finished with value: 0.5660356041491449 and parameters: {'ff_dim': 128, 'dropout_rate': 0.23444332314655164, 'embed_dim': 256, 'learning_rate': 5.858041296904111e-06, 'optimizer': 'AdamW', 'weight_decay': 3.7841260412373264e-05, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 1}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 79, Fold 1: Test Accuracy = 0.5660\n",
      "Hyperparameters: num_heads=16, num_transformer_blocks=1, learning_rate=8.660185725523056e-07, optimizer=Adam, weight_decay=0.00012096255442915502, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:20:42,579] Trial 80 finished with value: 0.5384949070180357 and parameters: {'ff_dim': 32, 'dropout_rate': 0.44987174711702843, 'embed_dim': 256, 'learning_rate': 0.0006942061789980255, 'optimizer': 'Adam', 'weight_decay': 0.00012933261394143845, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 1}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 80, Fold 1: Test Accuracy = 0.5385\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=1, learning_rate=1.9713517753692227e-05, optimizer=Adam, weight_decay=2.9715367219463973e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:22:04,327] Trial 82 finished with value: 0.5553669750490609 and parameters: {'ff_dim': 32, 'dropout_rate': 0.16339158641131102, 'embed_dim': 512, 'learning_rate': 1.9713517753692227e-05, 'optimizer': 'Adam', 'weight_decay': 2.9715367219463973e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 1}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 82, Fold 1: Test Accuracy = 0.5554\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=1, learning_rate=1.441039975573583e-05, optimizer=Adam, weight_decay=2.07666545491387e-05, batch_size=10,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:22:31,894] Trial 81 finished with value: 0.5853654798616952 and parameters: {'ff_dim': 32, 'dropout_rate': 0.4456896658177308, 'embed_dim': 1024, 'learning_rate': 8.660185725523056e-07, 'optimizer': 'Adam', 'weight_decay': 0.00012096255442915502, 'batch_size': 32, 'num_heads': 16, 'num_transformer_blocks': 1}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 81, Fold 1: Test Accuracy = 0.5854\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=1, learning_rate=1.6305483057801317e-05, optimizer=Adam, weight_decay=2.4301032666335606e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:23:00,375] Trial 83 finished with value: 0.5775108868330062 and parameters: {'ff_dim': 32, 'dropout_rate': 0.15673385612250934, 'embed_dim': 512, 'learning_rate': 1.441039975573583e-05, 'optimizer': 'Adam', 'weight_decay': 2.07666545491387e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 1}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 83, Fold 1: Test Accuracy = 0.5775\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=1, learning_rate=5.283609536266551e-07, optimizer=Adam, weight_decay=2.5809828001894262e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:24:32,513] Trial 84 finished with value: 0.5703965049995328 and parameters: {'ff_dim': 32, 'dropout_rate': 0.42688673533393834, 'embed_dim': 512, 'learning_rate': 1.6305483057801317e-05, 'optimizer': 'Adam', 'weight_decay': 2.4301032666335606e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 1}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 84, Fold 1: Test Accuracy = 0.5704\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=2.9145048627588646e-05, optimizer=Adam, weight_decay=3.4272775794538155e-05, batch_size=10,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:25:13,053] Trial 85 finished with value: 0.591024296794692 and parameters: {'ff_dim': 32, 'dropout_rate': 0.18005148036113905, 'embed_dim': 512, 'learning_rate': 5.283609536266551e-07, 'optimizer': 'Adam', 'weight_decay': 2.5809828001894262e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 1}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 85, Fold 1: Test Accuracy = 0.5910\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=5.262526247153893e-07, optimizer=Adam, weight_decay=1.591999571023229e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:25:45,056] Trial 86 finished with value: 0.5145102326885338 and parameters: {'ff_dim': 32, 'dropout_rate': 0.3384841964626336, 'embed_dim': 512, 'learning_rate': 2.9145048627588646e-05, 'optimizer': 'Adam', 'weight_decay': 3.4272775794538155e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 86, Fold 1: Test Accuracy = 0.5145\n",
      "Hyperparameters: num_heads=2, num_transformer_blocks=4, learning_rate=5.181203311597681e-07, optimizer=Adam, weight_decay=0.000696500617860753, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:28:05,695] Trial 88 finished with value: 0.5438599196336792 and parameters: {'ff_dim': 1024, 'dropout_rate': 0.17750017510965768, 'embed_dim': 1024, 'learning_rate': 5.181203311597681e-07, 'optimizer': 'Adam', 'weight_decay': 0.000696500617860753, 'batch_size': 10, 'num_heads': 2, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 88, Fold 1: Test Accuracy = 0.5439\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=1, learning_rate=2.917425811971858e-07, optimizer=Adam, weight_decay=1.6437589532233074e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:28:44,137] Trial 87 finished with value: 0.5386074198673021 and parameters: {'ff_dim': 1024, 'dropout_rate': 0.20292045666496236, 'embed_dim': 1024, 'learning_rate': 5.262526247153893e-07, 'optimizer': 'Adam', 'weight_decay': 1.591999571023229e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 87, Fold 1: Test Accuracy = 0.5386\n",
      "Hyperparameters: num_heads=1, num_transformer_blocks=1, learning_rate=2.8557811986418536e-07, optimizer=Adam, weight_decay=4.1814981034118535e-05, batch_size=16,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:29:01,787] Trial 89 finished with value: 0.37145294832258663 and parameters: {'ff_dim': 64, 'dropout_rate': 0.1994086664927045, 'embed_dim': 128, 'learning_rate': 2.917425811971858e-07, 'optimizer': 'Adam', 'weight_decay': 1.6437589532233074e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 1}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 89, Fold 1: Test Accuracy = 0.3715\n",
      "Hyperparameters: num_heads=1, num_transformer_blocks=1, learning_rate=1.2613331870471923e-07, optimizer=Adam, weight_decay=1.1643503990982395e-05, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 11\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:29:51,058] Trial 91 finished with value: 0.4717769367348845 and parameters: {'ff_dim': 32, 'dropout_rate': 0.39184778093525413, 'embed_dim': 512, 'learning_rate': 1.2613331870471923e-07, 'optimizer': 'Adam', 'weight_decay': 1.1643503990982395e-05, 'batch_size': 32, 'num_heads': 1, 'num_transformer_blocks': 1}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 91, Fold 1: Test Accuracy = 0.4718\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=1, learning_rate=1.9146653814962154e-06, optimizer=Adam, weight_decay=2.525511501307685e-05, batch_size=10,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:29:51,969] Trial 90 finished with value: 0.33318147836650785 and parameters: {'ff_dim': 32, 'dropout_rate': 0.14703709799904977, 'embed_dim': 128, 'learning_rate': 2.8557811986418536e-07, 'optimizer': 'Adam', 'weight_decay': 4.1814981034118535e-05, 'batch_size': 16, 'num_heads': 1, 'num_transformer_blocks': 1}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 90, Fold 1: Test Accuracy = 0.3332\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=1, learning_rate=9.122346854750486e-06, optimizer=Adam, weight_decay=2.647643637976971e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:31:31,207] Trial 93 finished with value: 0.5309644893000655 and parameters: {'ff_dim': 32, 'dropout_rate': 0.17849002721509705, 'embed_dim': 512, 'learning_rate': 9.122346854750486e-06, 'optimizer': 'Adam', 'weight_decay': 2.647643637976971e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 1}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 93, Fold 1: Test Accuracy = 0.5310\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=1, learning_rate=1.7514479266004605e-06, optimizer=Adam, weight_decay=1.93989528149809e-05, batch_size=10,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:32:05,049] Trial 92 finished with value: 0.5619947668442201 and parameters: {'ff_dim': 32, 'dropout_rate': 0.1801099051615927, 'embed_dim': 512, 'learning_rate': 1.9146653814962154e-06, 'optimizer': 'Adam', 'weight_decay': 2.525511501307685e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 1}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 92, Fold 1: Test Accuracy = 0.5620\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=1, learning_rate=8.545739489393219e-07, optimizer=Adam, weight_decay=0.00016783358437614076, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:33:40,040] Trial 94 finished with value: 0.5622879170171012 and parameters: {'ff_dim': 32, 'dropout_rate': 0.2889943323181326, 'embed_dim': 512, 'learning_rate': 1.7514479266004605e-06, 'optimizer': 'Adam', 'weight_decay': 1.93989528149809e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 1}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 94, Fold 1: Test Accuracy = 0.5623\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=16, learning_rate=8.025662902413745e-07, optimizer=Adam, weight_decay=0.0003775594864021996, batch_size=10,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:34:23,963] Trial 95 finished with value: 0.5519217830109335 and parameters: {'ff_dim': 32, 'dropout_rate': 0.41628854790297887, 'embed_dim': 512, 'learning_rate': 8.545739489393219e-07, 'optimizer': 'Adam', 'weight_decay': 0.00016783358437614076, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 1}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 95, Fold 1: Test Accuracy = 0.5519\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=1.5006182303146715e-07, optimizer=Adam, weight_decay=3.1305665557648896e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:37:03,175] Trial 96 finished with value: 0.5489378562751145 and parameters: {'ff_dim': 32, 'dropout_rate': 0.16023737757280906, 'embed_dim': 512, 'learning_rate': 8.025662902413745e-07, 'optimizer': 'Adam', 'weight_decay': 0.0003775594864021996, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 16}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 96, Fold 1: Test Accuracy = 0.5489\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=2.257052344365397e-05, optimizer=Adam, weight_decay=9.047095423593396e-06, batch_size=10,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:38:28,472] Trial 97 finished with value: 0.5444455658349687 and parameters: {'ff_dim': 32, 'dropout_rate': 0.3132256193069321, 'embed_dim': 2048, 'learning_rate': 1.5006182303146715e-07, 'optimizer': 'Adam', 'weight_decay': 3.1305665557648896e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 97, Fold 1: Test Accuracy = 0.5444\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=2, learning_rate=4.220257651007652e-07, optimizer=Adam, weight_decay=5.933431314784156e-05, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:39:05,139] Trial 98 finished with value: 0.6364156620876554 and parameters: {'ff_dim': 64, 'dropout_rate': 0.19427441641328858, 'embed_dim': 1024, 'learning_rate': 2.257052344365397e-05, 'optimizer': 'Adam', 'weight_decay': 9.047095423593396e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 98, Fold 1: Test Accuracy = 0.6364\n",
      "Hyperparameters: num_heads=2, num_transformer_blocks=4, learning_rate=8.652170306623112e-05, optimizer=AdamW, weight_decay=9.844435443508463e-06, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:40:01,989] Trial 100 finished with value: 0.493420054200542 and parameters: {'ff_dim': 64, 'dropout_rate': 0.1944823608458024, 'embed_dim': 1024, 'learning_rate': 8.652170306623112e-05, 'optimizer': 'AdamW', 'weight_decay': 9.844435443508463e-06, 'batch_size': 32, 'num_heads': 2, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100, Fold 1: Test Accuracy = 0.4934\n",
      "Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=4.134936997259088e-07, optimizer=Adam, weight_decay=4.176979786066645e-06, batch_size=10,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:40:40,501] Trial 99 finished with value: 0.5600055135034109 and parameters: {'ff_dim': 32, 'dropout_rate': 0.39798693153486536, 'embed_dim': 1024, 'learning_rate': 4.220257651007652e-07, 'optimizer': 'Adam', 'weight_decay': 5.933431314784156e-05, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 2}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 99, Fold 1: Test Accuracy = 0.5600\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=2.3734924654899906e-05, optimizer=Adam, weight_decay=4.082969181562746e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:42:26,517] Trial 102 finished with value: 0.5931323240818615 and parameters: {'ff_dim': 64, 'dropout_rate': 0.16991379692889416, 'embed_dim': 1024, 'learning_rate': 2.3734924654899906e-05, 'optimizer': 'Adam', 'weight_decay': 4.082969181562746e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 102, Fold 1: Test Accuracy = 0.5931\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=4.362933818907669e-05, optimizer=Adam, weight_decay=4.198763631740321e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 26\n",
      "Trial 101, Fold 1: Test Accuracy = 0.5714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:42:42,852] Trial 101 finished with value: 0.5714336977852538 and parameters: {'ff_dim': 64, 'dropout_rate': 0.1703265164725561, 'embed_dim': 1024, 'learning_rate': 4.134936997259088e-07, 'optimizer': 'Adam', 'weight_decay': 4.176979786066645e-06, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=2.3232630487364508e-07, optimizer=Adam, weight_decay=2.9089414955502543e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:44:14,976] Trial 103 finished with value: 0.6305775161199888 and parameters: {'ff_dim': 64, 'dropout_rate': 0.17115605751990334, 'embed_dim': 1024, 'learning_rate': 4.362933818907669e-05, 'optimizer': 'Adam', 'weight_decay': 4.198763631740321e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 103, Fold 1: Test Accuracy = 0.6306\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=4.843113857557776e-05, optimizer=Adam, weight_decay=3.0977446042539642e-06, batch_size=10,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:45:33,748] Trial 104 finished with value: 0.5839644893000654 and parameters: {'ff_dim': 64, 'dropout_rate': 0.21624688186694718, 'embed_dim': 1024, 'learning_rate': 2.3232630487364508e-07, 'optimizer': 'Adam', 'weight_decay': 2.9089414955502543e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 104, Fold 1: Test Accuracy = 0.5840\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=4.4135483707715073e-05, optimizer=Adam, weight_decay=4.686405193891303e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n",
      "Trial 105, Fold 1: Test Accuracy = 0.5971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:46:01,447] Trial 105 finished with value: 0.597098402018503 and parameters: {'ff_dim': 64, 'dropout_rate': 0.20819991236134966, 'embed_dim': 1024, 'learning_rate': 4.843113857557776e-05, 'optimizer': 'Adam', 'weight_decay': 3.0977446042539642e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=4.6069476117846655e-05, optimizer=Adam, weight_decay=4.674581703438227e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:47:23,932] Trial 106 finished with value: 0.5838951499859827 and parameters: {'ff_dim': 64, 'dropout_rate': 0.14877661426808522, 'embed_dim': 1024, 'learning_rate': 4.4135483707715073e-05, 'optimizer': 'Adam', 'weight_decay': 4.686405193891303e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 106, Fold 1: Test Accuracy = 0.5839\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=0.00014758760125284145, optimizer=Adam, weight_decay=2.346531853882423e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n",
      "Trial 107, Fold 1: Test Accuracy = 0.6061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:47:45,266] Trial 107 finished with value: 0.6061321371834408 and parameters: {'ff_dim': 64, 'dropout_rate': 0.22371631747518722, 'embed_dim': 1024, 'learning_rate': 4.6069476117846655e-05, 'optimizer': 'Adam', 'weight_decay': 4.674581703438227e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: num_heads=16, num_transformer_blocks=4, learning_rate=2.501083482979508e-05, optimizer=Adam, weight_decay=2.1943613491474405e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:49:37,123] Trial 109 finished with value: 0.5668913185683581 and parameters: {'ff_dim': 64, 'dropout_rate': 0.22677741424208778, 'embed_dim': 1024, 'learning_rate': 2.501083482979508e-05, 'optimizer': 'Adam', 'weight_decay': 2.1943613491474405e-06, 'batch_size': 10, 'num_heads': 16, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 109, Fold 1: Test Accuracy = 0.5669\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=0.00014111294231307884, optimizer=Adam, weight_decay=1.8300793227188553e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:49:41,419] Trial 108 finished with value: 0.376780487804878 and parameters: {'ff_dim': 64, 'dropout_rate': 0.22556270690994695, 'embed_dim': 1024, 'learning_rate': 0.00014758760125284145, 'optimizer': 'Adam', 'weight_decay': 2.346531853882423e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 108, Fold 1: Test Accuracy = 0.3768\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=5.8767899094426814e-05, optimizer=Adam, weight_decay=2.813519512707786e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:51:57,107] Trial 110 finished with value: 0.5959728997289973 and parameters: {'ff_dim': 64, 'dropout_rate': 0.2557554449229918, 'embed_dim': 1024, 'learning_rate': 0.00014111294231307884, 'optimizer': 'Adam', 'weight_decay': 1.8300793227188553e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 110, Fold 1: Test Accuracy = 0.5960\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=0.0001048588105861127, optimizer=Adam, weight_decay=1.3679940659435814e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:52:13,183] Trial 111 finished with value: 0.5734784599570134 and parameters: {'ff_dim': 64, 'dropout_rate': 0.2562490210414766, 'embed_dim': 1024, 'learning_rate': 5.8767899094426814e-05, 'optimizer': 'Adam', 'weight_decay': 2.813519512707786e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 111, Fold 1: Test Accuracy = 0.5735\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=9.815826299731989e-05, optimizer=Adam, weight_decay=4.48934688928994e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:53:43,271] Trial 113 finished with value: 0.5473642650219606 and parameters: {'ff_dim': 64, 'dropout_rate': 0.23946263116565686, 'embed_dim': 1024, 'learning_rate': 9.815826299731989e-05, 'optimizer': 'Adam', 'weight_decay': 4.48934688928994e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 113, Fold 1: Test Accuracy = 0.5474\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=0.0003718875587453743, optimizer=Adam, weight_decay=1.8591593245505161e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:53:57,601] Trial 112 finished with value: 0.5733551069993458 and parameters: {'ff_dim': 64, 'dropout_rate': 0.21103740895909637, 'embed_dim': 1024, 'learning_rate': 0.0001048588105861127, 'optimizer': 'Adam', 'weight_decay': 1.3679940659435814e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 112, Fold 1: Test Accuracy = 0.5734\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=0.00030482986050367375, optimizer=Adam, weight_decay=1.7402160372640836e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:54:54,114] Trial 114 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 64, 'dropout_rate': 0.2571387188921796, 'embed_dim': 1024, 'learning_rate': 0.0003718875587453743, 'optimizer': 'Adam', 'weight_decay': 1.8591593245505161e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 114, Fold 1: Test Accuracy = 0.3333\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=4.817249805907344e-05, optimizer=Adam, weight_decay=3.3722086882814303e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 14\n",
      "Trial 115, Fold 1: Test Accuracy = 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:55:30,251] Trial 115 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 64, 'dropout_rate': 0.23468972421490247, 'embed_dim': 1024, 'learning_rate': 0.00030482986050367375, 'optimizer': 'Adam', 'weight_decay': 1.7402160372640836e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=3.2379059546989724e-05, optimizer=Adam, weight_decay=6.9361445802775845e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:56:03,961] Trial 116 finished with value: 0.5118311372768901 and parameters: {'ff_dim': 64, 'dropout_rate': 0.23242853426235768, 'embed_dim': 1024, 'learning_rate': 4.817249805907344e-05, 'optimizer': 'Adam', 'weight_decay': 3.3722086882814303e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 116, Fold 1: Test Accuracy = 0.5118\n",
      "Hyperparameters: num_heads=1, num_transformer_blocks=4, learning_rate=3.32933093135078e-05, optimizer=Adam, weight_decay=6.446244749915356e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:57:30,530] Trial 117 finished with value: 0.5846207831043828 and parameters: {'ff_dim': 64, 'dropout_rate': 0.2034551059868298, 'embed_dim': 1024, 'learning_rate': 3.2379059546989724e-05, 'optimizer': 'Adam', 'weight_decay': 6.9361445802775845e-06, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 117, Fold 1: Test Accuracy = 0.5846\n",
      "Hyperparameters: num_heads=1, num_transformer_blocks=4, learning_rate=7.738398040711663e-05, optimizer=Adam, weight_decay=4.104502581350729e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 23\n",
      "Trial 118, Fold 1: Test Accuracy = 0.5166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 20:58:32,360] Trial 118 finished with value: 0.5166223717409588 and parameters: {'ff_dim': 64, 'dropout_rate': 0.19524448515413362, 'embed_dim': 1024, 'learning_rate': 3.32933093135078e-05, 'optimizer': 'Adam', 'weight_decay': 6.446244749915356e-06, 'batch_size': 10, 'num_heads': 1, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=0.00020874773452135375, optimizer=Adam, weight_decay=4.895964337847104e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 28\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:00:21,853] Trial 119 finished with value: 0.5467187178768339 and parameters: {'ff_dim': 64, 'dropout_rate': 0.27290196670780564, 'embed_dim': 1024, 'learning_rate': 7.738398040711663e-05, 'optimizer': 'Adam', 'weight_decay': 4.104502581350729e-06, 'batch_size': 10, 'num_heads': 1, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 119, Fold 1: Test Accuracy = 0.5467\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=0.0002067395412030011, optimizer=AdamW, weight_decay=3.622622008194277e-06, batch_size=16,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:00:23,478] Trial 120 finished with value: 0.4741463414634146 and parameters: {'ff_dim': 64, 'dropout_rate': 0.2506761832628175, 'embed_dim': 1024, 'learning_rate': 0.00020874773452135375, 'optimizer': 'Adam', 'weight_decay': 4.895964337847104e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 120, Fold 1: Test Accuracy = 0.4741\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=0.00012564574062294028, optimizer=Adam, weight_decay=3.6548834445308292e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:01:24,549] Trial 122 finished with value: 0.5208284272497897 and parameters: {'ff_dim': 64, 'dropout_rate': 0.1908525769541731, 'embed_dim': 1024, 'learning_rate': 0.00012564574062294028, 'optimizer': 'Adam', 'weight_decay': 3.6548834445308292e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 122, Fold 1: Test Accuracy = 0.5208\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=1.4068481564765744e-05, optimizer=Adam, weight_decay=7.699273114161537e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:02:43,487] Trial 121 finished with value: 0.5395872348378656 and parameters: {'ff_dim': 64, 'dropout_rate': 0.2170204999600088, 'embed_dim': 1024, 'learning_rate': 0.0002067395412030011, 'optimizer': 'AdamW', 'weight_decay': 3.622622008194277e-06, 'batch_size': 16, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 121, Fold 1: Test Accuracy = 0.5396\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=1.79187777991584e-05, optimizer=Adam, weight_decay=7.718730546574958e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:04:02,438] Trial 123 finished with value: 0.5129342117559107 and parameters: {'ff_dim': 64, 'dropout_rate': 0.17208929167716647, 'embed_dim': 1024, 'learning_rate': 1.4068481564765744e-05, 'optimizer': 'Adam', 'weight_decay': 7.699273114161537e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 123, Fold 1: Test Accuracy = 0.5129\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=2, learning_rate=2.246364084135396e-05, optimizer=Adam, weight_decay=5.606792338236577e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:04:15,335] Trial 124 finished with value: 0.5752815624707971 and parameters: {'ff_dim': 256, 'dropout_rate': 0.1354339650828623, 'embed_dim': 1024, 'learning_rate': 1.79187777991584e-05, 'optimizer': 'Adam', 'weight_decay': 7.718730546574958e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 124, Fold 1: Test Accuracy = 0.5753\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=2, learning_rate=7.957023704475064e-06, optimizer=Adam, weight_decay=5.953237858921499e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:05:33,722] Trial 125 finished with value: 0.5371396131202691 and parameters: {'ff_dim': 256, 'dropout_rate': 0.20528243841673938, 'embed_dim': 32, 'learning_rate': 2.246364084135396e-05, 'optimizer': 'Adam', 'weight_decay': 5.606792338236577e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 2}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 125, Fold 1: Test Accuracy = 0.5371\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=16, learning_rate=6.32072537496072e-05, optimizer=Adam, weight_decay=9.474193323085672e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:05:37,947] Trial 126 finished with value: 0.532962807214279 and parameters: {'ff_dim': 512, 'dropout_rate': 0.20677364325094355, 'embed_dim': 32, 'learning_rate': 7.957023704475064e-06, 'optimizer': 'Adam', 'weight_decay': 5.953237858921499e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 2}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 126, Fold 1: Test Accuracy = 0.5330\n",
      "Hyperparameters: num_heads=4, num_transformer_blocks=16, learning_rate=6.312455845142566e-05, optimizer=Adam, weight_decay=2.9146911544783023e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:06:48,781] Trial 128 finished with value: 0.3413333333333333 and parameters: {'ff_dim': 2048, 'dropout_rate': 0.1668047145651277, 'embed_dim': 128, 'learning_rate': 6.312455845142566e-05, 'optimizer': 'Adam', 'weight_decay': 2.9146911544783023e-06, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 16}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 128, Fold 1: Test Accuracy = 0.3413\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=32, learning_rate=5.392751848232855e-06, optimizer=Adam, weight_decay=8.89468386799069e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:07:01,504] Trial 127 finished with value: 0.5101283992150266 and parameters: {'ff_dim': 64, 'dropout_rate': 0.18348011554863505, 'embed_dim': 128, 'learning_rate': 6.32072537496072e-05, 'optimizer': 'Adam', 'weight_decay': 9.474193323085672e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 16}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 127, Fold 1: Test Accuracy = 0.5101\n",
      "Hyperparameters: num_heads=2, num_transformer_blocks=4, learning_rate=3.219718527975881e-07, optimizer=Adam, weight_decay=2.0185076754614875e-06, batch_size=10,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:10:08,400] Trial 130 finished with value: 0.5852771703579105 and parameters: {'ff_dim': 64, 'dropout_rate': 0.4334128231211219, 'embed_dim': 1024, 'learning_rate': 3.219718527975881e-07, 'optimizer': 'Adam', 'weight_decay': 2.0185076754614875e-06, 'batch_size': 10, 'num_heads': 2, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 130, Fold 1: Test Accuracy = 0.5853\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=32, learning_rate=1.1276971770881592e-05, optimizer=Adam, weight_decay=1.399375238718454e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n",
      "Trial 129, Fold 1: Test Accuracy = 0.5756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:17:22,782] Trial 129 finished with value: 0.5755574245397627 and parameters: {'ff_dim': 1024, 'dropout_rate': 0.22154237532383392, 'embed_dim': 1024, 'learning_rate': 5.392751848232855e-06, 'optimizer': 'Adam', 'weight_decay': 8.89468386799069e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 32}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=1.1425597340896094e-05, optimizer=Adam, weight_decay=1.5216572193970366e-06, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n",
      "Trial 132, Fold 1: Test Accuracy = 0.6094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:18:41,579] Trial 132 finished with value: 0.6093536118119802 and parameters: {'ff_dim': 128, 'dropout_rate': 0.4211697666165787, 'embed_dim': 256, 'learning_rate': 1.1425597340896094e-05, 'optimizer': 'Adam', 'weight_decay': 1.5216572193970366e-06, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=4.330574233886439e-05, optimizer=Adam, weight_decay=1.3509061303826148e-06, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:20:02,604] Trial 133 finished with value: 0.5951573684702364 and parameters: {'ff_dim': 128, 'dropout_rate': 0.4599821080077381, 'embed_dim': 1024, 'learning_rate': 4.330574233886439e-05, 'optimizer': 'Adam', 'weight_decay': 1.3509061303826148e-06, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 133, Fold 1: Test Accuracy = 0.5952\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=1.243465852749347e-05, optimizer=Adam, weight_decay=1.5003048898656208e-06, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:20:05,930] Trial 131 finished with value: 0.6124972432482946 and parameters: {'ff_dim': 1024, 'dropout_rate': 0.21915840594831595, 'embed_dim': 1024, 'learning_rate': 1.1276971770881592e-05, 'optimizer': 'Adam', 'weight_decay': 1.399375238718454e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 32}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 131, Fold 1: Test Accuracy = 0.6125\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=2.9043708219627267e-06, optimizer=Adam, weight_decay=1.460071266418146e-06, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n",
      "Trial 135, Fold 1: Test Accuracy = 0.4955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:20:52,281] Trial 135 finished with value: 0.49552182039061776 and parameters: {'ff_dim': 128, 'dropout_rate': 0.4655505813253903, 'embed_dim': 256, 'learning_rate': 2.9043708219627267e-06, 'optimizer': 'Adam', 'weight_decay': 1.460071266418146e-06, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: num_heads=8, num_transformer_blocks=32, learning_rate=1.0579509702432528e-05, optimizer=Adam, weight_decay=1.5259367105489132e-06, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:21:40,193] Trial 134 finished with value: 0.6036034015512569 and parameters: {'ff_dim': 128, 'dropout_rate': 0.465659499139645, 'embed_dim': 256, 'learning_rate': 1.243465852749347e-05, 'optimizer': 'Adam', 'weight_decay': 1.5003048898656208e-06, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 134, Fold 1: Test Accuracy = 0.6036\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=1.1159399641543927e-05, optimizer=Adam, weight_decay=1.6084352287719507e-06, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:21:56,285] Trial 136 finished with value: 0.434840108401084 and parameters: {'ff_dim': 128, 'dropout_rate': 0.4264085333440869, 'embed_dim': 256, 'learning_rate': 1.0579509702432528e-05, 'optimizer': 'Adam', 'weight_decay': 1.5259367105489132e-06, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 32}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 136, Fold 1: Test Accuracy = 0.4348\n",
      "Hyperparameters: num_heads=16, num_transformer_blocks=8, learning_rate=3.972343814074571e-05, optimizer=Adam, weight_decay=1.091858531268128e-06, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:22:27,543] Trial 137 finished with value: 0.5505453695916269 and parameters: {'ff_dim': 128, 'dropout_rate': 0.48406944421676856, 'embed_dim': 256, 'learning_rate': 1.1159399641543927e-05, 'optimizer': 'Adam', 'weight_decay': 1.6084352287719507e-06, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 137, Fold 1: Test Accuracy = 0.5505\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=4.210010636086002e-05, optimizer=Adam, weight_decay=1.1765452882904726e-06, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:22:59,222] Trial 138 finished with value: 0.4034254742547425 and parameters: {'ff_dim': 128, 'dropout_rate': 0.49392600314775603, 'embed_dim': 256, 'learning_rate': 3.972343814074571e-05, 'optimizer': 'Adam', 'weight_decay': 1.091858531268128e-06, 'batch_size': 32, 'num_heads': 16, 'num_transformer_blocks': 8}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 138, Fold 1: Test Accuracy = 0.4034\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=4.801986179979074e-06, optimizer=Adam, weight_decay=1.298890661170391e-06, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:24:04,112] Trial 139 finished with value: 0.5582277357256331 and parameters: {'ff_dim': 128, 'dropout_rate': 0.4901880152000981, 'embed_dim': 256, 'learning_rate': 4.210010636086002e-05, 'optimizer': 'Adam', 'weight_decay': 1.1765452882904726e-06, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 139, Fold 1: Test Accuracy = 0.5582\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=4.381966233615878e-06, optimizer=Adam, weight_decay=1.2647926098951371e-06, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:24:11,924] Trial 140 finished with value: 0.543699747687132 and parameters: {'ff_dim': 128, 'dropout_rate': 0.44406715972228245, 'embed_dim': 256, 'learning_rate': 4.801986179979074e-06, 'optimizer': 'Adam', 'weight_decay': 1.298890661170391e-06, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 140, Fold 1: Test Accuracy = 0.5437\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=2.7909385133629147e-05, optimizer=Adam, weight_decay=1.3373418817353601e-05, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:26:00,140] Trial 142 finished with value: 0.5528397346042425 and parameters: {'ff_dim': 1024, 'dropout_rate': 0.4599109705648494, 'embed_dim': 1024, 'learning_rate': 2.7909385133629147e-05, 'optimizer': 'Adam', 'weight_decay': 1.3373418817353601e-05, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 142, Fold 1: Test Accuracy = 0.5528\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=32, learning_rate=1.409819903495246e-05, optimizer=Adam, weight_decay=2.5888705497465068e-06, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:26:12,431] Trial 141 finished with value: 0.5636062984767779 and parameters: {'ff_dim': 128, 'dropout_rate': 0.47361753523369704, 'embed_dim': 256, 'learning_rate': 4.381966233615878e-06, 'optimizer': 'Adam', 'weight_decay': 1.2647926098951371e-06, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 141, Fold 1: Test Accuracy = 0.5636\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=32, learning_rate=1.1968081029347325e-05, optimizer=Adam, weight_decay=2.5536656373712486e-06, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:27:27,067] Trial 144 finished with value: 0.3812417531071863 and parameters: {'ff_dim': 1024, 'dropout_rate': 0.4085177537670149, 'embed_dim': 1024, 'learning_rate': 1.1968081029347325e-05, 'optimizer': 'Adam', 'weight_decay': 2.5536656373712486e-06, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 32}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 144, Fold 1: Test Accuracy = 0.3812\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=6.903724963573547e-06, optimizer=Adam, weight_decay=1.8168013426840205e-06, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:28:09,260] Trial 143 finished with value: 0.5734871507335764 and parameters: {'ff_dim': 128, 'dropout_rate': 0.43813671239686774, 'embed_dim': 256, 'learning_rate': 1.409819903495246e-05, 'optimizer': 'Adam', 'weight_decay': 2.5888705497465068e-06, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 32}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 143, Fold 1: Test Accuracy = 0.5735\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=1.9091249372108328e-05, optimizer=Adam, weight_decay=2.0855428744550207e-06, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:28:34,670] Trial 145 finished with value: 0.4209985048126343 and parameters: {'ff_dim': 128, 'dropout_rate': 0.4200378252115713, 'embed_dim': 64, 'learning_rate': 6.903724963573547e-06, 'optimizer': 'Adam', 'weight_decay': 1.8168013426840205e-06, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 145, Fold 1: Test Accuracy = 0.4210\n",
      "Hyperparameters: num_heads=4, num_transformer_blocks=8, learning_rate=1.904704193985763e-05, optimizer=AdamW, weight_decay=2.0619745216825846e-06, batch_size=32,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:29:05,376] Trial 146 finished with value: 0.5322863283805251 and parameters: {'ff_dim': 128, 'dropout_rate': 0.2969059335441002, 'embed_dim': 64, 'learning_rate': 1.9091249372108328e-05, 'optimizer': 'Adam', 'weight_decay': 2.0855428744550207e-06, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 146, Fold 1: Test Accuracy = 0.5323\n",
      "Hyperparameters: num_heads=4, num_transformer_blocks=8, learning_rate=8.451675019350264e-05, optimizer=AdamW, weight_decay=1.5714021145724927e-05, batch_size=16,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 11\n",
      "Trial 147, Fold 1: Test Accuracy = 0.4854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:32:30,545] Trial 147 finished with value: 0.4853983739837398 and parameters: {'ff_dim': 1024, 'dropout_rate': 0.42769973137551764, 'embed_dim': 2048, 'learning_rate': 1.904704193985763e-05, 'optimizer': 'AdamW', 'weight_decay': 2.0619745216825846e-06, 'batch_size': 32, 'num_heads': 4, 'num_transformer_blocks': 8}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: num_heads=1, num_transformer_blocks=32, learning_rate=5.597923949171476e-05, optimizer=Adam, weight_decay=1.5132283647198769e-05, batch_size=16,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 24\n",
      "Trial 148, Fold 1: Test Accuracy = 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:43:21,524] Trial 148 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 1024, 'dropout_rate': 0.4310425186265874, 'embed_dim': 2048, 'learning_rate': 8.451675019350264e-05, 'optimizer': 'AdamW', 'weight_decay': 1.5714021145724927e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 8}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: num_heads=1, num_transformer_blocks=32, learning_rate=5.262362313661389e-05, optimizer=Adam, weight_decay=1.1388756968500948e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 17\n",
      "Trial 149, Fold 1: Test Accuracy = 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:49:45,672] Trial 149 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 1024, 'dropout_rate': 0.44975089528636136, 'embed_dim': 1024, 'learning_rate': 5.597923949171476e-05, 'optimizer': 'Adam', 'weight_decay': 1.5132283647198769e-05, 'batch_size': 16, 'num_heads': 1, 'num_transformer_blocks': 32}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: num_heads=8, num_transformer_blocks=2, learning_rate=3.0385960196957858e-05, optimizer=Adam, weight_decay=1.12409718040724e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 16\n",
      "Trial 151, Fold 1: Test Accuracy = 0.5862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:51:53,793] Trial 151 finished with value: 0.5861585833099711 and parameters: {'ff_dim': 128, 'dropout_rate': 0.40051726090111495, 'embed_dim': 1024, 'learning_rate': 3.0385960196957858e-05, 'optimizer': 'Adam', 'weight_decay': 1.12409718040724e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 2}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=2.2299662909549243e-05, optimizer=Adam, weight_decay=4.9862343972045965e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:53:00,612] Trial 150 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 128, 'dropout_rate': 0.45636702652212846, 'embed_dim': 1024, 'learning_rate': 5.262362313661389e-05, 'optimizer': 'Adam', 'weight_decay': 1.1388756968500948e-05, 'batch_size': 10, 'num_heads': 1, 'num_transformer_blocks': 32}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 150, Fold 1: Test Accuracy = 0.3333\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=2.429226726395969e-05, optimizer=Adam, weight_decay=3.945713168323091e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:53:39,888] Trial 152 finished with value: 0.5283709933651061 and parameters: {'ff_dim': 64, 'dropout_rate': 0.15408343968915328, 'embed_dim': 1024, 'learning_rate': 2.2299662909549243e-05, 'optimizer': 'Adam', 'weight_decay': 4.9862343972045965e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 152, Fold 1: Test Accuracy = 0.5284\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=2.7396936161857595e-05, optimizer=Adam, weight_decay=3.2797323544607516e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:54:31,021] Trial 153 finished with value: 0.5478858050649472 and parameters: {'ff_dim': 64, 'dropout_rate': 0.19692457769344504, 'embed_dim': 1024, 'learning_rate': 2.429226726395969e-05, 'optimizer': 'Adam', 'weight_decay': 3.945713168323091e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 153, Fold 1: Test Accuracy = 0.5479\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=8.605494375889457e-06, optimizer=Adam, weight_decay=3.422246953154291e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:55:07,262] Trial 154 finished with value: 0.5214650967199327 and parameters: {'ff_dim': 64, 'dropout_rate': 0.46908223427569473, 'embed_dim': 1024, 'learning_rate': 2.7396936161857595e-05, 'optimizer': 'Adam', 'weight_decay': 3.2797323544607516e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 154, Fold 1: Test Accuracy = 0.5215\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=8.120652689109823e-06, optimizer=Adam, weight_decay=2.1783396328342504e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:56:03,999] Trial 155 finished with value: 0.5466537706756378 and parameters: {'ff_dim': 64, 'dropout_rate': 0.24535643659376286, 'embed_dim': 1024, 'learning_rate': 8.605494375889457e-06, 'optimizer': 'Adam', 'weight_decay': 3.422246953154291e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 155, Fold 1: Test Accuracy = 0.5467\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=0.0001340806489579121, optimizer=Adam, weight_decay=1.8572892950073395e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:57:14,678] Trial 156 finished with value: 0.48732296047098406 and parameters: {'ff_dim': 512, 'dropout_rate': 0.48413493370303856, 'embed_dim': 1024, 'learning_rate': 8.120652689109823e-06, 'optimizer': 'Adam', 'weight_decay': 2.1783396328342504e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 156, Fold 1: Test Accuracy = 0.4873\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=0.00012892783230313994, optimizer=Adam, weight_decay=1.6342221133485596e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:57:38,668] Trial 157 finished with value: 0.34959349593495936 and parameters: {'ff_dim': 512, 'dropout_rate': 0.21057289607809726, 'embed_dim': 1024, 'learning_rate': 0.0001340806489579121, 'optimizer': 'Adam', 'weight_decay': 1.8572892950073395e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 157, Fold 1: Test Accuracy = 0.3496\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=3.817090972753421e-05, optimizer=Adam, weight_decay=1.7065652910883664e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 10\n",
      "Trial 158, Fold 1: Test Accuracy = 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 21:58:48,773] Trial 158 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 2048, 'dropout_rate': 0.21138240675030265, 'embed_dim': 1024, 'learning_rate': 0.00012892783230313994, 'optimizer': 'Adam', 'weight_decay': 1.6342221133485596e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=4.5441279143770335e-05, optimizer=Adam, weight_decay=4.231607629839888e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:00:35,133] Trial 159 finished with value: 0.5739144939725259 and parameters: {'ff_dim': 2048, 'dropout_rate': 0.1851890214649858, 'embed_dim': 1024, 'learning_rate': 3.817090972753421e-05, 'optimizer': 'Adam', 'weight_decay': 1.7065652910883664e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 159, Fold 1: Test Accuracy = 0.5739\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 15\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=0.0490192458305797, optimizer=Adam, weight_decay=1.2985509380887581e-05, batch_size=10,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:00:37,301] Trial 160 finished with value: 0.5674656574151948 and parameters: {'ff_dim': 64, 'dropout_rate': 0.17375541012878595, 'embed_dim': 128, 'learning_rate': 4.5441279143770335e-05, 'optimizer': 'Adam', 'weight_decay': 4.231607629839888e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 160, Fold 1: Test Accuracy = 0.5675\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=16, learning_rate=7.192146634157417e-07, optimizer=Adam, weight_decay=1.9018382994779144e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:02:51,097] Trial 162 finished with value: 0.5263939818708532 and parameters: {'ff_dim': 64, 'dropout_rate': 0.18761018059114104, 'embed_dim': 1024, 'learning_rate': 7.192146634157417e-07, 'optimizer': 'Adam', 'weight_decay': 1.9018382994779144e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 16}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 162, Fold 1: Test Accuracy = 0.5264\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=2, learning_rate=1.3699723812544847e-07, optimizer=Adam, weight_decay=1.3901200117764658e-05, batch_size=10,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:03:02,325] Trial 161 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 64, 'dropout_rate': 0.23703526376978784, 'embed_dim': 128, 'learning_rate': 0.0490192458305797, 'optimizer': 'Adam', 'weight_decay': 1.2985509380887581e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 161, Fold 1: Test Accuracy = 0.3333\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=2, learning_rate=2.1170141561285303e-07, optimizer=Adam, weight_decay=2.2644022089853288e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 21\n",
      "Trial 163, Fold 1: Test Accuracy = 0.4833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:05:07,457] Trial 163 finished with value: 0.48332445565834964 and parameters: {'ff_dim': 1024, 'dropout_rate': 0.4177908436390044, 'embed_dim': 1024, 'learning_rate': 1.3699723812544847e-07, 'optimizer': 'Adam', 'weight_decay': 1.3901200117764658e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 2}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: num_heads=8, num_transformer_blocks=1, learning_rate=1.9920942893806854e-07, optimizer=Adam, weight_decay=1.1449960715460778e-06, batch_size=10,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:05:57,569] Trial 164 finished with value: 0.584400523315578 and parameters: {'ff_dim': 32, 'dropout_rate': 0.4141425576364578, 'embed_dim': 1024, 'learning_rate': 2.1170141561285303e-07, 'optimizer': 'Adam', 'weight_decay': 2.2644022089853288e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 2}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 164, Fold 1: Test Accuracy = 0.5844\n",
      "Hyperparameters: num_heads=2, num_transformer_blocks=1, learning_rate=3.1827455783877265e-07, optimizer=Adam, weight_decay=1.403337752543182e-06, batch_size=10,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:07:43,874] Trial 165 finished with value: 0.5399836463881881 and parameters: {'ff_dim': 32, 'dropout_rate': 0.31795544475952453, 'embed_dim': 1024, 'learning_rate': 1.9920942893806854e-07, 'optimizer': 'Adam', 'weight_decay': 1.1449960715460778e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 1}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 165, Fold 1: Test Accuracy = 0.5400\n",
      "Hyperparameters: num_heads=2, num_transformer_blocks=16, learning_rate=3.4359747412649513e-07, optimizer=Adam, weight_decay=1.7160290174677884e-05, batch_size=32,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:08:23,696] Trial 166 finished with value: 0.5597480609288851 and parameters: {'ff_dim': 64, 'dropout_rate': 0.32178876331435324, 'embed_dim': 256, 'learning_rate': 3.1827455783877265e-07, 'optimizer': 'Adam', 'weight_decay': 1.403337752543182e-06, 'batch_size': 10, 'num_heads': 2, 'num_transformer_blocks': 1}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 166, Fold 1: Test Accuracy = 0.5597\n",
      "Hyperparameters: num_heads=16, num_transformer_blocks=16, learning_rate=1.067126930552919e-06, optimizer=Adam, weight_decay=2.596233762056418e-05, batch_size=32,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:10:09,031] Trial 167 finished with value: 0.5553164190262593 and parameters: {'ff_dim': 64, 'dropout_rate': 0.19371435747801813, 'embed_dim': 256, 'learning_rate': 3.4359747412649513e-07, 'optimizer': 'Adam', 'weight_decay': 1.7160290174677884e-05, 'batch_size': 32, 'num_heads': 2, 'num_transformer_blocks': 16}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 167, Fold 1: Test Accuracy = 0.5553\n",
      "Hyperparameters: num_heads=16, num_transformer_blocks=4, learning_rate=1.5732872508115607e-05, optimizer=Adam, weight_decay=2.8906048800720474e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:10:57,820] Trial 168 finished with value: 0.5483231473694047 and parameters: {'ff_dim': 128, 'dropout_rate': 0.19809202316267613, 'embed_dim': 1024, 'learning_rate': 1.067126930552919e-06, 'optimizer': 'Adam', 'weight_decay': 2.596233762056418e-05, 'batch_size': 32, 'num_heads': 16, 'num_transformer_blocks': 16}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 168, Fold 1: Test Accuracy = 0.5483\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=5.655214148404367e-07, optimizer=Adam, weight_decay=5.178787382665183e-06, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:11:17,656] Trial 169 finished with value: 0.5944978039435567 and parameters: {'ff_dim': 128, 'dropout_rate': 0.16264250964450036, 'embed_dim': 1024, 'learning_rate': 1.5732872508115607e-05, 'optimizer': 'Adam', 'weight_decay': 2.8906048800720474e-05, 'batch_size': 10, 'num_heads': 16, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 169, Fold 1: Test Accuracy = 0.5945\n",
      "Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=1.4744044792478613e-05, optimizer=Adam, weight_decay=2.8027997042674867e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:12:53,796] Trial 171 finished with value: 0.47311503597794596 and parameters: {'ff_dim': 128, 'dropout_rate': 0.1659294662789501, 'embed_dim': 1024, 'learning_rate': 1.4744044792478613e-05, 'optimizer': 'Adam', 'weight_decay': 2.8027997042674867e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 171, Fold 1: Test Accuracy = 0.4731\n",
      "Hyperparameters: num_heads=16, num_transformer_blocks=4, learning_rate=1.741018337792561e-05, optimizer=Adam, weight_decay=3.700864210113766e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:13:43,509] Trial 170 finished with value: 0.5111184935987291 and parameters: {'ff_dim': 256, 'dropout_rate': 0.22244848053616642, 'embed_dim': 1024, 'learning_rate': 5.655214148404367e-07, 'optimizer': 'Adam', 'weight_decay': 5.178787382665183e-06, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 170, Fold 1: Test Accuracy = 0.5111\n",
      "Hyperparameters: num_heads=16, num_transformer_blocks=4, learning_rate=3.557583958363434e-05, optimizer=Adam, weight_decay=3.6235757846397387e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:14:15,780] Trial 172 finished with value: 0.5323520231754042 and parameters: {'ff_dim': 128, 'dropout_rate': 0.14203446648075033, 'embed_dim': 1024, 'learning_rate': 1.741018337792561e-05, 'optimizer': 'Adam', 'weight_decay': 3.700864210113766e-05, 'batch_size': 10, 'num_heads': 16, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 172, Fold 1: Test Accuracy = 0.5324\n",
      "Hyperparameters: num_heads=16, num_transformer_blocks=4, learning_rate=3.439514274342068e-05, optimizer=Adam, weight_decay=2.422489642667661e-05, batch_size=10,factor=1\n",
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 12\n",
      "Trial 173, Fold 1: Test Accuracy = 0.5914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:15:02,301] Trial 173 finished with value: 0.5913545463040838 and parameters: {'ff_dim': 128, 'dropout_rate': 0.15590002993070082, 'embed_dim': 1024, 'learning_rate': 3.557583958363434e-05, 'optimizer': 'Adam', 'weight_decay': 3.6235757846397387e-05, 'batch_size': 10, 'num_heads': 16, 'num_transformer_blocks': 4}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=1.2277013047912185e-05, optimizer=Adam, weight_decay=3.196579827425196e-05, batch_size=10,factor=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-06-03 22:15:15,109] Trial 174 failed with parameters: {'ff_dim': 128, 'dropout_rate': 0.17474688657303888, 'embed_dim': 1024, 'learning_rate': 3.439514274342068e-05, 'optimizer': 'Adam', 'weight_decay': 2.422489642667661e-05, 'batch_size': 10, 'num_heads': 16, 'num_transformer_blocks': 4} because of the following error: RuntimeError('DataLoader worker (pid(s) 5088) exited unexpectedly').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Gabriel\\anaconda3\\envs\\cudaenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1251, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "  File \"c:\\Users\\Gabriel\\anaconda3\\envs\\cudaenv\\Lib\\queue.py\", line 212, in get\n",
      "    raise Empty\n",
      "_queue.Empty\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Gabriel\\anaconda3\\envs\\cudaenv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_25904\\3722803089.py\", line 79, in objective\n",
      "    for val_inputs, val_labels in val_loader:\n",
      "                                  ^^^^^^^^^^\n",
      "  File \"c:\\Users\\Gabriel\\anaconda3\\envs\\cudaenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 708, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"c:\\Users\\Gabriel\\anaconda3\\envs\\cudaenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1458, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "                ~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\Gabriel\\anaconda3\\envs\\cudaenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1410, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "                    ~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\Gabriel\\anaconda3\\envs\\cudaenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1264, in _try_get_data\n",
      "    raise RuntimeError(\n",
      "        f\"DataLoader worker (pid(s) {pids_str}) exited unexpectedly\"\n",
      "    ) from e\n",
      "RuntimeError: DataLoader worker (pid(s) 5088) exited unexpectedly\n",
      "[W 2025-06-03 22:15:15,115] Trial 174 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divergence detected. Stopping training after 10 epochs.\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 22:16:02,122] Trial 175 finished with value: 0.6067218017007756 and parameters: {'ff_dim': 32, 'dropout_rate': 0.17545572485870525, 'embed_dim': 512, 'learning_rate': 1.2277013047912185e-05, 'optimizer': 'Adam', 'weight_decay': 3.196579827425196e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 26 with value: 0.6503238949630876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 175, Fold 1: Test Accuracy = 0.6067\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 5088) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\cudaenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1251\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1251\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\cudaenv\\Lib\\queue.py:212\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_empty\u001b[38;5;241m.\u001b[39mwait(remaining)\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 125\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# Start Optuna Study\u001b[39;00m\n\u001b[0;32m    119\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[0;32m    120\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    121\u001b[0m     sampler\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler(),\n\u001b[0;32m    122\u001b[0m     pruner\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39mpruners\u001b[38;5;241m.\u001b[39mMedianPruner(n_startup_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_warmup_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_min_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, interval_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    123\u001b[0m )\n\u001b[1;32m--> 125\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# Best result\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_params)\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\cudaenv\\Lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\cudaenv\\Lib\\site-packages\\optuna\\study\\_optimize.py:100\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     98\u001b[0m                     \u001b[38;5;66;03m# Raise if exception occurred in executing the completed futures.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m                     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m completed:\n\u001b[1;32m--> 100\u001b[0m                         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m                 futures\u001b[38;5;241m.\u001b[39madd(\n\u001b[0;32m    103\u001b[0m                     executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[0;32m    104\u001b[0m                         _optimize_sequential,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    115\u001b[0m                     )\n\u001b[0;32m    116\u001b[0m                 )\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\cudaenv\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\cudaenv\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\cudaenv\\Lib\\concurrent\\futures\\thread.py:59\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\cudaenv\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\cudaenv\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\cudaenv\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[8], line 79\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     77\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 79\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_outputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\cudaenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\cudaenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1458\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1457\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1458\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1461\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\cudaenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1410\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1408\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m   1409\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[1;32m-> 1410\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1411\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1412\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\envs\\cudaenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1264\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1263\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[1;32m-> 1264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1265\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1266\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[0;32m   1268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 5088) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "\n",
    "# Select a single fold to optimize (e.g., fold 0)\n",
    "selected_fold_idx = 0\n",
    "\n",
    "def objective(trial):\n",
    "    # Hyperparameter suggestions\n",
    "    ff_dim = trial.suggest_categorical(\"ff_dim\", [32, 64, 128, 256,512,1024,2048])\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)\n",
    "    embed_dim = trial.suggest_categorical(\"embed_dim\", [32, 64, 128, 256,512,1024,2048])\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-7, 1e-1, log=True)\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"AdamW\"])\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [10, 16, 32])\n",
    "    num_heads = trial.suggest_categorical(\"num_heads\", [1, 2, 4, 8, 16])\n",
    "    num_transformer_blocks = trial.suggest_categorical(\"num_transformer_blocks\", [1, 2, 4,8,16,32])\n",
    "    label_smoothing = 0.3\n",
    "\n",
    "    factor = 1\n",
    "\n",
    "    print(f\"Hyperparameters: num_heads={num_heads}, num_transformer_blocks={num_transformer_blocks}, \"\n",
    "          f\"learning_rate={learning_rate}, optimizer={optimizer_name}, weight_decay={weight_decay}, batch_size={batch_size},factor={factor}\")\n",
    "\n",
    "    test_fold = fold_indices[selected_fold_idx]\n",
    "    remaining_folds = [fold_indices[i] for i in range(5) if i != selected_fold_idx]\n",
    "    val_fold_idx = selected_fold_idx % 4\n",
    "    val_fold = remaining_folds[val_fold_idx]\n",
    "    train_folds = [fold for fold in remaining_folds if fold != val_fold]\n",
    "\n",
    "    train_data = np.concatenate([eeg_folds[j] for j in train_folds]).transpose(0, 3, 1, 2)\n",
    "    train_labels = np.concatenate([labels_folds[j] for j in train_folds])\n",
    "\n",
    "    val_data = eeg_folds[val_fold].transpose(0, 3, 1, 2)\n",
    "    val_labels = labels_folds[val_fold]\n",
    "\n",
    "    test_data = eeg_folds[test_fold].transpose(0, 3, 1, 2)\n",
    "    test_labels = labels_folds[test_fold]\n",
    "\n",
    "    balanced_train_data, balanced_train_labels = data_balancer(train_data, train_labels, factor=factor)\n",
    "\n",
    "    train_dataset = TensorDataset(torch.tensor(balanced_train_data, dtype=torch.float32), \n",
    "                                  torch.tensor(balanced_train_labels, dtype=torch.long))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "    val_dataset = TensorDataset(torch.tensor(val_data, dtype=torch.float32), \n",
    "                                torch.tensor(val_labels, dtype=torch.long))\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    test_dataset = TensorDataset(torch.tensor(test_data, dtype=torch.float32), \n",
    "                                 torch.tensor(test_labels, dtype=torch.long))\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = TransformerModel(input_shape=input_shape, num_classes=num_classes, embed_dim=embed_dim, num_heads=num_heads, ff_dim=ff_dim,dropout_rate=dropout_rate, num_transformer_blocks=num_transformer_blocks).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "    optimizer_cls = {\"Adam\": optim.Adam, \"AdamW\": optim.AdamW, \"SGD\": optim.SGD}\n",
    "    optimizer = optimizer_cls[optimizer_name](model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=10)\n",
    "\n",
    "    epochs = 30\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_labels in val_loader:\n",
    "                val_inputs, val_labels = val_inputs.to(device, non_blocking=True), val_labels.to(device, non_blocking=True)\n",
    "                val_outputs = model(val_inputs)\n",
    "                loss = criterion(val_outputs, val_labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        early_stopping(val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "    early_stopping.load_best_model(model)\n",
    "\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    fold_acc = balanced_accuracy_score(all_labels, all_preds)\n",
    "    print(f\"Trial {trial.number}, Fold {selected_fold_idx+1}: Test Accuracy = {fold_acc:.4f}\")\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    trial.set_user_attr(\"fold_accuracy\", fold_acc)\n",
    "    trial.report(fold_acc, step=0)\n",
    "\n",
    "    if trial.should_prune():\n",
    "        raise optuna.TrialPruned()\n",
    "\n",
    "    return fold_acc\n",
    "\n",
    "# Start Optuna Study\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=optuna.samplers.TPESampler(),\n",
    "    pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5, n_min_trials=5, interval_steps=1),\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=200, n_jobs=2)\n",
    "\n",
    "# Best result\n",
    "print(\"Best hyperparameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfba9f72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
