[I 2025-05-08 10:43:49,270] A new study created in memory with name: no-name-a0dbfd8a-de7e-4fb5-8258-5dce8477cfbc
Hyperparameters: num_heads=2, num_transformer_blocks=4, learning_rate=3.398124982496925e-06, optimizer=Adam, weight_decay=1.0773829757210749e-05, batch_size=10,factor=1
Hyperparameters: num_heads=4, num_transformer_blocks=2, learning_rate=6.572573477289355e-07, optimizer=Adam, weight_decay=6.043448462641347e-06, batch_size=32,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 0, Fold 1: Test Accuracy = 0.4055
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 1, Fold 1: Test Accuracy = 0.5137
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 1, Fold 2: Test Accuracy = 0.3832
Trial 0, Fold 2: Test Accuracy = 0.3707
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 1, Fold 3: Test Accuracy = 0.4898
Trial 0, Fold 3: Test Accuracy = 0.5248
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 1, Fold 4: Test Accuracy = 0.4399
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 0, Fold 4: Test Accuracy = 0.4309
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
[I 2025-05-08 10:49:09,543] Trial 0 finished with value: 0.4158495582179203 and parameters: {'ff_dim': 256, 'dropout_rate': 0.2274490276744359, 'embed_dim': 128, 'learning_rate': 3.398124982496925e-06, 'weight_decay': 1.0773829757210749e-05, 'batch_size': 10, 'num_heads': 2, 'num_transformer_blocks': 4}. Best is trial 0 with value: 0.4158495582179203.
Trial 0, Fold 5: Test Accuracy = 0.3474
Trial 0: Mean Accuracy = 0.4158, Fold Accuracies = [np.float64(0.4054834054834055), np.float64(0.37066462649089765), np.float64(0.5247886473429951), np.float64(0.43087352462352463), np.float64(0.3474375871487785)]
Hyperparameters: num_heads=16, num_transformer_blocks=8, learning_rate=0.08298964825265703, optimizer=Adam, weight_decay=4.9773202290767266e-05, batch_size=32,factor=1
[I 2025-05-08 10:49:30,169] Trial 1 finished with value: 0.4422859443993431 and parameters: {'ff_dim': 128, 'dropout_rate': 0.2574972504954214, 'embed_dim': 512, 'learning_rate': 6.572573477289355e-07, 'weight_decay': 6.043448462641347e-06, 'batch_size': 32, 'num_heads': 4, 'num_transformer_blocks': 2}. Best is trial 1 with value: 0.4422859443993431.
Trial 1, Fold 5: Test Accuracy = 0.3849
Trial 1: Mean Accuracy = 0.4423, Fold Accuracies = [np.float64(0.5137085137085137), np.float64(0.3831672421008579), np.float64(0.48979468599033815), np.float64(0.43985297110297106), np.float64(0.3849063090940347)]
Hyperparameters: num_heads=16, num_transformer_blocks=32, learning_rate=0.010936820099105144, optimizer=Adam, weight_decay=6.430241277757145e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 2, Fold 1: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 3, Fold 1: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 2, Fold 2: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Trial 2, Fold 3: Test Accuracy = 0.3333
Trial 3, Fold 2: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 2, Fold 4: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 3, Fold 3: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
[I 2025-05-08 10:54:08,415] Trial 2 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 512, 'dropout_rate': 0.11386718231640354, 'embed_dim': 256, 'learning_rate': 0.08298964825265703, 'weight_decay': 4.9773202290767266e-05, 'batch_size': 32, 'num_heads': 16, 'num_transformer_blocks': 8}. Best is trial 1 with value: 0.4422859443993431.
Trial 2, Fold 5: Test Accuracy = 0.3333
Trial 2: Mean Accuracy = 0.3333, Fold Accuracies = [np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333)]
Hyperparameters: num_heads=8, num_transformer_blocks=32, learning_rate=0.0024429164315225376, optimizer=Adam, weight_decay=8.930576660726489e-05, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 3, Fold 4: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 4, Fold 1: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
[I 2025-05-08 10:56:04,273] Trial 3 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 128, 'dropout_rate': 0.20817689368005796, 'embed_dim': 64, 'learning_rate': 0.010936820099105144, 'weight_decay': 6.430241277757145e-05, 'batch_size': 16, 'num_heads': 16, 'num_transformer_blocks': 32}. Best is trial 1 with value: 0.4422859443993431.
Trial 3, Fold 5: Test Accuracy = 0.3333
Trial 3: Mean Accuracy = 0.3333, Fold Accuracies = [np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333)]
Hyperparameters: num_heads=8, num_transformer_blocks=32, learning_rate=0.012116310589374523, optimizer=Adam, weight_decay=9.232374303056616e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 4, Fold 2: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 5, Fold 1: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 4, Fold 3: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 5, Fold 2: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 5, Fold 3: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
Trial 4, Fold 4: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 5, Fold 4: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
[I 2025-05-08 11:02:20,394] Trial 4 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 512, 'dropout_rate': 0.2916735655885666, 'embed_dim': 32, 'learning_rate': 0.0024429164315225376, 'weight_decay': 8.930576660726489e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 32}. Best is trial 1 with value: 0.4422859443993431.
Trial 4, Fold 5: Test Accuracy = 0.3333
Trial 4: Mean Accuracy = 0.3333, Fold Accuracies = [np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333)]
Hyperparameters: num_heads=4, num_transformer_blocks=16, learning_rate=0.01697666050771217, optimizer=Adam, weight_decay=7.285842321931726e-05, batch_size=32,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 6, Fold 1: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
[I 2025-05-08 11:04:08,593] Trial 5 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 128, 'dropout_rate': 0.1621928368252591, 'embed_dim': 128, 'learning_rate': 0.012116310589374523, 'weight_decay': 9.232374303056616e-05, 'batch_size': 16, 'num_heads': 8, 'num_transformer_blocks': 32}. Best is trial 1 with value: 0.4422859443993431.
Trial 5, Fold 5: Test Accuracy = 0.3333
Trial 5: Mean Accuracy = 0.3333, Fold Accuracies = [np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333)]
Hyperparameters: num_heads=16, num_transformer_blocks=8, learning_rate=8.57119858457158e-06, optimizer=Adam, weight_decay=1.5080386770529378e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 6, Fold 2: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 7, Fold 1: Test Accuracy = 0.4468
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 6, Fold 3: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 7, Fold 2: Test Accuracy = 0.4228
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Trial 6, Fold 4: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 7, Fold 3: Test Accuracy = 0.3989
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
[I 2025-05-08 11:07:28,757] Trial 6 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 512, 'dropout_rate': 0.2193661155392101, 'embed_dim': 64, 'learning_rate': 0.01697666050771217, 'weight_decay': 7.285842321931726e-05, 'batch_size': 32, 'num_heads': 4, 'num_transformer_blocks': 16}. Best is trial 1 with value: 0.4422859443993431.
Trial 6, Fold 5: Test Accuracy = 0.3333
Trial 6: Mean Accuracy = 0.3333, Fold Accuracies = [np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333)]
Hyperparameters: num_heads=16, num_transformer_blocks=1, learning_rate=4.647640154731444e-05, optimizer=Adam, weight_decay=0.0007964858782869212, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 7, Fold 4: Test Accuracy = 0.4325
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Trial 8, Fold 1: Test Accuracy = 0.5111
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
[I 2025-05-08 11:08:59,849] Trial 7 finished with value: 0.4236203161423206 and parameters: {'ff_dim': 256, 'dropout_rate': 0.2038880260375684, 'embed_dim': 64, 'learning_rate': 8.57119858457158e-06, 'weight_decay': 1.5080386770529378e-05, 'batch_size': 16, 'num_heads': 16, 'num_transformer_blocks': 8}. Best is trial 1 with value: 0.4422859443993431.
Trial 7, Fold 5: Test Accuracy = 0.4170
Trial 7: Mean Accuracy = 0.4236, Fold Accuracies = [np.float64(0.4467893217893218), np.float64(0.4228264281230383), np.float64(0.3989130434782609), np.float64(0.4325269637769638), np.float64(0.4170458235440185)]
Hyperparameters: num_heads=16, num_transformer_blocks=8, learning_rate=2.986230076772995e-06, optimizer=Adam, weight_decay=2.4473561010518278e-05, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 8, Fold 2: Test Accuracy = 0.4105
Trial 9, Fold 1: Test Accuracy = 0.4272
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
Trial 8, Fold 3: Test Accuracy = 0.5986
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Trial 9, Fold 2: Test Accuracy = 0.4128
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
Trial 8, Fold 4: Test Accuracy = 0.3614
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 9, Fold 3: Test Accuracy = 0.5618
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
[I 2025-05-08 11:13:47,497] Trial 8 finished with value: 0.45177459105847867 and parameters: {'ff_dim': 64, 'dropout_rate': 0.2724230739591647, 'embed_dim': 64, 'learning_rate': 4.647640154731444e-05, 'weight_decay': 0.0007964858782869212, 'batch_size': 10, 'num_heads': 16, 'num_transformer_blocks': 1}. Best is trial 8 with value: 0.45177459105847867.
Trial 8, Fold 5: Test Accuracy = 0.3773
Trial 8: Mean Accuracy = 0.4518, Fold Accuracies = [np.float64(0.5110930735930735), np.float64(0.4105265222849968), np.float64(0.5985507246376812), np.float64(0.36139092389092387), np.float64(0.3773117108857182)]
Hyperparameters: num_heads=16, num_transformer_blocks=16, learning_rate=0.0050344740107442975, optimizer=Adam, weight_decay=1.3608452518519408e-06, batch_size=32,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 9, Fold 4: Test Accuracy = 0.3989
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 10, Fold 1: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 10, Fold 2: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
[I 2025-05-08 11:16:13,317] Trial 9 finished with value: 0.4409161424879673 and parameters: {'ff_dim': 32, 'dropout_rate': 0.1226120058859598, 'embed_dim': 256, 'learning_rate': 2.986230076772995e-06, 'weight_decay': 2.4473561010518278e-05, 'batch_size': 10, 'num_heads': 16, 'num_transformer_blocks': 8}. Best is trial 8 with value: 0.45177459105847867.
Trial 9, Fold 5: Test Accuracy = 0.4039
Trial 9: Mean Accuracy = 0.4409, Fold Accuracies = [np.float64(0.4272186147186147), np.float64(0.4127563297761038), np.float64(0.5618055555555556), np.float64(0.39894943019943013), np.float64(0.4038507821901323)]
Hyperparameters: num_heads=1, num_transformer_blocks=1, learning_rate=0.0002023177443342631, optimizer=Adam, weight_decay=0.0007280715309568118, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 10, Fold 3: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
Trial 11, Fold 1: Test Accuracy = 0.4573
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 10, Fold 4: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 11, Fold 2: Test Accuracy = 0.4728
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
[I 2025-05-08 11:19:41,425] Trial 10 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 512, 'dropout_rate': 0.20149290854761226, 'embed_dim': 128, 'learning_rate': 0.0050344740107442975, 'weight_decay': 1.3608452518519408e-06, 'batch_size': 32, 'num_heads': 16, 'num_transformer_blocks': 16}. Best is trial 8 with value: 0.45177459105847867.
Trial 10, Fold 5: Test Accuracy = 0.3333
Trial 10: Mean Accuracy = 0.3333, Fold Accuracies = [np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333)]
Hyperparameters: num_heads=4, num_transformer_blocks=2, learning_rate=2.1663687173149606e-07, optimizer=Adam, weight_decay=0.0005808160489263726, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 12, Fold 1: Test Accuracy = 0.4200
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
Trial 11, Fold 3: Test Accuracy = 0.4445
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Trial 11, Fold 4: Test Accuracy = 0.4653
Trial 12, Fold 2: Test Accuracy = 0.3706
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
[I 2025-05-08 11:23:58,965] Trial 11 finished with value: 0.43553489717433064 and parameters: {'ff_dim': 64, 'dropout_rate': 0.2983321076975251, 'embed_dim': 32, 'learning_rate': 0.0002023177443342631, 'weight_decay': 0.0007280715309568118, 'batch_size': 10, 'num_heads': 1, 'num_transformer_blocks': 1}. Best is trial 8 with value: 0.45177459105847867.
Trial 11, Fold 5: Test Accuracy = 0.3378
Trial 11: Mean Accuracy = 0.4355, Fold Accuracies = [np.float64(0.45725108225108224), np.float64(0.472791117388575), np.float64(0.44453502415458934), np.float64(0.4653286528286528), np.float64(0.3377686092487537)]
Hyperparameters: num_heads=4, num_transformer_blocks=2, learning_rate=1.0927239462140566e-07, optimizer=Adam, weight_decay=3.008240032473233e-06, batch_size=32,factor=1
Trial 12, Fold 3: Test Accuracy = 0.4499
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 13, Fold 1: Test Accuracy = 0.4011
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 13, Fold 2: Test Accuracy = 0.3261
Trial 12, Fold 4: Test Accuracy = 0.3482
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 13, Fold 3: Test Accuracy = 0.2876
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
[I 2025-05-08 11:27:03,489] Trial 12 finished with value: 0.3921334438003798 and parameters: {'ff_dim': 64, 'dropout_rate': 0.27909310364729745, 'embed_dim': 512, 'learning_rate': 2.1663687173149606e-07, 'weight_decay': 0.0005808160489263726, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 2}. Best is trial 8 with value: 0.45177459105847867.
Trial 12, Fold 5: Test Accuracy = 0.3720
Trial 12: Mean Accuracy = 0.3921, Fold Accuracies = [np.float64(0.4200036075036075), np.float64(0.37063847039129527), np.float64(0.44987922705314004), np.float64(0.3481634106634106), np.float64(0.37198250339044564)]
Hyperparameters: num_heads=4, num_transformer_blocks=2, learning_rate=1.78365995917288e-07, optimizer=Adam, weight_decay=4.195530461725651e-06, batch_size=32,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
Trial 13, Fold 4: Test Accuracy = 0.4381
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 14, Fold 1: Test Accuracy = 0.4099
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
[I 2025-05-08 11:29:02,618] Trial 13 finished with value: 0.36112904097941567 and parameters: {'ff_dim': 64, 'dropout_rate': 0.258302952246159, 'embed_dim': 512, 'learning_rate': 1.0927239462140566e-07, 'weight_decay': 3.008240032473233e-06, 'batch_size': 32, 'num_heads': 4, 'num_transformer_blocks': 2}. Best is trial 8 with value: 0.45177459105847867.
Trial 13, Fold 5: Test Accuracy = 0.3529
Trial 13: Mean Accuracy = 0.3611, Fold Accuracies = [np.float64(0.40106421356421357), np.float64(0.32605539861895794), np.float64(0.28756038647342996), np.float64(0.43807234432234426), np.float64(0.3528928619181326)]
Hyperparameters: num_heads=1, num_transformer_blocks=1, learning_rate=0.00011118523538352134, optimizer=Adam, weight_decay=4.841550151204454e-06, batch_size=32,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 14, Fold 2: Test Accuracy = 0.2897
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 15, Fold 1: Test Accuracy = 0.4619
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 14, Fold 3: Test Accuracy = 0.2858
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 14, Fold 4: Test Accuracy = 0.3273
Trial 15, Fold 2: Test Accuracy = 0.4378
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 15, Fold 3: Test Accuracy = 0.4883
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
[I 2025-05-08 11:32:36,200] Trial 14 finished with value: 0.34201322202198015 and parameters: {'ff_dim': 128, 'dropout_rate': 0.26271889482455535, 'embed_dim': 512, 'learning_rate': 1.78365995917288e-07, 'weight_decay': 4.195530461725651e-06, 'batch_size': 32, 'num_heads': 4, 'num_transformer_blocks': 2}. Best is trial 8 with value: 0.45177459105847867.
Trial 14, Fold 5: Test Accuracy = 0.3973
Trial 14: Mean Accuracy = 0.3420, Fold Accuracies = [np.float64(0.4099025974025974), np.float64(0.28971149822138526), np.float64(0.2858393719806763), np.float64(0.32731735856735855), np.float64(0.39729528393788316)]
Hyperparameters: num_heads=1, num_transformer_blocks=1, learning_rate=8.05196537136388e-05, optimizer=Adam, weight_decay=0.00023471994905142714, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 16, Fold 1: Test Accuracy = 0.5090
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 28
Trial 15, Fold 4: Test Accuracy = 0.4714
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 16, Fold 2: Test Accuracy = 0.4523
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
[I 2025-05-08 11:35:17,009] Trial 15 finished with value: 0.4466307393896434 and parameters: {'ff_dim': 128, 'dropout_rate': 0.25136596718432075, 'embed_dim': 512, 'learning_rate': 0.00011118523538352134, 'weight_decay': 4.841550151204454e-06, 'batch_size': 32, 'num_heads': 1, 'num_transformer_blocks': 1}. Best is trial 8 with value: 0.45177459105847867.
Trial 15, Fold 5: Test Accuracy = 0.3736
Trial 15: Mean Accuracy = 0.4466, Fold Accuracies = [np.float64(0.46194083694083693), np.float64(0.4378073341703285), np.float64(0.48834541062801934), np.float64(0.4714463776963777), np.float64(0.3736137375126545)]
Hyperparameters: num_heads=1, num_transformer_blocks=1, learning_rate=0.00011979199951166355, optimizer=Adam, weight_decay=0.0002827447817058559, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 16, Fold 3: Test Accuracy = 0.5114
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 17, Fold 1: Test Accuracy = 0.3522
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 16, Fold 4: Test Accuracy = 0.3902
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 17, Fold 2: Test Accuracy = 0.3779
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
[I 2025-05-08 11:39:29,083] Trial 16 finished with value: 0.4413432162323656 and parameters: {'ff_dim': 32, 'dropout_rate': 0.2462550239759675, 'embed_dim': 512, 'learning_rate': 8.05196537136388e-05, 'weight_decay': 0.00023471994905142714, 'batch_size': 10, 'num_heads': 1, 'num_transformer_blocks': 1}. Best is trial 8 with value: 0.45177459105847867.
Trial 16, Fold 5: Test Accuracy = 0.3437
Trial 16: Mean Accuracy = 0.4413, Fold Accuracies = [np.float64(0.509018759018759), np.float64(0.4523305084745763), np.float64(0.5114130434782608), np.float64(0.39023707773707766), np.float64(0.34371669245315456)]
Hyperparameters: num_heads=1, num_transformer_blocks=1, learning_rate=0.00014322206670365554, optimizer=Adam, weight_decay=1.697736139140734e-06, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
Trial 17, Fold 3: Test Accuracy = 0.4790
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 18, Fold 1: Test Accuracy = 0.4284
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 17, Fold 4: Test Accuracy = 0.4860
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 29
Trial 18, Fold 2: Test Accuracy = 0.4264
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
[I 2025-05-08 11:43:34,246] Trial 17 finished with value: 0.41594813487542126 and parameters: {'ff_dim': 32, 'dropout_rate': 0.23825047701332414, 'embed_dim': 64, 'learning_rate': 0.00011979199951166355, 'weight_decay': 0.0002827447817058559, 'batch_size': 10, 'num_heads': 1, 'num_transformer_blocks': 1}. Best is trial 8 with value: 0.45177459105847867.
Trial 17, Fold 5: Test Accuracy = 0.3848
Trial 17: Mean Accuracy = 0.4159, Fold Accuracies = [np.float64(0.3521825396825397), np.float64(0.37786409290646583), np.float64(0.4789553140096618), np.float64(0.48595848595848595), np.float64(0.384780241819953)]
Hyperparameters: num_heads=2, num_transformer_blocks=1, learning_rate=0.000582536314556408, optimizer=Adam, weight_decay=2.13330676187778e-06, batch_size=32,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 28
Trial 18, Fold 3: Test Accuracy = 0.4608
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 18, Fold 4: Test Accuracy = 0.4084
Trial 19, Fold 1: Test Accuracy = 0.4543
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
[I 2025-05-08 11:46:49,285] Trial 18 finished with value: 0.41418869610601855 and parameters: {'ff_dim': 64, 'dropout_rate': 0.16126549426325087, 'embed_dim': 64, 'learning_rate': 0.00014322206670365554, 'weight_decay': 1.697736139140734e-06, 'batch_size': 10, 'num_heads': 1, 'num_transformer_blocks': 1}. Best is trial 8 with value: 0.45177459105847867.
Trial 18, Fold 5: Test Accuracy = 0.3470
Trial 18: Mean Accuracy = 0.4142, Fold Accuracies = [np.float64(0.4283910533910534), np.float64(0.4263509625444654), np.float64(0.4608393719806763), np.float64(0.40838675213675213), np.float64(0.34697534047714557)]
Hyperparameters: num_heads=2, num_transformer_blocks=1, learning_rate=0.000830705843352676, optimizer=Adam, weight_decay=0.0002114212594580932, batch_size=32,factor=1
Trial 19, Fold 2: Test Accuracy = 0.4692
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 20, Fold 1: Test Accuracy = 0.3477
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 20, Fold 2: Test Accuracy = 0.3439
Trial 19, Fold 3: Test Accuracy = 0.4951
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 19, Fold 4: Test Accuracy = 0.4887
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Trial 20, Fold 3: Test Accuracy = 0.5978
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
[I 2025-05-08 11:50:44,749] Trial 19 finished with value: 0.4606266643484158 and parameters: {'ff_dim': 64, 'dropout_rate': 0.17819477485429114, 'embed_dim': 64, 'learning_rate': 0.000582536314556408, 'weight_decay': 2.13330676187778e-06, 'batch_size': 32, 'num_heads': 2, 'num_transformer_blocks': 1}. Best is trial 19 with value: 0.4606266643484158.
Trial 19, Fold 5: Test Accuracy = 0.3958
Trial 19: Mean Accuracy = 0.4606, Fold Accuracies = [np.float64(0.4542748917748917), np.float64(0.4692338878426449), np.float64(0.49513888888888885), np.float64(0.4887184574684575), np.float64(0.39576719576719577)]
Hyperparameters: num_heads=2, num_transformer_blocks=4, learning_rate=0.0006853561186469903, optimizer=Adam, weight_decay=0.00015357806952655227, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 20, Fold 4: Test Accuracy = 0.3373
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 21, Fold 1: Test Accuracy = 0.4157
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
[I 2025-05-08 11:51:34,733] Trial 20 finished with value: 0.40897604375818686 and parameters: {'ff_dim': 128, 'dropout_rate': 0.2734972633486991, 'embed_dim': 256, 'learning_rate': 0.000830705843352676, 'weight_decay': 0.0002114212594580932, 'batch_size': 32, 'num_heads': 2, 'num_transformer_blocks': 1}. Best is trial 19 with value: 0.4606266643484158.
Trial 20, Fold 5: Test Accuracy = 0.4182
Trial 20: Mean Accuracy = 0.4090, Fold Accuracies = [np.float64(0.3476731601731602), np.float64(0.3438677024482109), np.float64(0.5977657004830917), np.float64(0.3373397435897436), np.float64(0.41823391209672794)]
Hyperparameters: num_heads=2, num_transformer_blocks=1, learning_rate=2.380380550196826e-05, optimizer=Adam, weight_decay=1.0213487443246716e-06, batch_size=32,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Trial 21, Fold 2: Test Accuracy = 0.3555
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 22, Fold 1: Test Accuracy = 0.4931
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 22, Fold 2: Test Accuracy = 0.4010
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
Trial 21, Fold 3: Test Accuracy = 0.5477
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 21, Fold 4: Test Accuracy = 0.4381
Trial 22, Fold 3: Test Accuracy = 0.5577
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
[I 2025-05-08 11:55:42,124] Trial 21 finished with value: 0.4325677542138652 and parameters: {'ff_dim': 64, 'dropout_rate': 0.17382524176838618, 'embed_dim': 64, 'learning_rate': 0.0006853561186469903, 'weight_decay': 0.00015357806952655227, 'batch_size': 16, 'num_heads': 2, 'num_transformer_blocks': 4}. Best is trial 19 with value: 0.4606266643484158.
Trial 21, Fold 5: Test Accuracy = 0.4059
Trial 21: Mean Accuracy = 0.4326, Fold Accuracies = [np.float64(0.4156746031746032), np.float64(0.3554613935969868), np.float64(0.5477053140096618), np.float64(0.43811050061050055), np.float64(0.40588695967757343)]
Hyperparameters: num_heads=2, num_transformer_blocks=1, learning_rate=2.11897791836904e-05, optimizer=Adam, weight_decay=1.0838822535638158e-06, batch_size=32,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 23, Fold 1: Test Accuracy = 0.3598
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 29
Trial 23, Fold 2: Test Accuracy = 0.4040
Trial 22, Fold 4: Test Accuracy = 0.3711
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
[I 2025-05-08 11:58:11,938] Trial 22 finished with value: 0.44617248468956683 and parameters: {'ff_dim': 64, 'dropout_rate': 0.17114872284014532, 'embed_dim': 64, 'learning_rate': 2.380380550196826e-05, 'weight_decay': 1.0213487443246716e-06, 'batch_size': 32, 'num_heads': 2, 'num_transformer_blocks': 1}. Best is trial 19 with value: 0.4606266643484158.
Trial 22, Fold 5: Test Accuracy = 0.4079
Trial 22: Mean Accuracy = 0.4462, Fold Accuracies = [np.float64(0.4930555555555556), np.float64(0.40103185812931574), np.float64(0.5576992753623188), np.float64(0.37113349613349617), np.float64(0.40794223826714804)]
Hyperparameters: num_heads=2, num_transformer_blocks=1, learning_rate=2.6329783293816797e-05, optimizer=Adam, weight_decay=2.7429622508651865e-06, batch_size=32,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 23, Fold 3: Test Accuracy = 0.5413
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 24, Fold 1: Test Accuracy = 0.4183
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Trial 23, Fold 4: Test Accuracy = 0.3269
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 24, Fold 2: Test Accuracy = 0.3587
[I 2025-05-08 12:00:49,732] Trial 23 finished with value: 0.38997673090120155 and parameters: {'ff_dim': 64, 'dropout_rate': 0.17643319970804588, 'embed_dim': 64, 'learning_rate': 2.11897791836904e-05, 'weight_decay': 1.0838822535638158e-06, 'batch_size': 32, 'num_heads': 2, 'num_transformer_blocks': 1}. Best is trial 19 with value: 0.4606266643484158.
Trial 23, Fold 5: Test Accuracy = 0.3178
Trial 23: Mean Accuracy = 0.3900, Fold Accuracies = [np.float64(0.35984848484848486), np.float64(0.40402019250889304), np.float64(0.5413043478260869), np.float64(0.32694851444851447), np.float64(0.3177621148740282)]
Hyperparameters: num_heads=1, num_transformer_blocks=1, learning_rate=0.0010669804134923239, optimizer=Adam, weight_decay=2.7347050415692995e-06, batch_size=32,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 25, Fold 1: Test Accuracy = 0.4453
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
Trial 24, Fold 3: Test Accuracy = 0.5375
Trial 25, Fold 2: Test Accuracy = 0.3353
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
Trial 24, Fold 4: Test Accuracy = 0.3427
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
[I 2025-05-08 12:04:49,766] Trial 24 finished with value: 0.40124668656141377 and parameters: {'ff_dim': 64, 'dropout_rate': 0.1890555826147434, 'embed_dim': 64, 'learning_rate': 2.6329783293816797e-05, 'weight_decay': 2.7429622508651865e-06, 'batch_size': 32, 'num_heads': 2, 'num_transformer_blocks': 1}. Best is trial 19 with value: 0.4606266643484158.
Trial 24, Fold 5: Test Accuracy = 0.3490
Trial 24: Mean Accuracy = 0.4012, Fold Accuracies = [np.float64(0.4182900432900433), np.float64(0.3586589767733836), np.float64(0.537530193236715), np.float64(0.34271978021978017), np.float64(0.3490344392871469)]
Hyperparameters: num_heads=1, num_transformer_blocks=1, learning_rate=0.0005726181103409623, optimizer=Adam, weight_decay=7.14819390557156e-06, batch_size=32,factor=1
Trial 25, Fold 3: Test Accuracy = 0.5057
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 26, Fold 1: Test Accuracy = 0.4865
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 25, Fold 4: Test Accuracy = 0.3496
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 26, Fold 2: Test Accuracy = 0.3834
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
[I 2025-05-08 12:07:05,848] Trial 25 finished with value: 0.3866950034935165 and parameters: {'ff_dim': 64, 'dropout_rate': 0.14243689387157044, 'embed_dim': 32, 'learning_rate': 0.0010669804134923239, 'weight_decay': 2.7347050415692995e-06, 'batch_size': 32, 'num_heads': 1, 'num_transformer_blocks': 1}. Best is trial 19 with value: 0.4606266643484158.
Trial 25, Fold 5: Test Accuracy = 0.2975
Trial 25: Mean Accuracy = 0.3867, Fold Accuracies = [np.float64(0.4453463203463204), np.float64(0.33533427495291906), np.float64(0.5056763285024154), np.float64(0.34962606837606836), np.float64(0.29749202528985924)]
Hyperparameters: num_heads=8, num_transformer_blocks=1, learning_rate=0.00035921436745099927, optimizer=Adam, weight_decay=6.4656684199488595e-06, batch_size=32,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 26, Fold 3: Test Accuracy = 0.5543
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 27, Fold 1: Test Accuracy = 0.4003
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 26, Fold 4: Test Accuracy = 0.3076
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 27, Fold 2: Test Accuracy = 0.3364
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 27, Fold 3: Test Accuracy = 0.4077
[I 2025-05-08 12:10:36,667] Trial 26 finished with value: 0.4229105028277723 and parameters: {'ff_dim': 256, 'dropout_rate': 0.15219434633931098, 'embed_dim': 32, 'learning_rate': 0.0005726181103409623, 'weight_decay': 7.14819390557156e-06, 'batch_size': 32, 'num_heads': 1, 'num_transformer_blocks': 1}. Best is trial 19 with value: 0.4606266643484158.
Trial 26, Fold 5: Test Accuracy = 0.3827
Trial 26: Mean Accuracy = 0.4229, Fold Accuracies = [np.float64(0.48647186147186144), np.float64(0.38341572504708094), np.float64(0.5543176328502416), np.float64(0.3076414326414327), np.float64(0.3827058621282448)]
Hyperparameters: num_heads=8, num_transformer_blocks=1, learning_rate=5.366953635086111e-05, optimizer=Adam, weight_decay=2.803549941296244e-05, batch_size=32,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 27, Fold 4: Test Accuracy = 0.3419
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 28, Fold 1: Test Accuracy = 0.4682
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
[I 2025-05-08 12:12:46,304] Trial 27 finished with value: 0.3828340759662074 and parameters: {'ff_dim': 256, 'dropout_rate': 0.23982323012471657, 'embed_dim': 512, 'learning_rate': 0.00035921436745099927, 'weight_decay': 6.4656684199488595e-06, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 1}. Best is trial 19 with value: 0.4606266643484158.
Trial 27, Fold 5: Test Accuracy = 0.4279
Trial 27: Mean Accuracy = 0.3828, Fold Accuracies = [np.float64(0.40025252525252525), np.float64(0.33643283113622097), np.float64(0.4076992753623188), np.float64(0.3419057794057794), np.float64(0.4278799686741925)]
Hyperparameters: num_heads=16, num_transformer_blocks=16, learning_rate=6.319349893667354e-05, optimizer=Adam, weight_decay=2.7028900946929107e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 28, Fold 2: Test Accuracy = 0.3682
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 28, Fold 3: Test Accuracy = 0.4650
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 29, Fold 1: Test Accuracy = 0.4278
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 28, Fold 4: Test Accuracy = 0.4464
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
Trial 29, Fold 2: Test Accuracy = 0.4086
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
[I 2025-05-08 12:15:40,247] Trial 28 finished with value: 0.41615816688541285 and parameters: {'ff_dim': 128, 'dropout_rate': 0.2256809692046585, 'embed_dim': 512, 'learning_rate': 5.366953635086111e-05, 'weight_decay': 2.803549941296244e-05, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 1}. Best is trial 19 with value: 0.4606266643484158.
Trial 28, Fold 5: Test Accuracy = 0.3331
Trial 28: Mean Accuracy = 0.4162, Fold Accuracies = [np.float64(0.46816378066378067), np.float64(0.36817325800376643), np.float64(0.4649758454106281), np.float64(0.44641585266585265), np.float64(0.33306209768303635)]
Hyperparameters: num_heads=16, num_transformer_blocks=4, learning_rate=2.7548923811847403e-06, optimizer=Adam, weight_decay=1.4321213183402708e-05, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 30, Fold 1: Test Accuracy = 0.4492
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
Trial 29, Fold 3: Test Accuracy = 0.5399
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 30, Fold 2: Test Accuracy = 0.3060
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 29, Fold 4: Test Accuracy = 0.3445
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 30, Fold 3: Test Accuracy = 0.5198
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
[I 2025-05-08 12:20:23,774] Trial 29 finished with value: 0.41297966186853596 and parameters: {'ff_dim': 128, 'dropout_rate': 0.2780683675977887, 'embed_dim': 64, 'learning_rate': 6.319349893667354e-05, 'weight_decay': 2.7028900946929107e-05, 'batch_size': 16, 'num_heads': 16, 'num_transformer_blocks': 16}. Best is trial 19 with value: 0.4606266643484158.
Trial 29, Fold 5: Test Accuracy = 0.3441
Trial 29: Mean Accuracy = 0.4130, Fold Accuracies = [np.float64(0.42775974025974023), np.float64(0.40862366603892025), np.float64(0.539885265700483), np.float64(0.3445385632885633), np.float64(0.34409107405497297)]
Hyperparameters: num_heads=2, num_transformer_blocks=4, learning_rate=4.1062361988564824e-06, optimizer=Adam, weight_decay=1.1232756641996003e-05, batch_size=10,factor=1
Trial 30, Fold 4: Test Accuracy = 0.3268
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 31, Fold 1: Test Accuracy = 0.4591
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
[I 2025-05-08 12:21:38,559] Trial 30 finished with value: 0.4021774093143766 and parameters: {'ff_dim': 64, 'dropout_rate': 0.18645143804672115, 'embed_dim': 128, 'learning_rate': 2.7548923811847403e-06, 'weight_decay': 1.4321213183402708e-05, 'batch_size': 10, 'num_heads': 16, 'num_transformer_blocks': 4}. Best is trial 19 with value: 0.4606266643484158.
Trial 30, Fold 5: Test Accuracy = 0.4091
Trial 30: Mean Accuracy = 0.4022, Fold Accuracies = [np.float64(0.44922438672438675), np.float64(0.3059675141242938), np.float64(0.5197765700483092), np.float64(0.3267958892958893), np.float64(0.40912268637900406)]
Hyperparameters: num_heads=2, num_transformer_blocks=1, learning_rate=1.054730847558432e-05, optimizer=Adam, weight_decay=1.6881415249229259e-06, batch_size=32,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 31, Fold 2: Test Accuracy = 0.3691
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 32, Fold 1: Test Accuracy = 0.4646
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 32, Fold 2: Test Accuracy = 0.3743
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 31, Fold 3: Test Accuracy = 0.5599
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 32, Fold 3: Test Accuracy = 0.5578
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 31, Fold 4: Test Accuracy = 0.4201
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
Trial 32, Fold 4: Test Accuracy = 0.3743
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
[I 2025-05-08 12:25:32,484] Trial 31 finished with value: 0.44058537329714237 and parameters: {'ff_dim': 64, 'dropout_rate': 0.13679111512849618, 'embed_dim': 128, 'learning_rate': 4.1062361988564824e-06, 'weight_decay': 1.1232756641996003e-05, 'batch_size': 10, 'num_heads': 2, 'num_transformer_blocks': 4}. Best is trial 19 with value: 0.4606266643484158.
Trial 31, Fold 5: Test Accuracy = 0.3947
Trial 31: Mean Accuracy = 0.4406, Fold Accuracies = [np.float64(0.45914502164502163), np.float64(0.3690691044151497), np.float64(0.559933574879227), np.float64(0.4201007326007326), np.float64(0.39467843294558097)]
Hyperparameters: num_heads=2, num_transformer_blocks=1, learning_rate=1.7132627783621882e-05, optimizer=Adam, weight_decay=1.786174609912199e-06, batch_size=32,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
[I 2025-05-08 12:27:01,268] Trial 32 finished with value: 0.4340455731947358 and parameters: {'ff_dim': 64, 'dropout_rate': 0.138142992120247, 'embed_dim': 64, 'learning_rate': 1.054730847558432e-05, 'weight_decay': 1.6881415249229259e-06, 'batch_size': 32, 'num_heads': 2, 'num_transformer_blocks': 1}. Best is trial 19 with value: 0.4606266643484158.
Trial 32, Fold 5: Test Accuracy = 0.3993
Trial 32: Mean Accuracy = 0.4340, Fold Accuracies = [np.float64(0.4646464646464646), np.float64(0.3742610901862314), np.float64(0.5577596618357489), np.float64(0.37427503052503047), np.float64(0.39928561878020363)]
Hyperparameters: num_heads=2, num_transformer_blocks=1, learning_rate=2.0293600662535475e-05, optimizer=Adam, weight_decay=1.0081426534733607e-06, batch_size=32,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
Trial 33, Fold 1: Test Accuracy = 0.4496
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 33, Fold 2: Test Accuracy = 0.4343
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 34, Fold 1: Test Accuracy = 0.5091
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 33, Fold 3: Test Accuracy = 0.4637
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Trial 34, Fold 2: Test Accuracy = 0.4447
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 33, Fold 4: Test Accuracy = 0.4010
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 34, Fold 3: Test Accuracy = 0.4580
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 34, Fold 4: Test Accuracy = 0.4131
[I 2025-05-08 12:32:24,953] Trial 33 finished with value: 0.41524461834803567 and parameters: {'ff_dim': 64, 'dropout_rate': 0.2176525762418505, 'embed_dim': 64, 'learning_rate': 1.7132627783621882e-05, 'weight_decay': 1.786174609912199e-06, 'batch_size': 32, 'num_heads': 2, 'num_transformer_blocks': 1}. Best is trial 19 with value: 0.4606266643484158.
Trial 33, Fold 5: Test Accuracy = 0.3276
Trial 33: Mean Accuracy = 0.4152, Fold Accuracies = [np.float64(0.4495851370851371), np.float64(0.434256643649299), np.float64(0.463737922705314), np.float64(0.40104802604802603), np.float64(0.327595362252402)]
Hyperparameters: num_heads=2, num_transformer_blocks=1, learning_rate=3.7977014594923156e-05, optimizer=Adam, weight_decay=4.6742011225964905e-06, batch_size=32,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
[I 2025-05-08 12:33:03,362] Trial 34 finished with value: 0.438329679539609 and parameters: {'ff_dim': 64, 'dropout_rate': 0.2188499048994482, 'embed_dim': 64, 'learning_rate': 2.0293600662535475e-05, 'weight_decay': 1.0081426534733607e-06, 'batch_size': 32, 'num_heads': 2, 'num_transformer_blocks': 1}. Best is trial 19 with value: 0.4606266643484158.
Trial 34, Fold 5: Test Accuracy = 0.3668
Trial 34: Mean Accuracy = 0.4383, Fold Accuracies = [np.float64(0.5091089466089466), np.float64(0.4446929273906675), np.float64(0.4580012077294686), np.float64(0.4130926943426943), np.float64(0.3667526216262678)]
Hyperparameters: num_heads=2, num_transformer_blocks=1, learning_rate=7.100877694882721e-07, optimizer=Adam, weight_decay=4.090105231381161e-06, batch_size=32,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 36, Fold 1: Test Accuracy = 0.3897
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 29
Trial 35, Fold 1: Test Accuracy = 0.4592
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 35, Fold 2: Test Accuracy = 0.3675
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 29
Trial 36, Fold 2: Test Accuracy = 0.4105
Trial 35, Fold 3: Test Accuracy = 0.5195
Trial 36, Fold 3: Test Accuracy = 0.4756
Trial 35, Fold 4: Test Accuracy = 0.3994
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 36, Fold 4: Test Accuracy = 0.3732
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
[I 2025-05-08 12:40:17,979] Trial 36 finished with value: 0.40197095957721213 and parameters: {'ff_dim': 128, 'dropout_rate': 0.18657980493963586, 'embed_dim': 256, 'learning_rate': 7.100877694882721e-07, 'weight_decay': 4.090105231381161e-06, 'batch_size': 32, 'num_heads': 2, 'num_transformer_blocks': 1}. Best is trial 19 with value: 0.4606266643484158.
Trial 36, Fold 5: Test Accuracy = 0.3609
Trial 36: Mean Accuracy = 0.4020, Fold Accuracies = [np.float64(0.3897005772005772), np.float64(0.41046113203599077), np.float64(0.4755736714975845), np.float64(0.3732193732193732), np.float64(0.36090004393253494)]
Hyperparameters: num_heads=2, num_transformer_blocks=32, learning_rate=0.0023371113628463777, optimizer=Adam, weight_decay=4.5656628059108604e-05, batch_size=32,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
[I 2025-05-08 12:40:31,113] Trial 35 finished with value: 0.42720458982165893 and parameters: {'ff_dim': 64, 'dropout_rate': 0.1865825339605951, 'embed_dim': 64, 'learning_rate': 3.7977014594923156e-05, 'weight_decay': 4.6742011225964905e-06, 'batch_size': 32, 'num_heads': 2, 'num_transformer_blocks': 1}. Best is trial 19 with value: 0.4606266643484158.
Trial 35, Fold 5: Test Accuracy = 0.3903
Trial 35: Mean Accuracy = 0.4272, Fold Accuracies = [np.float64(0.4592352092352092), np.float64(0.3675258945386064), np.float64(0.5195350241545894), np.float64(0.39944546194546193), np.float64(0.39028135923442786)]
Hyperparameters: num_heads=16, num_transformer_blocks=32, learning_rate=0.00027980489622887614, optimizer=Adam, weight_decay=2.1422660616215064e-06, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 37, Fold 1: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 37, Fold 2: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
Trial 38, Fold 1: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 37, Fold 3: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 38, Fold 2: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 37, Fold 4: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 38, Fold 3: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 38, Fold 4: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
[I 2025-05-08 12:45:41,190] Trial 37 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 64, 'dropout_rate': 0.25009767420471357, 'embed_dim': 64, 'learning_rate': 0.0023371113628463777, 'weight_decay': 4.5656628059108604e-05, 'batch_size': 32, 'num_heads': 2, 'num_transformer_blocks': 32}. Best is trial 19 with value: 0.4606266643484158.
Trial 37, Fold 5: Test Accuracy = 0.3333
Trial 37: Mean Accuracy = 0.3333, Fold Accuracies = [np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333)]
Hyperparameters: num_heads=16, num_transformer_blocks=8, learning_rate=0.0002475597119632828, optimizer=Adam, weight_decay=0.0009928109064919971, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
[I 2025-05-08 12:47:00,937] Trial 38 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 512, 'dropout_rate': 0.2662487692069257, 'embed_dim': 64, 'learning_rate': 0.00027980489622887614, 'weight_decay': 2.1422660616215064e-06, 'batch_size': 16, 'num_heads': 16, 'num_transformer_blocks': 32}. Best is trial 19 with value: 0.4606266643484158.
Trial 38, Fold 5: Test Accuracy = 0.3333
Trial 38: Mean Accuracy = 0.3333, Fold Accuracies = [np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333)]
Hyperparameters: num_heads=1, num_transformer_blocks=8, learning_rate=0.001941447147135279, optimizer=Adam, weight_decay=8.903068987090388e-06, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 39, Fold 1: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 40, Fold 1: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 39, Fold 2: Test Accuracy = 0.4190
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 40, Fold 2: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 39, Fold 3: Test Accuracy = 0.4290
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 40, Fold 3: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 39, Fold 4: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Trial 40, Fold 4: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
[I 2025-05-08 12:51:44,891] Trial 39 finished with value: 0.37418810826963567 and parameters: {'ff_dim': 512, 'dropout_rate': 0.2677655190794849, 'embed_dim': 512, 'learning_rate': 0.0002475597119632828, 'weight_decay': 0.0009928109064919971, 'batch_size': 16, 'num_heads': 16, 'num_transformer_blocks': 8}. Best is trial 19 with value: 0.4606266643484158.
Trial 39, Fold 5: Test Accuracy = 0.3563
Trial 39: Mean Accuracy = 0.3742, Fold Accuracies = [np.float64(0.3333333333333333), np.float64(0.4189618644067797), np.float64(0.4290458937198067), np.float64(0.3333333333333333), np.float64(0.3562661165549252)]
Hyperparameters: num_heads=1, num_transformer_blocks=16, learning_rate=0.0016384082851439573, optimizer=Adam, weight_decay=8.024613953747288e-06, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
[I 2025-05-08 12:52:48,559] Trial 40 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 256, 'dropout_rate': 0.2853293208645794, 'embed_dim': 512, 'learning_rate': 0.001941447147135279, 'weight_decay': 8.903068987090388e-06, 'batch_size': 10, 'num_heads': 1, 'num_transformer_blocks': 8}. Best is trial 19 with value: 0.4606266643484158.
Trial 40, Fold 5: Test Accuracy = 0.3333
Trial 40: Mean Accuracy = 0.3333, Fold Accuracies = [np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333)]
Hyperparameters: num_heads=4, num_transformer_blocks=2, learning_rate=0.04490907035112959, optimizer=Adam, weight_decay=5.60365872255683e-06, batch_size=32,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 41, Fold 1: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
Trial 42, Fold 1: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 41, Fold 2: Test Accuracy = 0.3333
Trial 42, Fold 2: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
Trial 41, Fold 3: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Trial 42, Fold 3: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 41, Fold 4: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 42, Fold 4: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
[I 2025-05-08 12:59:33,926] Trial 41 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 256, 'dropout_rate': 0.2889969166426939, 'embed_dim': 256, 'learning_rate': 0.0016384082851439573, 'weight_decay': 8.024613953747288e-06, 'batch_size': 10, 'num_heads': 1, 'num_transformer_blocks': 16}. Best is trial 19 with value: 0.4606266643484158.
Trial 41, Fold 5: Test Accuracy = 0.3333
Trial 41: Mean Accuracy = 0.3333, Fold Accuracies = [np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333)]
Hyperparameters: num_heads=4, num_transformer_blocks=2, learning_rate=0.028045856343328034, optimizer=Adam, weight_decay=1.9121272395809968e-05, batch_size=32,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
Trial 42, Fold 5: Test Accuracy = 0.3333
Trial 42: Mean Accuracy = 0.3333, Fold Accuracies = [np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333)]
[I 2025-05-08 12:59:54,799] Trial 42 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 128, 'dropout_rate': 0.2341990288902064, 'embed_dim': 512, 'learning_rate': 0.04490907035112959, 'weight_decay': 5.60365872255683e-06, 'batch_size': 32, 'num_heads': 4, 'num_transformer_blocks': 2}. Best is trial 19 with value: 0.4606266643484158.
Hyperparameters: num_heads=4, num_transformer_blocks=2, learning_rate=1.0481819500110948e-06, optimizer=Adam, weight_decay=3.40406019076036e-06, batch_size=32,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Trial 43, Fold 1: Test Accuracy = 0.3333
Trial 44, Fold 1: Test Accuracy = 0.4057
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Trial 43, Fold 2: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 43, Fold 3: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
Trial 44, Fold 2: Test Accuracy = 0.3855
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 43, Fold 4: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 44, Fold 3: Test Accuracy = 0.4903
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
[I 2025-05-08 13:04:36,371] Trial 43 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 128, 'dropout_rate': 0.1033086174086726, 'embed_dim': 512, 'learning_rate': 0.028045856343328034, 'weight_decay': 1.9121272395809968e-05, 'batch_size': 32, 'num_heads': 4, 'num_transformer_blocks': 2}. Best is trial 19 with value: 0.4606266643484158.
Trial 43, Fold 5: Test Accuracy = 0.3333
Trial 43: Mean Accuracy = 0.3333, Fold Accuracies = [np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333)]
Hyperparameters: num_heads=4, num_transformer_blocks=2, learning_rate=9.521251683335189e-07, optimizer=Adam, weight_decay=3.45868335779032e-06, batch_size=32,factor=1
Trial 44, Fold 4: Test Accuracy = 0.4017
Trial 45, Fold 1: Test Accuracy = 0.4393
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 45, Fold 2: Test Accuracy = 0.3849
[I 2025-05-08 13:08:15,002] Trial 44 finished with value: 0.4070802660541542 and parameters: {'ff_dim': 128, 'dropout_rate': 0.252962377599145, 'embed_dim': 512, 'learning_rate': 1.0481819500110948e-06, 'weight_decay': 3.40406019076036e-06, 'batch_size': 32, 'num_heads': 4, 'num_transformer_blocks': 2}. Best is trial 19 with value: 0.4606266643484158.
Trial 44, Fold 5: Test Accuracy = 0.3522
Trial 44: Mean Accuracy = 0.4071, Fold Accuracies = [np.float64(0.40566378066378067), np.float64(0.38552129106507643), np.float64(0.4903079710144927), np.float64(0.4016839641839642), np.float64(0.35222432334345694)]
Hyperparameters: num_heads=8, num_transformer_blocks=2, learning_rate=0.004183645642871351, optimizer=Adam, weight_decay=1.354897702863525e-06, batch_size=32,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 46, Fold 1: Test Accuracy = 0.4228
Trial 45, Fold 3: Test Accuracy = 0.4425
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 46, Fold 2: Test Accuracy = 0.3852
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 46, Fold 3: Test Accuracy = 0.4616
Trial 45, Fold 4: Test Accuracy = 0.4187
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 46, Fold 4: Test Accuracy = 0.3327
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
[I 2025-05-08 13:13:16,373] Trial 46 finished with value: 0.40671315086545706 and parameters: {'ff_dim': 32, 'dropout_rate': 0.16561667228033458, 'embed_dim': 32, 'learning_rate': 0.004183645642871351, 'weight_decay': 1.354897702863525e-06, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 2}. Best is trial 19 with value: 0.4606266643484158.
Trial 46, Fold 5: Test Accuracy = 0.4313
Trial 46: Mean Accuracy = 0.4067, Fold Accuracies = [np.float64(0.4227994227994228), np.float64(0.385161644695543), np.float64(0.4615942028985507), np.float64(0.3326846764346764), np.float64(0.43132580749909266)]
Hyperparameters: num_heads=4, num_transformer_blocks=32, learning_rate=6.1636464220558125e-06, optimizer=Adam, weight_decay=2.2073785300813678e-06, batch_size=32,factor=1
[I 2025-05-08 13:13:31,216] Trial 45 finished with value: 0.4169126847192901 and parameters: {'ff_dim': 128, 'dropout_rate': 0.2503747060376172, 'embed_dim': 512, 'learning_rate': 9.521251683335189e-07, 'weight_decay': 3.45868335779032e-06, 'batch_size': 32, 'num_heads': 4, 'num_transformer_blocks': 2}. Best is trial 19 with value: 0.4606266643484158.
Trial 45, Fold 5: Test Accuracy = 0.3991
Trial 45: Mean Accuracy = 0.4169, Fold Accuracies = [np.float64(0.43930375180375175), np.float64(0.38491316174931994), np.float64(0.442512077294686), np.float64(0.41873982498982504), np.float64(0.3990946077588677)]
Hyperparameters: num_heads=16, num_transformer_blocks=32, learning_rate=7.113663520472322e-06, optimizer=Adam, weight_decay=0.0004371568779032318, batch_size=32,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 47, Fold 1: Test Accuracy = 0.3931
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 48, Fold 1: Test Accuracy = 0.4012
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 48, Fold 2: Test Accuracy = 0.3708
Trial 47, Fold 2: Test Accuracy = 0.3625
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 48, Fold 3: Test Accuracy = 0.5075
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 48, Fold 4: Test Accuracy = 0.3729
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
Trial 47, Fold 3: Test Accuracy = 0.4982
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
[I 2025-05-08 13:18:41,981] Trial 48 finished with value: 0.4178250156706264 and parameters: {'ff_dim': 128, 'dropout_rate': 0.2078430917153968, 'embed_dim': 128, 'learning_rate': 7.113663520472322e-06, 'weight_decay': 0.0004371568779032318, 'batch_size': 32, 'num_heads': 16, 'num_transformer_blocks': 32}. Best is trial 19 with value: 0.4606266643484158.
Trial 48, Fold 5: Test Accuracy = 0.4367
Trial 48: Mean Accuracy = 0.4178, Fold Accuracies = [np.float64(0.40124458874458874), np.float64(0.3708411801632141), np.float64(0.5074879227053141), np.float64(0.37285052910052907), np.float64(0.4367008576394858)]
Hyperparameters: num_heads=4, num_transformer_blocks=1, learning_rate=0.00012953354783644096, optimizer=Adam, weight_decay=3.8832516840890815e-05, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
Trial 49, Fold 1: Test Accuracy = 0.4389
Trial 47, Fold 4: Test Accuracy = 0.3669
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Trial 49, Fold 2: Test Accuracy = 0.4249
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
[I 2025-05-08 13:21:08,223] Trial 47 finished with value: 0.3955146461981724 and parameters: {'ff_dim': 128, 'dropout_rate': 0.19755191972458702, 'embed_dim': 128, 'learning_rate': 6.1636464220558125e-06, 'weight_decay': 2.2073785300813678e-06, 'batch_size': 32, 'num_heads': 4, 'num_transformer_blocks': 32}. Best is trial 19 with value: 0.4606266643484158.
Trial 47, Fold 5: Test Accuracy = 0.3567
Trial 47: Mean Accuracy = 0.3955, Fold Accuracies = [np.float64(0.3931277056277056), np.float64(0.362543157564344), np.float64(0.4982185990338164), np.float64(0.3669363044363044), np.float64(0.3567474643286917)]
Hyperparameters: num_heads=16, num_transformer_blocks=1, learning_rate=4.338215343355629e-07, optimizer=Adam, weight_decay=1.1102678997586836e-05, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 50, Fold 1: Test Accuracy = 0.4049
Trial 49, Fold 3: Test Accuracy = 0.5466
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
Trial 50, Fold 2: Test Accuracy = 0.3738
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Trial 49, Fold 4: Test Accuracy = 0.4279
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 50, Fold 3: Test Accuracy = 0.4520
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
[I 2025-05-08 13:26:03,036] Trial 49 finished with value: 0.45238008603863056 and parameters: {'ff_dim': 512, 'dropout_rate': 0.19679150600471357, 'embed_dim': 64, 'learning_rate': 0.00012953354783644096, 'weight_decay': 3.8832516840890815e-05, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 1}. Best is trial 19 with value: 0.4606266643484158.
Trial 49, Fold 5: Test Accuracy = 0.4236
Trial 49: Mean Accuracy = 0.4524, Fold Accuracies = [np.float64(0.43885281385281383), np.float64(0.42487968194182885), np.float64(0.5466183574879228), np.float64(0.42791005291005285), np.float64(0.4236395240005348)]
Hyperparameters: num_heads=16, num_transformer_blocks=1, learning_rate=0.00010188544071899756, optimizer=Adam, weight_decay=4.852072962133658e-05, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
Trial 50, Fold 4: Test Accuracy = 0.3562
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 51, Fold 1: Test Accuracy = 0.4435
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
[I 2025-05-08 13:27:11,174] Trial 50 finished with value: 0.383897616604259 and parameters: {'ff_dim': 32, 'dropout_rate': 0.25890507873510077, 'embed_dim': 64, 'learning_rate': 4.338215343355629e-07, 'weight_decay': 1.1102678997586836e-05, 'batch_size': 10, 'num_heads': 16, 'num_transformer_blocks': 1}. Best is trial 19 with value: 0.4606266643484158.
Trial 50, Fold 5: Test Accuracy = 0.3326
Trial 50: Mean Accuracy = 0.3839, Fold Accuracies = [np.float64(0.40485209235209235), np.float64(0.3738098974680895), np.float64(0.4519927536231884), np.float64(0.3562143874643875), np.float64(0.3326189521135369)]
Hyperparameters: num_heads=4, num_transformer_blocks=1, learning_rate=0.00013382911644244726, optimizer=Adam, weight_decay=4.746142800204975e-05, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 51, Fold 2: Test Accuracy = 0.3645
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 52, Fold 1: Test Accuracy = 0.4379
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Trial 51, Fold 3: Test Accuracy = 0.4214
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
Trial 52, Fold 2: Test Accuracy = 0.3828
Trial 51, Fold 4: Test Accuracy = 0.4354
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 52, Fold 3: Test Accuracy = 0.5090
[I 2025-05-08 13:32:49,987] Trial 51 finished with value: 0.4124737010918903 and parameters: {'ff_dim': 512, 'dropout_rate': 0.1976799733408441, 'embed_dim': 64, 'learning_rate': 0.00010188544071899756, 'weight_decay': 4.852072962133658e-05, 'batch_size': 10, 'num_heads': 16, 'num_transformer_blocks': 1}. Best is trial 19 with value: 0.4606266643484158.
Trial 51, Fold 5: Test Accuracy = 0.3975
Trial 51: Mean Accuracy = 0.4125, Fold Accuracies = [np.float64(0.4435425685425685), np.float64(0.3645244821092279), np.float64(0.4213768115942029), np.float64(0.4353886853886854), np.float64(0.39753595782476653)]
Hyperparameters: num_heads=4, num_transformer_blocks=1, learning_rate=0.00018276521261747982, optimizer=Adam, weight_decay=9.627836026079373e-05, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 52, Fold 4: Test Accuracy = 0.3943
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 53, Fold 1: Test Accuracy = 0.4774
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
[I 2025-05-08 13:34:15,839] Trial 52 finished with value: 0.4224996030017647 and parameters: {'ff_dim': 512, 'dropout_rate': 0.19586510897313358, 'embed_dim': 64, 'learning_rate': 0.00013382911644244726, 'weight_decay': 4.746142800204975e-05, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 1}. Best is trial 19 with value: 0.4606266643484158.
Trial 52, Fold 5: Test Accuracy = 0.3886
Trial 52: Mean Accuracy = 0.4225, Fold Accuracies = [np.float64(0.43786075036075034), np.float64(0.38279451768152334), np.float64(0.5089975845410628), np.float64(0.394294363044363), np.float64(0.3885507993811243)]
Hyperparameters: num_heads=4, num_transformer_blocks=1, learning_rate=0.0004887263080865231, optimizer=Adam, weight_decay=9.449013634586874e-05, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 53, Fold 2: Test Accuracy = 0.4555
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 54, Fold 1: Test Accuracy = 0.4171
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 54, Fold 2: Test Accuracy = 0.3931
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 53, Fold 3: Test Accuracy = 0.5235
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 53, Fold 4: Test Accuracy = 0.3980
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
Trial 54, Fold 3: Test Accuracy = 0.5487
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
[I 2025-05-08 13:37:56,118] Trial 53 finished with value: 0.4391495502845662 and parameters: {'ff_dim': 512, 'dropout_rate': 0.17286048295059828, 'embed_dim': 64, 'learning_rate': 0.00018276521261747982, 'weight_decay': 9.627836026079373e-05, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 1}. Best is trial 19 with value: 0.4606266643484158.
Trial 53, Fold 5: Test Accuracy = 0.3414
Trial 53: Mean Accuracy = 0.4391, Fold Accuracies = [np.float64(0.4773629148629149), np.float64(0.4555084745762712), np.float64(0.5234601449275362), np.float64(0.3980336792836792), np.float64(0.3413825377724295)]
Hyperparameters: num_heads=4, num_transformer_blocks=1, learning_rate=0.00046269394870735754, optimizer=Adam, weight_decay=0.00011711458551829446, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 54, Fold 4: Test Accuracy = 0.4312
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 55, Fold 1: Test Accuracy = 0.4696
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
[I 2025-05-08 13:40:11,022] Trial 54 finished with value: 0.43475467364667697 and parameters: {'ff_dim': 512, 'dropout_rate': 0.2995123455289495, 'embed_dim': 64, 'learning_rate': 0.0004887263080865231, 'weight_decay': 9.449013634586874e-05, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 1}. Best is trial 19 with value: 0.4606266643484158.
Trial 54, Fold 5: Test Accuracy = 0.3837
Trial 54: Mean Accuracy = 0.4348, Fold Accuracies = [np.float64(0.4171176046176046), np.float64(0.3930673258003767), np.float64(0.548701690821256), np.float64(0.43122964997964996), np.float64(0.3836570970144977)]
Hyperparameters: num_heads=1, num_transformer_blocks=16, learning_rate=4.28383035735023e-05, optimizer=Adam, weight_decay=5.3969851614839286e-06, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 55, Fold 2: Test Accuracy = 0.5312
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 55, Fold 3: Test Accuracy = 0.5640
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Trial 56, Fold 1: Test Accuracy = 0.3802
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
Trial 55, Fold 4: Test Accuracy = 0.4263
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
Trial 56, Fold 2: Test Accuracy = 0.4490
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
[I 2025-05-08 13:44:48,671] Trial 55 finished with value: 0.48925222855532075 and parameters: {'ff_dim': 512, 'dropout_rate': 0.29722015100615246, 'embed_dim': 64, 'learning_rate': 0.00046269394870735754, 'weight_decay': 0.00011711458551829446, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 1}. Best is trial 55 with value: 0.48925222855532075.
Trial 55, Fold 5: Test Accuracy = 0.4551
Trial 55: Mean Accuracy = 0.4893, Fold Accuracies = [np.float64(0.46960678210678214), np.float64(0.53125), np.float64(0.5640398550724638), np.float64(0.42630748880748887), np.float64(0.4550570167898688)]
Hyperparameters: num_heads=1, num_transformer_blocks=1, learning_rate=3.9279210264763406e-05, optimizer=Adam, weight_decay=0.00014393831063619898, batch_size=10,factor=1
Trial 56, Fold 3: Test Accuracy = 0.5566
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 57, Fold 1: Test Accuracy = 0.4621
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 56, Fold 4: Test Accuracy = 0.4910
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
Trial 57, Fold 2: Test Accuracy = 0.4366
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
[I 2025-05-08 13:47:58,790] Trial 56 finished with value: 0.45333547575074773 and parameters: {'ff_dim': 64, 'dropout_rate': 0.16636797495522507, 'embed_dim': 64, 'learning_rate': 4.28383035735023e-05, 'weight_decay': 5.3969851614839286e-06, 'batch_size': 10, 'num_heads': 1, 'num_transformer_blocks': 16}. Best is trial 55 with value: 0.48925222855532075.
Trial 56, Fold 5: Test Accuracy = 0.3898
Trial 56: Mean Accuracy = 0.4533, Fold Accuracies = [np.float64(0.38023088023088025), np.float64(0.4489890667503662), np.float64(0.5565821256038648), np.float64(0.49103327228327226), np.float64(0.3898420338853552)]
Hyperparameters: num_heads=1, num_transformer_blocks=16, learning_rate=4.573879229931868e-05, optimizer=Adam, weight_decay=0.00047097988236775493, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
Trial 58, Fold 1: Test Accuracy = 0.4736
Trial 57, Fold 3: Test Accuracy = 0.5305
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 57, Fold 4: Test Accuracy = 0.3405
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 58, Fold 2: Test Accuracy = 0.4450
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
[I 2025-05-08 13:51:04,545] Trial 57 finished with value: 0.42478838903218835 and parameters: {'ff_dim': 512, 'dropout_rate': 0.28235074887034695, 'embed_dim': 64, 'learning_rate': 3.9279210264763406e-05, 'weight_decay': 0.00014393831063619898, 'batch_size': 10, 'num_heads': 1, 'num_transformer_blocks': 1}. Best is trial 55 with value: 0.48925222855532075.
Trial 57, Fold 5: Test Accuracy = 0.3542
Trial 57: Mean Accuracy = 0.4248, Fold Accuracies = [np.float64(0.4621212121212121), np.float64(0.4366172316384181), np.float64(0.5305253623188405), np.float64(0.34045584045584043), np.float64(0.35422229862663074)]
Hyperparameters: num_heads=1, num_transformer_blocks=16, learning_rate=0.0012418160059662151, optimizer=Adam, weight_decay=0.0003342901069273111, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 58, Fold 3: Test Accuracy = 0.4591
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 58, Fold 4: Test Accuracy = 0.4537
Trial 59, Fold 1: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 59, Fold 2: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
[I 2025-05-08 13:54:58,714] Trial 58 finished with value: 0.45160197791596624 and parameters: {'ff_dim': 512, 'dropout_rate': 0.15280849774218225, 'embed_dim': 64, 'learning_rate': 4.573879229931868e-05, 'weight_decay': 0.00047097988236775493, 'batch_size': 10, 'num_heads': 1, 'num_transformer_blocks': 16}. Best is trial 55 with value: 0.48925222855532075.
Trial 58, Fold 5: Test Accuracy = 0.4266
Trial 58: Mean Accuracy = 0.4516, Fold Accuracies = [np.float64(0.4735750360750361), np.float64(0.4450329566854991), np.float64(0.45911835748792273), np.float64(0.453690984940985), np.float64(0.42659255439038835)]
Hyperparameters: num_heads=1, num_transformer_blocks=16, learning_rate=0.00038505073635695106, optimizer=Adam, weight_decay=0.000518655542257784, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 59, Fold 3: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 60, Fold 1: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 59, Fold 4: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 60, Fold 2: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 60, Fold 3: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 28
[I 2025-05-08 13:59:15,591] Trial 59 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 512, 'dropout_rate': 0.15450816816994897, 'embed_dim': 64, 'learning_rate': 0.0012418160059662151, 'weight_decay': 0.0003342901069273111, 'batch_size': 10, 'num_heads': 1, 'num_transformer_blocks': 16}. Best is trial 55 with value: 0.48925222855532075.
Trial 59, Fold 5: Test Accuracy = 0.3333
Trial 59: Mean Accuracy = 0.3333, Fold Accuracies = [np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333)]
Hyperparameters: num_heads=1, num_transformer_blocks=16, learning_rate=0.0070330009051750965, optimizer=Adam, weight_decay=0.000521070012447334, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 60, Fold 4: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 61, Fold 1: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 61, Fold 2: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 29
[I 2025-05-08 14:02:01,758] Trial 60 finished with value: 0.3537898496743262 and parameters: {'ff_dim': 512, 'dropout_rate': 0.15560373533371297, 'embed_dim': 64, 'learning_rate': 0.00038505073635695106, 'weight_decay': 0.000518655542257784, 'batch_size': 10, 'num_heads': 1, 'num_transformer_blocks': 16}. Best is trial 55 with value: 0.48925222855532075.
Trial 60, Fold 5: Test Accuracy = 0.4356
Trial 60: Mean Accuracy = 0.3538, Fold Accuracies = [np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.4356159150382977)]
Hyperparameters: num_heads=1, num_transformer_blocks=16, learning_rate=6.061662622137619e-05, optimizer=Adam, weight_decay=0.0007771494074478454, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 61, Fold 3: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 62, Fold 1: Test Accuracy = 0.3710
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 61, Fold 4: Test Accuracy = 0.3333
Trial 62, Fold 2: Test Accuracy = 0.3816
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
[I 2025-05-08 14:05:57,164] Trial 61 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 512, 'dropout_rate': 0.14873955519513088, 'embed_dim': 64, 'learning_rate': 0.0070330009051750965, 'weight_decay': 0.000521070012447334, 'batch_size': 10, 'num_heads': 1, 'num_transformer_blocks': 16}. Best is trial 55 with value: 0.48925222855532075.
Trial 61, Fold 5: Test Accuracy = 0.3333
Trial 61: Mean Accuracy = 0.3333, Fold Accuracies = [np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333)]
Hyperparameters: num_heads=1, num_transformer_blocks=16, learning_rate=8.501951988723539e-05, optimizer=Adam, weight_decay=0.0008177502918345802, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 63, Fold 1: Test Accuracy = 0.5696
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 62, Fold 3: Test Accuracy = 0.5168
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 63, Fold 2: Test Accuracy = 0.3534
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 62, Fold 4: Test Accuracy = 0.4737
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 63, Fold 3: Test Accuracy = 0.4592
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
[I 2025-05-08 14:10:13,269] Trial 62 finished with value: 0.4343061012523485 and parameters: {'ff_dim': 512, 'dropout_rate': 0.1284965332871412, 'embed_dim': 64, 'learning_rate': 6.061662622137619e-05, 'weight_decay': 0.0007771494074478454, 'batch_size': 10, 'num_heads': 1, 'num_transformer_blocks': 16}. Best is trial 55 with value: 0.48925222855532075.
Trial 62, Fold 5: Test Accuracy = 0.4284
Trial 62: Mean Accuracy = 0.4343, Fold Accuracies = [np.float64(0.37103174603174605), np.float64(0.3816044151496129), np.float64(0.5168176328502415), np.float64(0.47372303622303624), np.float64(0.4283536760071056)]
Hyperparameters: num_heads=1, num_transformer_blocks=16, learning_rate=9.371129406209527e-05, optimizer=Adam, weight_decay=3.475275916031267e-05, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 63, Fold 4: Test Accuracy = 0.4388
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 64, Fold 1: Test Accuracy = 0.3672
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
[I 2025-05-08 14:12:14,830] Trial 63 finished with value: 0.44424735393685005 and parameters: {'ff_dim': 512, 'dropout_rate': 0.1254812012820954, 'embed_dim': 64, 'learning_rate': 8.501951988723539e-05, 'weight_decay': 0.0008177502918345802, 'batch_size': 10, 'num_heads': 1, 'num_transformer_blocks': 16}. Best is trial 55 with value: 0.48925222855532075.
Trial 63, Fold 5: Test Accuracy = 0.4002
Trial 63: Mean Accuracy = 0.4442, Fold Accuracies = [np.float64(0.5696248196248196), np.float64(0.3534016007532957), np.float64(0.45917874396135266), np.float64(0.4388100325600326), np.float64(0.40022157278474974)]
Hyperparameters: num_heads=1, num_transformer_blocks=16, learning_rate=3.8990965599570494e-05, optimizer=Adam, weight_decay=3.4605268389925544e-05, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 65, Fold 1: Test Accuracy = 0.4443
Trial 64, Fold 2: Test Accuracy = 0.3575
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 64, Fold 3: Test Accuracy = 0.5195
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Trial 65, Fold 2: Test Accuracy = 0.3326
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 64, Fold 4: Test Accuracy = 0.4186
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
Trial 65, Fold 3: Test Accuracy = 0.6033
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
[I 2025-05-08 14:17:41,640] Trial 64 finished with value: 0.4027664501718533 and parameters: {'ff_dim': 512, 'dropout_rate': 0.1784765682799423, 'embed_dim': 64, 'learning_rate': 9.371129406209527e-05, 'weight_decay': 3.475275916031267e-05, 'batch_size': 10, 'num_heads': 1, 'num_transformer_blocks': 16}. Best is trial 55 with value: 0.48925222855532075.
Trial 64, Fold 5: Test Accuracy = 0.3510
Trial 64: Mean Accuracy = 0.4028, Fold Accuracies = [np.float64(0.3672438672438672), np.float64(0.3575081083908767), np.float64(0.5194746376811594), np.float64(0.4185617623117623), np.float64(0.3510438752316009)]
Hyperparameters: num_heads=1, num_transformer_blocks=16, learning_rate=0.000176586941673774, optimizer=Adam, weight_decay=0.00015729580955932954, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 66, Fold 1: Test Accuracy = 0.3175
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
Trial 65, Fold 4: Test Accuracy = 0.4516
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
Trial 66, Fold 2: Test Accuracy = 0.4323
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
[I 2025-05-08 14:21:18,426] Trial 65 finished with value: 0.4381264044756758 and parameters: {'ff_dim': 64, 'dropout_rate': 0.17858366194877714, 'embed_dim': 64, 'learning_rate': 3.8990965599570494e-05, 'weight_decay': 3.4605268389925544e-05, 'batch_size': 10, 'num_heads': 1, 'num_transformer_blocks': 16}. Best is trial 55 with value: 0.48925222855532075.
Trial 65, Fold 5: Test Accuracy = 0.3589
Trial 65: Mean Accuracy = 0.4381, Fold Accuracies = [np.float64(0.4442640692640693), np.float64(0.33260750156936597), np.float64(0.6032608695652174), np.float64(0.4515669515669516), np.float64(0.35893263041277484)]
Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=0.0001676052408737554, optimizer=Adam, weight_decay=6.93902442204194e-05, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
Trial 66, Fold 3: Test Accuracy = 0.5044
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 28
Trial 67, Fold 1: Test Accuracy = 0.4434
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Trial 66, Fold 4: Test Accuracy = 0.4416
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
Trial 67, Fold 2: Test Accuracy = 0.3834
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
[I 2025-05-08 14:26:14,885] Trial 66 finished with value: 0.4219942337934818 and parameters: {'ff_dim': 64, 'dropout_rate': 0.16259431469930852, 'embed_dim': 32, 'learning_rate': 0.000176586941673774, 'weight_decay': 0.00015729580955932954, 'batch_size': 10, 'num_heads': 1, 'num_transformer_blocks': 16}. Best is trial 55 with value: 0.48925222855532075.
Trial 66, Fold 5: Test Accuracy = 0.4142
Trial 66: Mean Accuracy = 0.4220, Fold Accuracies = [np.float64(0.31746031746031744), np.float64(0.43232109227871945), np.float64(0.5043780193236715), np.float64(0.4416081603581603), np.float64(0.4142035795465399)]
Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=0.0007474488674251663, optimizer=Adam, weight_decay=6.974922904959979e-05, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
Trial 67, Fold 3: Test Accuracy = 0.4910
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 68, Fold 1: Test Accuracy = 0.3958
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Trial 67, Fold 4: Test Accuracy = 0.3695
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
Trial 68, Fold 2: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
[I 2025-05-08 14:29:43,358] Trial 67 finished with value: 0.40434314248307546 and parameters: {'ff_dim': 64, 'dropout_rate': 0.2931908365743115, 'embed_dim': 32, 'learning_rate': 0.0001676052408737554, 'weight_decay': 6.93902442204194e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 55 with value: 0.48925222855532075.
Trial 67, Fold 5: Test Accuracy = 0.3344
Trial 67: Mean Accuracy = 0.4043, Fold Accuracies = [np.float64(0.4433621933621934), np.float64(0.3834353421217829), np.float64(0.4910326086956522), np.float64(0.3695054945054945), np.float64(0.33438007373025425)]
Hyperparameters: num_heads=4, num_transformer_blocks=1, learning_rate=1.4126386201488075e-05, optimizer=Adam, weight_decay=0.0003355936584794079, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 68, Fold 3: Test Accuracy = 0.3770
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 68, Fold 4: Test Accuracy = 0.3565
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 69, Fold 1: Test Accuracy = 0.4356
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
[I 2025-05-08 14:31:59,411] Trial 68 finished with value: 0.3576607202029035 and parameters: {'ff_dim': 64, 'dropout_rate': 0.2924542171768255, 'embed_dim': 256, 'learning_rate': 0.0007474488674251663, 'weight_decay': 6.974922904959979e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 68, Fold 5: Test Accuracy = 0.3257
Trial 68: Mean Accuracy = 0.3577, Fold Accuracies = [np.float64(0.3958333333333333), np.float64(0.3333333333333333), np.float64(0.3769625603864734), np.float64(0.35648148148148145), np.float64(0.3256928924798961)]
Hyperparameters: num_heads=4, num_transformer_blocks=1, learning_rate=3.278571393001856e-05, optimizer=Adam, weight_decay=0.0003451279125156922, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 69, Fold 2: Test Accuracy = 0.5146
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
Trial 70, Fold 1: Test Accuracy = 0.4546
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 28
Trial 69, Fold 3: Test Accuracy = 0.5728
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 70, Fold 2: Test Accuracy = 0.4436
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Trial 69, Fold 4: Test Accuracy = 0.3948
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 70, Fold 3: Test Accuracy = 0.5128
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 70, Fold 4: Test Accuracy = 0.2974
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
[I 2025-05-08 14:36:59,834] Trial 69 finished with value: 0.4610863848687116 and parameters: {'ff_dim': 32, 'dropout_rate': 0.27237744081675297, 'embed_dim': 256, 'learning_rate': 1.4126386201488075e-05, 'weight_decay': 0.0003355936584794079, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 1}. Best is trial 55 with value: 0.48925222855532075.
Trial 69, Fold 5: Test Accuracy = 0.3876
Trial 69: Mean Accuracy = 0.4611, Fold Accuracies = [np.float64(0.43560606060606055), np.float64(0.5145951035781544), np.float64(0.5727657004830918), np.float64(0.39481583231583234), np.float64(0.3876492273604187)]
Hyperparameters: num_heads=4, num_transformer_blocks=1, learning_rate=2.19251224828397e-06, optimizer=Adam, weight_decay=0.000337092479935353, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
[I 2025-05-08 14:37:55,743] Trial 70 finished with value: 0.4218402419133486 and parameters: {'ff_dim': 32, 'dropout_rate': 0.1676276129874661, 'embed_dim': 64, 'learning_rate': 3.278571393001856e-05, 'weight_decay': 0.0003451279125156922, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 1}. Best is trial 55 with value: 0.48925222855532075.
Trial 70, Fold 5: Test Accuracy = 0.4008
Trial 70: Mean Accuracy = 0.4218, Fold Accuracies = [np.float64(0.4546356421356421), np.float64(0.443620527306968), np.float64(0.5127717391304348), np.float64(0.2973519536019536), np.float64(0.4008213473917445)]
Hyperparameters: num_heads=4, num_transformer_blocks=1, learning_rate=1.544368505309101e-05, optimizer=Adam, weight_decay=0.00021987395222167772, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 72, Fold 1: Test Accuracy = 0.4644
Trial 71, Fold 1: Test Accuracy = 0.4060
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 72, Fold 2: Test Accuracy = 0.3792
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 71, Fold 2: Test Accuracy = 0.4791
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 71, Fold 3: Test Accuracy = 0.4702
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
Trial 72, Fold 3: Test Accuracy = 0.5705
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 71, Fold 4: Test Accuracy = 0.4039
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 72, Fold 4: Test Accuracy = 0.4048
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
[I 2025-05-08 14:43:55,188] Trial 71 finished with value: 0.4205732826657133 and parameters: {'ff_dim': 32, 'dropout_rate': 0.27099186840120276, 'embed_dim': 256, 'learning_rate': 2.19251224828397e-06, 'weight_decay': 0.000337092479935353, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 1}. Best is trial 55 with value: 0.48925222855532075.
Trial 71, Fold 5: Test Accuracy = 0.3436
Trial 71: Mean Accuracy = 0.4206, Fold Accuracies = [np.float64(0.406024531024531), np.float64(0.4791208934923625), np.float64(0.4702294685990338), np.float64(0.4038588726088726), np.float64(0.3436326476037667)]
Hyperparameters: num_heads=4, num_transformer_blocks=1, learning_rate=5.3705354838932985e-05, optimizer=Adam, weight_decay=0.000647307249168548, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
[I 2025-05-08 14:43:59,112] Trial 72 finished with value: 0.4412841783215417 and parameters: {'ff_dim': 32, 'dropout_rate': 0.27105086940521916, 'embed_dim': 256, 'learning_rate': 1.544368505309101e-05, 'weight_decay': 0.00021987395222167772, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 1}. Best is trial 55 with value: 0.48925222855532075.
Trial 72, Fold 5: Test Accuracy = 0.3875
Trial 72: Mean Accuracy = 0.4413, Fold Accuracies = [np.float64(0.4643759018759019), np.float64(0.3791980539861896), np.float64(0.5705314009661836), np.float64(0.4048382173382173), np.float64(0.38747731744121633)]
Hyperparameters: num_heads=4, num_transformer_blocks=1, learning_rate=1.4741443324868091e-05, optimizer=Adam, weight_decay=0.0004200590703233996, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Trial 74, Fold 1: Test Accuracy = 0.4355
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
Trial 73, Fold 1: Test Accuracy = 0.4609
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 73, Fold 2: Test Accuracy = 0.4466
Trial 74, Fold 2: Test Accuracy = 0.4207
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 74, Fold 3: Test Accuracy = 0.5524
Trial 73, Fold 3: Test Accuracy = 0.5643
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 73, Fold 4: Test Accuracy = 0.4166
Trial 74, Fold 4: Test Accuracy = 0.3808
Trial 73, Fold 5: Test Accuracy = 0.3874
Trial 73: Mean Accuracy = 0.4551, Fold Accuracies = [np.float64(0.46085858585858586), np.float64(0.44655001046243986), np.float64(0.5643417874396136), np.float64(0.4165776353276353), np.float64(0.38739327259182854)]
[I 2025-05-08 14:51:52,784] Trial 73 finished with value: 0.4551442583360206 and parameters: {'ff_dim': 32, 'dropout_rate': 0.27732577436877376, 'embed_dim': 256, 'learning_rate': 5.3705354838932985e-05, 'weight_decay': 0.000647307249168548, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 1}. Best is trial 55 with value: 0.48925222855532075.
Hyperparameters: num_heads=4, num_transformer_blocks=1, learning_rate=1.1654123565737317e-05, optimizer=Adam, weight_decay=0.000663405709771569, batch_size=10,factor=1
[I 2025-05-08 14:52:28,865] Trial 74 finished with value: 0.4370981499604122 and parameters: {'ff_dim': 32, 'dropout_rate': 0.27693507686893376, 'embed_dim': 256, 'learning_rate': 1.4741443324868091e-05, 'weight_decay': 0.0004200590703233996, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 1}. Best is trial 55 with value: 0.48925222855532075.
Trial 74, Fold 5: Test Accuracy = 0.3961
Trial 74: Mean Accuracy = 0.4371, Fold Accuracies = [np.float64(0.435515873015873), np.float64(0.4207208621050429), np.float64(0.5523852657004831), np.float64(0.3807997557997558), np.float64(0.3960689931809065)]
Hyperparameters: num_heads=4, num_transformer_blocks=1, learning_rate=5.548708353223736e-05, optimizer=Adam, weight_decay=0.0006330568242229171, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 75, Fold 1: Test Accuracy = 0.4598
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 76, Fold 1: Test Accuracy = 0.4745
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 75, Fold 2: Test Accuracy = 0.5005
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 76, Fold 2: Test Accuracy = 0.3889
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 75, Fold 3: Test Accuracy = 0.5499
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Trial 75, Fold 4: Test Accuracy = 0.3577
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 28
Trial 76, Fold 3: Test Accuracy = 0.4928
[I 2025-05-08 14:58:30,058] Trial 75 finished with value: 0.45143616889913896 and parameters: {'ff_dim': 32, 'dropout_rate': 0.2763996903482324, 'embed_dim': 256, 'learning_rate': 1.1654123565737317e-05, 'weight_decay': 0.000663405709771569, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 1}. Best is trial 55 with value: 0.48925222855532075.
Trial 75, Fold 5: Test Accuracy = 0.3894
Trial 75: Mean Accuracy = 0.4514, Fold Accuracies = [np.float64(0.4597763347763348), np.float64(0.5004773488177444), np.float64(0.5498792270531401), np.float64(0.3576643264143264), np.float64(0.38938360743414896)]
Hyperparameters: num_heads=4, num_transformer_blocks=1, learning_rate=5.615716327574121e-05, optimizer=Adam, weight_decay=0.0006796215543111992, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
Trial 76, Fold 4: Test Accuracy = 0.4017
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
[I 2025-05-08 14:59:44,226] Trial 76 finished with value: 0.4303777715348141 and parameters: {'ff_dim': 32, 'dropout_rate': 0.21207250175646572, 'embed_dim': 256, 'learning_rate': 5.548708353223736e-05, 'weight_decay': 0.0006330568242229171, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 1}. Best is trial 55 with value: 0.48925222855532075.
Trial 76, Fold 5: Test Accuracy = 0.3941
Trial 76: Mean Accuracy = 0.4304, Fold Accuracies = [np.float64(0.47447691197691194), np.float64(0.3888561937643858), np.float64(0.49275362318840576), np.float64(0.40165852665852664), np.float64(0.39414360208584037)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.00029274467808069375, optimizer=Adam, weight_decay=0.0009290789691432952, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Trial 77, Fold 1: Test Accuracy = 0.4345
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 78, Fold 1: Test Accuracy = 0.4468
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 77, Fold 2: Test Accuracy = 0.4439
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 78, Fold 2: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 77, Fold 3: Test Accuracy = 0.5163
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 78, Fold 3: Test Accuracy = 0.4507
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Trial 77, Fold 4: Test Accuracy = 0.4034
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 78, Fold 4: Test Accuracy = 0.4241
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
[I 2025-05-08 15:04:47,694] Trial 77 finished with value: 0.43591138778485305 and parameters: {'ff_dim': 32, 'dropout_rate': 0.21227104833837007, 'embed_dim': 256, 'learning_rate': 5.615716327574121e-05, 'weight_decay': 0.0006796215543111992, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 1}. Best is trial 55 with value: 0.48925222855532075.
Trial 77, Fold 5: Test Accuracy = 0.3814
Trial 77: Mean Accuracy = 0.4359, Fold Accuracies = [np.float64(0.43452380952380953), np.float64(0.4439147834274953), np.float64(0.5163345410628019), np.float64(0.40338827838827834), np.float64(0.3813955265218803)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.0002780394817331274, optimizer=Adam, weight_decay=0.0009508714981834456, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 79, Fold 1: Test Accuracy = 0.4881
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
[I 2025-05-08 15:06:21,938] Trial 78 finished with value: 0.4200897194128241 and parameters: {'ff_dim': 32, 'dropout_rate': 0.2962080461034363, 'embed_dim': 256, 'learning_rate': 0.00029274467808069375, 'weight_decay': 0.0009290789691432952, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 78, Fold 5: Test Accuracy = 0.4456
Trial 78: Mean Accuracy = 0.4201, Fold Accuracies = [np.float64(0.4467893217893218), np.float64(0.3333333333333333), np.float64(0.45069444444444445), np.float64(0.4240562678062678), np.float64(0.4455752296907532)]
Hyperparameters: num_heads=4, num_transformer_blocks=1, learning_rate=2.963144704040382e-05, optimizer=Adam, weight_decay=0.00011728499031175209, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 79, Fold 2: Test Accuracy = 0.4790
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 80, Fold 1: Test Accuracy = 0.4515
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
Trial 79, Fold 3: Test Accuracy = 0.5229
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 80, Fold 2: Test Accuracy = 0.4225
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 80, Fold 3: Test Accuracy = 0.5332
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 29
Trial 79, Fold 4: Test Accuracy = 0.4399
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 80, Fold 4: Test Accuracy = 0.3363
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
[I 2025-05-08 15:12:21,453] Trial 79 finished with value: 0.4615764060634543 and parameters: {'ff_dim': 64, 'dropout_rate': 0.2873304469992138, 'embed_dim': 256, 'learning_rate': 0.0002780394817331274, 'weight_decay': 0.0009508714981834456, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 79, Fold 5: Test Accuracy = 0.3779
Trial 79: Mean Accuracy = 0.4616, Fold Accuracies = [np.float64(0.48809523809523814), np.float64(0.47901626909395273), np.float64(0.5228864734299516), np.float64(0.43994200244200243), np.float64(0.37794204725612673)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.0004783440282759618, optimizer=Adam, weight_decay=0.0008620928561893915, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
[I 2025-05-08 15:13:08,191] Trial 80 finished with value: 0.42797771969806797 and parameters: {'ff_dim': 64, 'dropout_rate': 0.2636341609899642, 'embed_dim': 64, 'learning_rate': 2.963144704040382e-05, 'weight_decay': 0.00011728499031175209, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 1}. Best is trial 55 with value: 0.48925222855532075.
Trial 80, Fold 5: Test Accuracy = 0.3964
Trial 80: Mean Accuracy = 0.4280, Fold Accuracies = [np.float64(0.45147907647907654), np.float64(0.42247332077840555), np.float64(0.5332125603864735), np.float64(0.3362840862840863), np.float64(0.3964395545622983)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.00042654798659541343, optimizer=Adam, weight_decay=0.00026201805279901184, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 81, Fold 1: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 81, Fold 2: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 82, Fold 1: Test Accuracy = 0.3661
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 82, Fold 2: Test Accuracy = 0.3333
Trial 81, Fold 3: Test Accuracy = 0.5839
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 82, Fold 3: Test Accuracy = 0.5158
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 81, Fold 4: Test Accuracy = 0.4397
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
[I 2025-05-08 15:18:12,218] Trial 81 finished with value: 0.4147503773425921 and parameters: {'ff_dim': 64, 'dropout_rate': 0.28758570436471764, 'embed_dim': 256, 'learning_rate': 0.0004783440282759618, 'weight_decay': 0.0008620928561893915, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 81, Fold 5: Test Accuracy = 0.3835
Trial 81: Mean Accuracy = 0.4148, Fold Accuracies = [np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.5838768115942029), np.float64(0.43973850223850225), np.float64(0.3834699062135885)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.000993691235453486, optimizer=Adam, weight_decay=0.0005400911174679524, batch_size=10,factor=1
Trial 82, Fold 4: Test Accuracy = 0.4452
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
[I 2025-05-08 15:19:14,935] Trial 82 finished with value: 0.40754828658003206 and parameters: {'ff_dim': 64, 'dropout_rate': 0.28336926628650566, 'embed_dim': 256, 'learning_rate': 0.00042654798659541343, 'weight_decay': 0.00026201805279901184, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 82, Fold 5: Test Accuracy = 0.3773
Trial 82: Mean Accuracy = 0.4075, Fold Accuracies = [np.float64(0.36607142857142855), np.float64(0.3333333333333333), np.float64(0.5158212560386474), np.float64(0.4452457264957265), np.float64(0.3772696884610242)]
Hyperparameters: num_heads=16, num_transformer_blocks=4, learning_rate=8.06049826832049e-05, optimizer=Adam, weight_decay=0.0004785866084870555, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 83, Fold 1: Test Accuracy = 0.3264
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 83, Fold 2: Test Accuracy = 0.3457
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 28
Trial 84, Fold 1: Test Accuracy = 0.4609
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 83, Fold 3: Test Accuracy = 0.4656
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
Trial 84, Fold 2: Test Accuracy = 0.4221
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
Trial 83, Fold 4: Test Accuracy = 0.3133
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
[I 2025-05-08 15:24:24,049] Trial 83 finished with value: 0.3644653179616948 and parameters: {'ff_dim': 64, 'dropout_rate': 0.28112939410028004, 'embed_dim': 256, 'learning_rate': 0.000993691235453486, 'weight_decay': 0.0005400911174679524, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 83, Fold 5: Test Accuracy = 0.3714
Trial 83: Mean Accuracy = 0.3645, Fold Accuracies = [np.float64(0.3263888888888889), np.float64(0.34567901234567905), np.float64(0.46557971014492755), np.float64(0.313250407000407), np.float64(0.37142857142857144)]
Hyperparameters: num_heads=16, num_transformer_blocks=8, learning_rate=0.00024841692780917953, optimizer=Adam, weight_decay=0.0004526743963297269, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 84, Fold 3: Test Accuracy = 0.5574
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 85, Fold 1: Test Accuracy = 0.5029
Trial 84, Fold 4: Test Accuracy = 0.3972
Trial 85, Fold 2: Test Accuracy = 0.4410
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
[I 2025-05-08 15:27:36,280] Trial 84 finished with value: 0.44924720974137494 and parameters: {'ff_dim': 64, 'dropout_rate': 0.1825125153346089, 'embed_dim': 256, 'learning_rate': 8.06049826832049e-05, 'weight_decay': 0.0004785866084870555, 'batch_size': 10, 'num_heads': 16, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 84, Fold 5: Test Accuracy = 0.4086
Trial 84: Mean Accuracy = 0.4492, Fold Accuracies = [np.float64(0.46085858585858586), np.float64(0.42213983050847453), np.float64(0.557427536231884), np.float64(0.3972069597069597), np.float64(0.40860313640097035)]
Hyperparameters: num_heads=2, num_transformer_blocks=8, learning_rate=0.00012328328006223918, optimizer=Adam, weight_decay=1.8690527100347672e-05, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 86, Fold 1: Test Accuracy = 0.3956
Trial 85, Fold 3: Test Accuracy = 0.5216
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 86, Fold 2: Test Accuracy = 0.4395
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 85, Fold 4: Test Accuracy = 0.3958
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 28
Trial 86, Fold 3: Test Accuracy = 0.5658
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
[I 2025-05-08 15:32:44,031] Trial 85 finished with value: 0.45596461452881165 and parameters: {'ff_dim': 64, 'dropout_rate': 0.2903040624274201, 'embed_dim': 64, 'learning_rate': 0.00024841692780917953, 'weight_decay': 0.0004526743963297269, 'batch_size': 10, 'num_heads': 16, 'num_transformer_blocks': 8}. Best is trial 55 with value: 0.48925222855532075.
Trial 85, Fold 5: Test Accuracy = 0.4185
Trial 85: Mean Accuracy = 0.4560, Fold Accuracies = [np.float64(0.5028860028860028), np.float64(0.44097222222222227), np.float64(0.5215881642512078), np.float64(0.3958333333333333), np.float64(0.4185433499512922)]
Hyperparameters: num_heads=16, num_transformer_blocks=8, learning_rate=0.00025689333314821936, optimizer=Adam, weight_decay=2.1565111796885745e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 86, Fold 4: Test Accuracy = 0.4647
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 87, Fold 1: Test Accuracy = 0.4019
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
[I 2025-05-08 15:34:22,144] Trial 86 finished with value: 0.4589411717411561 and parameters: {'ff_dim': 256, 'dropout_rate': 0.19190779410242212, 'embed_dim': 64, 'learning_rate': 0.00012328328006223918, 'weight_decay': 1.8690527100347672e-05, 'batch_size': 10, 'num_heads': 2, 'num_transformer_blocks': 8}. Best is trial 55 with value: 0.48925222855532075.
Trial 86, Fold 5: Test Accuracy = 0.4291
Trial 86: Mean Accuracy = 0.4589, Fold Accuracies = [np.float64(0.3955627705627705), np.float64(0.4395467147938899), np.float64(0.5657910628019324), np.float64(0.4647181522181522), np.float64(0.4290871583290356)]
Hyperparameters: num_heads=2, num_transformer_blocks=8, learning_rate=0.00030254563212874517, optimizer=Adam, weight_decay=1.7470491788354083e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 88, Fold 1: Test Accuracy = 0.3975
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
Trial 87, Fold 2: Test Accuracy = 0.3533
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Trial 88, Fold 2: Test Accuracy = 0.4233
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 87, Fold 3: Test Accuracy = 0.4686
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 87, Fold 4: Test Accuracy = 0.4092
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 88, Fold 3: Test Accuracy = 0.5447
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 88, Fold 4: Test Accuracy = 0.4206
[I 2025-05-08 15:39:44,915] Trial 87 finished with value: 0.4009474711185777 and parameters: {'ff_dim': 64, 'dropout_rate': 0.29139985168030885, 'embed_dim': 64, 'learning_rate': 0.00025689333314821936, 'weight_decay': 2.1565111796885745e-05, 'batch_size': 16, 'num_heads': 16, 'num_transformer_blocks': 8}. Best is trial 55 with value: 0.48925222855532075.
Trial 87, Fold 5: Test Accuracy = 0.3717
Trial 87: Mean Accuracy = 0.4009, Fold Accuracies = [np.float64(0.4018759018759019), np.float64(0.353329671479389), np.float64(0.46856884057971016), np.float64(0.4092134717134717), np.float64(0.37174946994441577)]
Hyperparameters: num_heads=2, num_transformer_blocks=8, learning_rate=0.0001238099564562562, optimizer=Adam, weight_decay=1.368890398588868e-05, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
[I 2025-05-08 15:39:52,643] Trial 88 finished with value: 0.43103774433353 and parameters: {'ff_dim': 256, 'dropout_rate': 0.19022290804494477, 'embed_dim': 64, 'learning_rate': 0.00030254563212874517, 'weight_decay': 1.7470491788354083e-05, 'batch_size': 16, 'num_heads': 2, 'num_transformer_blocks': 8}. Best is trial 55 with value: 0.48925222855532075.
Trial 88, Fold 5: Test Accuracy = 0.3691
Trial 88: Mean Accuracy = 0.4310, Fold Accuracies = [np.float64(0.3974567099567099), np.float64(0.4233430110901863), np.float64(0.5446557971014493), np.float64(0.42059676434676435), np.float64(0.36913643917254024)]
Hyperparameters: num_heads=2, num_transformer_blocks=8, learning_rate=0.0006026941637358495, optimizer=Adam, weight_decay=0.00019312677730476082, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 89, Fold 1: Test Accuracy = 0.4859
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 90, Fold 1: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
Trial 89, Fold 2: Test Accuracy = 0.4025
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
Trial 90, Fold 2: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 90, Fold 3: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 90, Fold 4: Test Accuracy = 0.3333
Trial 89, Fold 3: Test Accuracy = 0.5371
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
[I 2025-05-08 15:45:48,056] Trial 90 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 256, 'dropout_rate': 0.19208535541114985, 'embed_dim': 128, 'learning_rate': 0.0006026941637358495, 'weight_decay': 0.00019312677730476082, 'batch_size': 10, 'num_heads': 2, 'num_transformer_blocks': 8}. Best is trial 55 with value: 0.48925222855532075.
Trial 90, Fold 5: Test Accuracy = 0.3333
Trial 90: Mean Accuracy = 0.3333, Fold Accuracies = [np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333)]
Hyperparameters: num_heads=2, num_transformer_blocks=8, learning_rate=0.00012008652986456692, optimizer=Adam, weight_decay=1.4417140225538201e-05, batch_size=10,factor=1
Trial 89, Fold 4: Test Accuracy = 0.4549
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 91, Fold 1: Test Accuracy = 0.3911
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
[I 2025-05-08 15:47:34,421] Trial 89 finished with value: 0.4563045302359557 and parameters: {'ff_dim': 256, 'dropout_rate': 0.19362310844513722, 'embed_dim': 128, 'learning_rate': 0.0001238099564562562, 'weight_decay': 1.368890398588868e-05, 'batch_size': 10, 'num_heads': 2, 'num_transformer_blocks': 8}. Best is trial 55 with value: 0.48925222855532075.
Trial 89, Fold 5: Test Accuracy = 0.4011
Trial 89: Mean Accuracy = 0.4563, Fold Accuracies = [np.float64(0.48593073593073594), np.float64(0.4024900606821511), np.float64(0.5371074879227052), np.float64(0.4549247049247049), np.float64(0.40106966171948116)]
Hyperparameters: num_heads=2, num_transformer_blocks=8, learning_rate=0.00011833585465114953, optimizer=Adam, weight_decay=1.384051137092256e-05, batch_size=10,factor=1
Trial 91, Fold 2: Test Accuracy = 0.3089
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 92, Fold 1: Test Accuracy = 0.4802
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 92, Fold 2: Test Accuracy = 0.3854
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 91, Fold 3: Test Accuracy = 0.5171
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 91, Fold 4: Test Accuracy = 0.5037
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 92, Fold 3: Test Accuracy = 0.5194
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
[I 2025-05-08 15:52:27,549] Trial 91 finished with value: 0.41691265153184975 and parameters: {'ff_dim': 256, 'dropout_rate': 0.2030357009844615, 'embed_dim': 64, 'learning_rate': 0.00012008652986456692, 'weight_decay': 1.4417140225538201e-05, 'batch_size': 10, 'num_heads': 2, 'num_transformer_blocks': 8}. Best is trial 55 with value: 0.48925222855532075.
Trial 91, Fold 5: Test Accuracy = 0.3638
Trial 91: Mean Accuracy = 0.4169, Fold Accuracies = [np.float64(0.39105339105339104), np.float64(0.30891661435446743), np.float64(0.5171497584541063), np.float64(0.5036630036630036), np.float64(0.3637804901342807)]
Hyperparameters: num_heads=2, num_transformer_blocks=8, learning_rate=0.00022654482448925675, optimizer=Adam, weight_decay=1.2262653714070537e-05, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 92, Fold 4: Test Accuracy = 0.5147
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 93, Fold 1: Test Accuracy = 0.3730
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 93, Fold 2: Test Accuracy = 0.4474
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
[I 2025-05-08 15:54:35,612] Trial 92 finished with value: 0.4758831039901937 and parameters: {'ff_dim': 256, 'dropout_rate': 0.2051768973953511, 'embed_dim': 128, 'learning_rate': 0.00011833585465114953, 'weight_decay': 1.384051137092256e-05, 'batch_size': 10, 'num_heads': 2, 'num_transformer_blocks': 8}. Best is trial 55 with value: 0.48925222855532075.
Trial 92, Fold 5: Test Accuracy = 0.4798
Trial 92: Mean Accuracy = 0.4759, Fold Accuracies = [np.float64(0.4801587301587302), np.float64(0.38538397154216364), np.float64(0.5194444444444445), np.float64(0.5146774521774522), np.float64(0.4797509216281779)]
Hyperparameters: num_heads=2, num_transformer_blocks=8, learning_rate=0.0002189094344364017, optimizer=Adam, weight_decay=9.139016670248568e-06, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 93, Fold 3: Test Accuracy = 0.5638
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 94, Fold 1: Test Accuracy = 0.4028
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Trial 93, Fold 4: Test Accuracy = 0.4758
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Trial 94, Fold 2: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 94, Fold 3: Test Accuracy = 0.4487
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
[I 2025-05-08 15:58:05,553] Trial 93 finished with value: 0.45307233176855705 and parameters: {'ff_dim': 256, 'dropout_rate': 0.18321143568794607, 'embed_dim': 128, 'learning_rate': 0.00022654482448925675, 'weight_decay': 1.2262653714070537e-05, 'batch_size': 10, 'num_heads': 2, 'num_transformer_blocks': 8}. Best is trial 55 with value: 0.48925222855532075.
Trial 93, Fold 5: Test Accuracy = 0.4053
Trial 93: Mean Accuracy = 0.4531, Fold Accuracies = [np.float64(0.373015873015873), np.float64(0.4473804666248169), np.float64(0.5638285024154589), np.float64(0.47583435083435077), np.float64(0.4053024659522855)]
Hyperparameters: num_heads=2, num_transformer_blocks=8, learning_rate=2.2461155848298734e-05, optimizer=Adam, weight_decay=8.796826050927009e-06, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 94, Fold 4: Test Accuracy = 0.4146
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 28
Trial 95, Fold 1: Test Accuracy = 0.4203
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
[I 2025-05-08 16:00:10,654] Trial 94 finished with value: 0.394519777610148 and parameters: {'ff_dim': 256, 'dropout_rate': 0.1828388133386773, 'embed_dim': 128, 'learning_rate': 0.0002189094344364017, 'weight_decay': 9.139016670248568e-06, 'batch_size': 10, 'num_heads': 2, 'num_transformer_blocks': 8}. Best is trial 55 with value: 0.48925222855532075.
Trial 94, Fold 5: Test Accuracy = 0.3732
Trial 94: Mean Accuracy = 0.3945, Fold Accuracies = [np.float64(0.40277777777777773), np.float64(0.3333333333333333), np.float64(0.448671497584541), np.float64(0.41461894586894593), np.float64(0.3731973334861421)]
Hyperparameters: num_heads=2, num_transformer_blocks=8, learning_rate=2.3467684115339e-05, optimizer=Adam, weight_decay=6.6894315174781795e-06, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 96, Fold 1: Test Accuracy = 0.4470
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Trial 95, Fold 2: Test Accuracy = 0.4764
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 96, Fold 2: Test Accuracy = 0.3667
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Trial 95, Fold 3: Test Accuracy = 0.5570
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Trial 95, Fold 4: Test Accuracy = 0.4085
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
Trial 96, Fold 3: Test Accuracy = 0.5095
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
[I 2025-05-08 16:05:25,175] Trial 95 finished with value: 0.45190340520848 and parameters: {'ff_dim': 256, 'dropout_rate': 0.29593087728433143, 'embed_dim': 128, 'learning_rate': 2.2461155848298734e-05, 'weight_decay': 8.796826050927009e-06, 'batch_size': 10, 'num_heads': 2, 'num_transformer_blocks': 8}. Best is trial 55 with value: 0.48925222855532075.
Trial 95, Fold 5: Test Accuracy = 0.3973
Trial 95: Mean Accuracy = 0.4519, Fold Accuracies = [np.float64(0.4202741702741703), np.float64(0.4764398932831136), np.float64(0.5569746376811594), np.float64(0.40851393976393974), np.float64(0.39731438504001687)]
Hyperparameters: num_heads=2, num_transformer_blocks=8, learning_rate=0.0013673534025815098, optimizer=Adam, weight_decay=1.6493425863263188e-05, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
Trial 96, Fold 4: Test Accuracy = 0.4107
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 97, Fold 1: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 97, Fold 2: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
[I 2025-05-08 16:07:18,180] Trial 96 finished with value: 0.4274516602030509 and parameters: {'ff_dim': 256, 'dropout_rate': 0.2947833447715138, 'embed_dim': 128, 'learning_rate': 2.3467684115339e-05, 'weight_decay': 6.6894315174781795e-06, 'batch_size': 10, 'num_heads': 2, 'num_transformer_blocks': 8}. Best is trial 55 with value: 0.48925222855532075.
Trial 96, Fold 5: Test Accuracy = 0.4034
Trial 96: Mean Accuracy = 0.4275, Fold Accuracies = [np.float64(0.44696969696969696), np.float64(0.3667019774011299), np.float64(0.5095410628019325), np.float64(0.4106761294261294), np.float64(0.4033694344163658)]
Hyperparameters: num_heads=2, num_transformer_blocks=8, learning_rate=8.035504440263517e-05, optimizer=Adam, weight_decay=2.7465741144959778e-05, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 98, Fold 1: Test Accuracy = 0.4315
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Trial 97, Fold 3: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 97, Fold 4: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 29
Trial 98, Fold 2: Test Accuracy = 0.3928
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
[I 2025-05-08 16:10:38,372] Trial 97 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 256, 'dropout_rate': 0.22397915906308677, 'embed_dim': 128, 'learning_rate': 0.0013673534025815098, 'weight_decay': 1.6493425863263188e-05, 'batch_size': 10, 'num_heads': 2, 'num_transformer_blocks': 8}. Best is trial 55 with value: 0.48925222855532075.
Trial 97, Fold 5: Test Accuracy = 0.3333
Trial 97: Mean Accuracy = 0.3333, Fold Accuracies = [np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333)]
Hyperparameters: num_heads=2, num_transformer_blocks=8, learning_rate=8.101569752424904e-05, optimizer=Adam, weight_decay=2.3243848704438986e-05, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 98, Fold 3: Test Accuracy = 0.5549
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 99, Fold 1: Test Accuracy = 0.4437
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 98, Fold 4: Test Accuracy = 0.4531
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
[I 2025-05-08 16:13:30,242] Trial 98 finished with value: 0.43674808498913154 and parameters: {'ff_dim': 256, 'dropout_rate': 0.2872050938573869, 'embed_dim': 128, 'learning_rate': 8.035504440263517e-05, 'weight_decay': 2.7465741144959778e-05, 'batch_size': 10, 'num_heads': 2, 'num_transformer_blocks': 8}. Best is trial 55 with value: 0.48925222855532075.
Trial 98, Fold 5: Test Accuracy = 0.3515
Trial 98: Mean Accuracy = 0.4367, Fold Accuracies = [np.float64(0.4314574314574315), np.float64(0.3927926867545512), np.float64(0.554921497584541), np.float64(0.45305504680504677), np.float64(0.3515137623440872)]
Hyperparameters: num_heads=2, num_transformer_blocks=8, learning_rate=0.0001579998164136124, optimizer=Adam, weight_decay=5.6633782909547154e-05, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 99, Fold 2: Test Accuracy = 0.4371
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Trial 99, Fold 3: Test Accuracy = 0.5679
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 100, Fold 1: Test Accuracy = 0.4929
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 99, Fold 4: Test Accuracy = 0.4703
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 100, Fold 2: Test Accuracy = 0.4035
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 100, Fold 3: Test Accuracy = 0.5737
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
[I 2025-05-08 16:17:16,400] Trial 99 finished with value: 0.4637555132960802 and parameters: {'ff_dim': 256, 'dropout_rate': 0.28605041916955265, 'embed_dim': 128, 'learning_rate': 8.101569752424904e-05, 'weight_decay': 2.3243848704438986e-05, 'batch_size': 10, 'num_heads': 2, 'num_transformer_blocks': 8}. Best is trial 55 with value: 0.48925222855532075.
Trial 99, Fold 5: Test Accuracy = 0.3997
Trial 99: Mean Accuracy = 0.4638, Fold Accuracies = [np.float64(0.4437229437229437), np.float64(0.4371403536304666), np.float64(0.5679347826086957), np.float64(0.4703271265771265), np.float64(0.39965235994116854)]
Hyperparameters: num_heads=2, num_transformer_blocks=8, learning_rate=0.0008182622572631901, optimizer=Adam, weight_decay=2.1187544544790027e-05, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 101, Fold 1: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
Trial 100, Fold 4: Test Accuracy = 0.4387
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 101, Fold 2: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 101, Fold 3: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
[I 2025-05-08 16:20:57,290] Trial 100 finished with value: 0.4656181613677643 and parameters: {'ff_dim': 256, 'dropout_rate': 0.16993058107561124, 'embed_dim': 128, 'learning_rate': 0.0001579998164136124, 'weight_decay': 5.6633782909547154e-05, 'batch_size': 10, 'num_heads': 2, 'num_transformer_blocks': 8}. Best is trial 55 with value: 0.48925222855532075.
Trial 100, Fold 5: Test Accuracy = 0.4193
Trial 100: Mean Accuracy = 0.4656, Fold Accuracies = [np.float64(0.49287518037518036), np.float64(0.4035428436911488), np.float64(0.5737016908212561), np.float64(0.4387210012210012), np.float64(0.41925009073023506)]
Hyperparameters: num_heads=2, num_transformer_blocks=8, learning_rate=0.00014510374363090053, optimizer=Adam, weight_decay=2.247075119535685e-05, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 101, Fold 4: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 102, Fold 1: Test Accuracy = 0.4477
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
[I 2025-05-08 16:22:25,111] Trial 101 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 256, 'dropout_rate': 0.2731012100844244, 'embed_dim': 128, 'learning_rate': 0.0008182622572631901, 'weight_decay': 2.1187544544790027e-05, 'batch_size': 10, 'num_heads': 2, 'num_transformer_blocks': 8}. Best is trial 55 with value: 0.48925222855532075.
Trial 101, Fold 5: Test Accuracy = 0.3333
Trial 101: Mean Accuracy = 0.3333, Fold Accuracies = [np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333)]
Hyperparameters: num_heads=2, num_transformer_blocks=8, learning_rate=0.00014883281526507182, optimizer=Adam, weight_decay=6.12660792090052e-05, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 102, Fold 2: Test Accuracy = 0.4155
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 103, Fold 1: Test Accuracy = 0.3389
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 103, Fold 2: Test Accuracy = 0.3611
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
Trial 102, Fold 3: Test Accuracy = 0.4851
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 103, Fold 3: Test Accuracy = 0.5812
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 102, Fold 4: Test Accuracy = 0.4735
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 103, Fold 4: Test Accuracy = 0.4783
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
[I 2025-05-08 16:26:37,401] Trial 102 finished with value: 0.43244258413437675 and parameters: {'ff_dim': 256, 'dropout_rate': 0.2992993722164671, 'embed_dim': 128, 'learning_rate': 0.00014510374363090053, 'weight_decay': 2.247075119535685e-05, 'batch_size': 10, 'num_heads': 2, 'num_transformer_blocks': 8}. Best is trial 55 with value: 0.48925222855532075.
Trial 102, Fold 5: Test Accuracy = 0.3404
Trial 102: Mean Accuracy = 0.4324, Fold Accuracies = [np.float64(0.4476911976911977), np.float64(0.4154896421845575), np.float64(0.48514492753623184), np.float64(0.47353225478225475), np.float64(0.3403548984776421)]
Hyperparameters: num_heads=2, num_transformer_blocks=8, learning_rate=0.00033380595878625195, optimizer=Adam, weight_decay=6.0493520402156194e-05, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
[I 2025-05-08 16:28:07,632] Trial 103 finished with value: 0.4313004863501253 and parameters: {'ff_dim': 256, 'dropout_rate': 0.29960403224544285, 'embed_dim': 128, 'learning_rate': 0.00014883281526507182, 'weight_decay': 6.12660792090052e-05, 'batch_size': 10, 'num_heads': 2, 'num_transformer_blocks': 8}. Best is trial 55 with value: 0.48925222855532075.
Trial 103, Fold 5: Test Accuracy = 0.3969
Trial 103: Mean Accuracy = 0.4313, Fold Accuracies = [np.float64(0.3389249639249639), np.float64(0.3611111111111111), np.float64(0.5812499999999999), np.float64(0.47827635327635326), np.float64(0.3969400034381983)]
Hyperparameters: num_heads=2, num_transformer_blocks=8, learning_rate=0.00033185241615737624, optimizer=Adam, weight_decay=0.0003957166073369673, batch_size=10,factor=1
Trial 104, Fold 1: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Trial 104, Fold 2: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 105, Fold 1: Test Accuracy = 0.4954
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 105, Fold 2: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 104, Fold 3: Test Accuracy = 0.4534
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 28
Trial 105, Fold 3: Test Accuracy = 0.5012
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
Trial 104, Fold 4: Test Accuracy = 0.5249
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 105, Fold 4: Test Accuracy = 0.4574
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
[I 2025-05-08 16:33:54,403] Trial 104 finished with value: 0.4129864577977119 and parameters: {'ff_dim': 256, 'dropout_rate': 0.2890204590870565, 'embed_dim': 128, 'learning_rate': 0.00033380595878625195, 'weight_decay': 6.0493520402156194e-05, 'batch_size': 10, 'num_heads': 2, 'num_transformer_blocks': 8}. Best is trial 55 with value: 0.48925222855532075.
Trial 104, Fold 5: Test Accuracy = 0.4199
Trial 104: Mean Accuracy = 0.4130, Fold Accuracies = [np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.45341183574879224), np.float64(0.5249160561660561), np.float64(0.41993773040704446)]
Hyperparameters: num_heads=2, num_transformer_blocks=8, learning_rate=7.11813204232043e-05, optimizer=Adam, weight_decay=3.1540153139309786e-05, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 106, Fold 1: Test Accuracy = 0.4791
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
[I 2025-05-08 16:35:42,154] Trial 105 finished with value: 0.44161454554328516 and parameters: {'ff_dim': 256, 'dropout_rate': 0.2795752351964278, 'embed_dim': 128, 'learning_rate': 0.00033185241615737624, 'weight_decay': 0.0003957166073369673, 'batch_size': 10, 'num_heads': 2, 'num_transformer_blocks': 8}. Best is trial 55 with value: 0.48925222855532075.
Trial 105, Fold 5: Test Accuracy = 0.4208
Trial 105: Mean Accuracy = 0.4416, Fold Accuracies = [np.float64(0.4954004329004329), np.float64(0.3333333333333333), np.float64(0.5011775362318841), np.float64(0.4573794261294261), np.float64(0.4207819991213493)]
Hyperparameters: num_heads=2, num_transformer_blocks=8, learning_rate=0.003035546963725532, optimizer=Adam, weight_decay=1.2781348307483953e-05, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 107, Fold 1: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 106, Fold 2: Test Accuracy = 0.4644
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 107, Fold 2: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 106, Fold 3: Test Accuracy = 0.5191
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 107, Fold 3: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 106, Fold 4: Test Accuracy = 0.4216
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 107, Fold 4: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
[I 2025-05-08 16:40:35,313] Trial 106 finished with value: 0.45029438336921396 and parameters: {'ff_dim': 256, 'dropout_rate': 0.2789018694596673, 'embed_dim': 128, 'learning_rate': 7.11813204232043e-05, 'weight_decay': 3.1540153139309786e-05, 'batch_size': 10, 'num_heads': 2, 'num_transformer_blocks': 8}. Best is trial 55 with value: 0.48925222855532075.
Trial 106, Fold 5: Test Accuracy = 0.3673
Trial 106: Mean Accuracy = 0.4503, Fold Accuracies = [np.float64(0.47907647907647904), np.float64(0.4643950094161959), np.float64(0.5190821256038647), np.float64(0.42158882783882784), np.float64(0.36732947491070234)]
Hyperparameters: num_heads=2, num_transformer_blocks=8, learning_rate=0.0001103122637544903, optimizer=Adam, weight_decay=0.00011117402497938502, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
[I 2025-05-08 16:40:52,228] Trial 107 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 256, 'dropout_rate': 0.28517401812149135, 'embed_dim': 128, 'learning_rate': 0.003035546963725532, 'weight_decay': 1.2781348307483953e-05, 'batch_size': 10, 'num_heads': 2, 'num_transformer_blocks': 8}. Best is trial 55 with value: 0.48925222855532075.
Trial 107, Fold 5: Test Accuracy = 0.3333
Trial 107: Mean Accuracy = 0.3333, Fold Accuracies = [np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333)]
Hyperparameters: num_heads=2, num_transformer_blocks=8, learning_rate=0.00017792788404976143, optimizer=Adam, weight_decay=0.0005963975819961275, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 108, Fold 1: Test Accuracy = 0.4486
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 109, Fold 1: Test Accuracy = 0.4171
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 109, Fold 2: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 108, Fold 2: Test Accuracy = 0.4259
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
Trial 109, Fold 3: Test Accuracy = 0.5055
Trial 108, Fold 3: Test Accuracy = 0.5478
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 109, Fold 4: Test Accuracy = 0.4641
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 108, Fold 4: Test Accuracy = 0.4329
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
[I 2025-05-08 16:46:30,762] Trial 109 finished with value: 0.4272119185307853 and parameters: {'ff_dim': 256, 'dropout_rate': 0.17553998813113364, 'embed_dim': 128, 'learning_rate': 0.00017792788404976143, 'weight_decay': 0.0005963975819961275, 'batch_size': 10, 'num_heads': 2, 'num_transformer_blocks': 8}. Best is trial 55 with value: 0.48925222855532075.
Trial 109, Fold 5: Test Accuracy = 0.4160
Trial 109: Mean Accuracy = 0.4272, Fold Accuracies = [np.float64(0.4171176046176046), np.float64(0.3333333333333333), np.float64(0.5054649758454106), np.float64(0.46409493284493286), np.float64(0.41604874601264497)]
Hyperparameters: num_heads=2, num_transformer_blocks=32, learning_rate=9.826037347301137e-05, optimizer=Adam, weight_decay=0.00011297605726987969, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
[I 2025-05-08 16:46:49,045] Trial 108 finished with value: 0.4473174639832683 and parameters: {'ff_dim': 256, 'dropout_rate': 0.1930412543333679, 'embed_dim': 128, 'learning_rate': 0.0001103122637544903, 'weight_decay': 0.00011117402497938502, 'batch_size': 10, 'num_heads': 2, 'num_transformer_blocks': 8}. Best is trial 55 with value: 0.48925222855532075.
Trial 108, Fold 5: Test Accuracy = 0.3814
Trial 108: Mean Accuracy = 0.4473, Fold Accuracies = [np.float64(0.4485930735930736), np.float64(0.42594554300062776), np.float64(0.5478260869565218), np.float64(0.4328576516076516), np.float64(0.38136496475846654)]
Hyperparameters: num_heads=2, num_transformer_blocks=32, learning_rate=0.0005438532511968617, optimizer=Adam, weight_decay=8.432450214154315e-05, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 111, Fold 1: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 110, Fold 1: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 110, Fold 2: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 111, Fold 2: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 111, Fold 3: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 110, Fold 3: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 110, Fold 4: Test Accuracy = 0.3333
Trial 111, Fold 4: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
[I 2025-05-08 16:54:43,517] Trial 110 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 256, 'dropout_rate': 0.2443706126606614, 'embed_dim': 256, 'learning_rate': 9.826037347301137e-05, 'weight_decay': 0.00011297605726987969, 'batch_size': 10, 'num_heads': 2, 'num_transformer_blocks': 32}. Best is trial 55 with value: 0.48925222855532075.
Trial 110, Fold 5: Test Accuracy = 0.3333
Trial 110: Mean Accuracy = 0.3333, Fold Accuracies = [np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333)]
Hyperparameters: num_heads=16, num_transformer_blocks=8, learning_rate=4.749132972161664e-05, optimizer=Adam, weight_decay=5.6384258840487565e-06, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
[I 2025-05-08 16:55:28,569] Trial 111 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 32, 'dropout_rate': 0.15941820765845963, 'embed_dim': 256, 'learning_rate': 0.0005438532511968617, 'weight_decay': 8.432450214154315e-05, 'batch_size': 10, 'num_heads': 2, 'num_transformer_blocks': 32}. Best is trial 55 with value: 0.48925222855532075.
Trial 111, Fold 5: Test Accuracy = 0.3333
Trial 111: Mean Accuracy = 0.3333, Fold Accuracies = [np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333)]
Hyperparameters: num_heads=16, num_transformer_blocks=8, learning_rate=4.489325051161354e-05, optimizer=Adam, weight_decay=1.915116252651401e-05, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 112, Fold 1: Test Accuracy = 0.4591
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 113, Fold 1: Test Accuracy = 0.5047
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
Trial 112, Fold 2: Test Accuracy = 0.3973
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
Trial 113, Fold 2: Test Accuracy = 0.3852
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
Trial 112, Fold 3: Test Accuracy = 0.5637
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 113, Fold 3: Test Accuracy = 0.5475
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 113, Fold 4: Test Accuracy = 0.3970
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 112, Fold 4: Test Accuracy = 0.4149
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
[I 2025-05-08 17:01:40,908] Trial 112 finished with value: 0.448112191037188 and parameters: {'ff_dim': 64, 'dropout_rate': 0.15819813687382286, 'embed_dim': 32, 'learning_rate': 4.749132972161664e-05, 'weight_decay': 5.6384258840487565e-06, 'batch_size': 10, 'num_heads': 16, 'num_transformer_blocks': 8}. Best is trial 55 with value: 0.48925222855532075.
Trial 112, Fold 5: Test Accuracy = 0.4055
Trial 112: Mean Accuracy = 0.4481, Fold Accuracies = [np.float64(0.4591450216450217), np.float64(0.3973373090604729), np.float64(0.5636775362318841), np.float64(0.4149496336996337), np.float64(0.40545145454892745)]
Hyperparameters: num_heads=8, num_transformer_blocks=8, learning_rate=5.1084773960116755e-06, optimizer=Adam, weight_decay=3.977843134952082e-05, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 114, Fold 1: Test Accuracy = 0.4049
[I 2025-05-08 17:02:46,748] Trial 113 finished with value: 0.44856057685196743 and parameters: {'ff_dim': 64, 'dropout_rate': 0.1681778481657884, 'embed_dim': 32, 'learning_rate': 4.489325051161354e-05, 'weight_decay': 1.915116252651401e-05, 'batch_size': 10, 'num_heads': 16, 'num_transformer_blocks': 8}. Best is trial 55 with value: 0.48925222855532075.
Trial 113, Fold 5: Test Accuracy = 0.4084
Trial 113: Mean Accuracy = 0.4486, Fold Accuracies = [np.float64(0.5046897546897547), np.float64(0.3852401129943503), np.float64(0.547463768115942), np.float64(0.39697802197802196), np.float64(0.408431226481768)]
Hyperparameters: num_heads=2, num_transformer_blocks=8, learning_rate=6.605932529946096e-05, optimizer=Adam, weight_decay=3.853360785775571e-05, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 115, Fold 1: Test Accuracy = 0.5085
Trial 114, Fold 2: Test Accuracy = 0.4211
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 115, Fold 2: Test Accuracy = 0.3760
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Trial 115, Fold 3: Test Accuracy = 0.5257
Trial 114, Fold 3: Test Accuracy = 0.5333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 115, Fold 4: Test Accuracy = 0.4271
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 114, Fold 4: Test Accuracy = 0.3647
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
[I 2025-05-08 17:08:33,684] Trial 115 finished with value: 0.44726992291288425 and parameters: {'ff_dim': 64, 'dropout_rate': 0.25972129300111807, 'embed_dim': 64, 'learning_rate': 6.605932529946096e-05, 'weight_decay': 3.853360785775571e-05, 'batch_size': 10, 'num_heads': 2, 'num_transformer_blocks': 8}. Best is trial 55 with value: 0.48925222855532075.
Trial 115, Fold 5: Test Accuracy = 0.3991
Trial 115: Mean Accuracy = 0.4473, Fold Accuracies = [np.float64(0.5084776334776334), np.float64(0.3759677756852898), np.float64(0.5256944444444445), np.float64(0.4270960520960521), np.float64(0.3991137088610013)]
Hyperparameters: num_heads=4, num_transformer_blocks=8, learning_rate=0.00019135627823829037, optimizer=Adam, weight_decay=4.543263505338354e-06, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
[I 2025-05-08 17:09:18,969] Trial 114 finished with value: 0.4290453234996005 and parameters: {'ff_dim': 64, 'dropout_rate': 0.16903099826067283, 'embed_dim': 64, 'learning_rate': 5.1084773960116755e-06, 'weight_decay': 3.977843134952082e-05, 'batch_size': 10, 'num_heads': 8, 'num_transformer_blocks': 8}. Best is trial 55 with value: 0.48925222855532075.
Trial 114, Fold 5: Test Accuracy = 0.4211
Trial 114: Mean Accuracy = 0.4290, Fold Accuracies = [np.float64(0.40494227994227994), np.float64(0.4211197426239799), np.float64(0.5333333333333333), np.float64(0.3646978021978022), np.float64(0.42113345940060737)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.00019231216726674124, optimizer=Adam, weight_decay=2.523599082423066e-05, batch_size=10,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 116, Fold 1: Test Accuracy = 0.4118
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 117, Fold 1: Test Accuracy = 0.4775
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 29
Trial 116, Fold 2: Test Accuracy = 0.3989
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 117, Fold 2: Test Accuracy = 0.4410
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 116, Fold 3: Test Accuracy = 0.5565
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Trial 117, Fold 3: Test Accuracy = 0.4654
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Trial 116, Fold 4: Test Accuracy = 0.4727
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 117, Fold 4: Test Accuracy = 0.4589
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
[I 2025-05-08 17:15:45,452] Trial 117 finished with value: 0.45521931671394344 and parameters: {'ff_dim': 32, 'dropout_rate': 0.16288658080204196, 'embed_dim': 256, 'learning_rate': 0.00019231216726674124, 'weight_decay': 2.523599082423066e-05, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 117, Fold 5: Test Accuracy = 0.4333
Trial 117: Mean Accuracy = 0.4552, Fold Accuracies = [np.float64(0.4774531024531025), np.float64(0.4410310734463277), np.float64(0.4654287439613527), np.float64(0.45886752136752135), np.float64(0.4333161423414131)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.00020921142391111628, optimizer=Adam, weight_decay=2.6024639631947746e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
[I 2025-05-08 17:16:24,605] Trial 116 finished with value: 0.44880043268209613 and parameters: {'ff_dim': 32, 'dropout_rate': 0.2676791584326428, 'embed_dim': 64, 'learning_rate': 0.00019135627823829037, 'weight_decay': 4.543263505338354e-06, 'batch_size': 10, 'num_heads': 4, 'num_transformer_blocks': 8}. Best is trial 55 with value: 0.48925222855532075.
Trial 116, Fold 5: Test Accuracy = 0.4042
Trial 116: Mean Accuracy = 0.4488, Fold Accuracies = [np.float64(0.41179653679653677), np.float64(0.3989001360117179), np.float64(0.5564613526570047), np.float64(0.4726800976800977), np.float64(0.40416404026512326)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.0003818981986106918, optimizer=Adam, weight_decay=3.157489345217692e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 118, Fold 1: Test Accuracy = 0.3651
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 119, Fold 1: Test Accuracy = 0.3464
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
Trial 118, Fold 2: Test Accuracy = 0.4868
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 119, Fold 2: Test Accuracy = 0.4303
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 118, Fold 3: Test Accuracy = 0.5607
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
Trial 119, Fold 3: Test Accuracy = 0.4667
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 118, Fold 4: Test Accuracy = 0.4772
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
[I 2025-05-08 17:21:58,438] Trial 118 finished with value: 0.4578599711249033 and parameters: {'ff_dim': 32, 'dropout_rate': 0.14445795411919, 'embed_dim': 256, 'learning_rate': 0.00020921142391111628, 'weight_decay': 2.6024639631947746e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 118, Fold 5: Test Accuracy = 0.3996
Trial 118: Mean Accuracy = 0.4579, Fold Accuracies = [np.float64(0.36507936507936506), np.float64(0.4867650136011718), np.float64(0.5607185990338164), np.float64(0.47715710215710216), np.float64(0.399579775753061)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.0004263038054798882, optimizer=Adam, weight_decay=1.5788489120874556e-05, batch_size=16,factor=1
Trial 119, Fold 4: Test Accuracy = 0.4411
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 29
Trial 120, Fold 1: Test Accuracy = 0.4545
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
[I 2025-05-08 17:24:29,327] Trial 119 finished with value: 0.4086520429397759 and parameters: {'ff_dim': 32, 'dropout_rate': 0.1722488210141193, 'embed_dim': 256, 'learning_rate': 0.0003818981986106918, 'weight_decay': 3.157489345217692e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 119, Fold 5: Test Accuracy = 0.3587
Trial 119: Mean Accuracy = 0.4087, Fold Accuracies = [np.float64(0.3464105339105339), np.float64(0.43029399455953127), np.float64(0.4666968599033816), np.float64(0.4411248473748474), np.float64(0.35873397895058545)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.00042318866086719947, optimizer=Adam, weight_decay=0.00018190504157724273, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 120, Fold 2: Test Accuracy = 0.4297
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Trial 121, Fold 1: Test Accuracy = 0.4088
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 121, Fold 2: Test Accuracy = 0.3527
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 120, Fold 3: Test Accuracy = 0.5665
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 121, Fold 3: Test Accuracy = 0.3841
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 120, Fold 4: Test Accuracy = 0.4688
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
[I 2025-05-08 17:28:46,014] Trial 120 finished with value: 0.46448212817892875 and parameters: {'ff_dim': 32, 'dropout_rate': 0.13794509019694567, 'embed_dim': 256, 'learning_rate': 0.0004263038054798882, 'weight_decay': 1.5788489120874556e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 120, Fold 5: Test Accuracy = 0.4029
Trial 120: Mean Accuracy = 0.4645, Fold Accuracies = [np.float64(0.4545454545454546), np.float64(0.4297250993931785), np.float64(0.5664855072463767), np.float64(0.46880087505087514), np.float64(0.4028537046587588)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.000232575983573029, optimizer=Adam, weight_decay=2.3267948455640763e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
Trial 121, Fold 4: Test Accuracy = 0.4717
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 122, Fold 1: Test Accuracy = 0.5035
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
[I 2025-05-08 17:30:42,240] Trial 121 finished with value: 0.4102581775319494 and parameters: {'ff_dim': 32, 'dropout_rate': 0.1426731790172658, 'embed_dim': 256, 'learning_rate': 0.00042318866086719947, 'weight_decay': 0.00018190504157724273, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 121, Fold 5: Test Accuracy = 0.4340
Trial 121: Mean Accuracy = 0.4103, Fold Accuracies = [np.float64(0.4088203463203463), np.float64(0.35274115923833443), np.float64(0.38405797101449274), np.float64(0.4717134717134717), np.float64(0.43395793937310173)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.0002464957787334111, optimizer=Adam, weight_decay=1.6739212062847114e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 122, Fold 2: Test Accuracy = 0.4115
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 123, Fold 1: Test Accuracy = 0.4648
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 122, Fold 3: Test Accuracy = 0.4784
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 122, Fold 4: Test Accuracy = 0.4411
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
Trial 123, Fold 2: Test Accuracy = 0.3438
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 123, Fold 3: Test Accuracy = 0.5349
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
[I 2025-05-08 17:35:05,391] Trial 122 finished with value: 0.45843325056384626 and parameters: {'ff_dim': 32, 'dropout_rate': 0.1407487341406242, 'embed_dim': 256, 'learning_rate': 0.000232575983573029, 'weight_decay': 2.3267948455640763e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 122, Fold 5: Test Accuracy = 0.4576
Trial 122: Mean Accuracy = 0.4584, Fold Accuracies = [np.float64(0.503517316017316), np.float64(0.4115466101694915), np.float64(0.47841183574879226), np.float64(0.4411121286121286), np.float64(0.45757836227150306)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.0006901423848235135, optimizer=Adam, weight_decay=1.5844722879492793e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 124, Fold 1: Test Accuracy = 0.3502
Trial 123, Fold 4: Test Accuracy = 0.4424
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 124, Fold 2: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
[I 2025-05-08 17:38:27,919] Trial 123 finished with value: 0.44353153629130715 and parameters: {'ff_dim': 32, 'dropout_rate': 0.130113353367044, 'embed_dim': 256, 'learning_rate': 0.0002464957787334111, 'weight_decay': 1.6739212062847114e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 123, Fold 5: Test Accuracy = 0.4318
Trial 123: Mean Accuracy = 0.4435, Fold Accuracies = [np.float64(0.4648268398268398), np.float64(0.34375), np.float64(0.5348731884057971), np.float64(0.4424348799348799), np.float64(0.4317727732890188)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.0006682444449383952, optimizer=Adam, weight_decay=1.3634161356483771e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
Trial 124, Fold 3: Test Accuracy = 0.4630
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 125, Fold 1: Test Accuracy = 0.4096
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 125, Fold 2: Test Accuracy = 0.3569
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
Trial 124, Fold 4: Test Accuracy = 0.4592
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
[I 2025-05-08 17:41:23,495] Trial 124 finished with value: 0.39703063752898937 and parameters: {'ff_dim': 32, 'dropout_rate': 0.12990708959292202, 'embed_dim': 256, 'learning_rate': 0.0006901423848235135, 'weight_decay': 1.5844722879492793e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 124, Fold 5: Test Accuracy = 0.3794
Trial 124: Mean Accuracy = 0.3970, Fold Accuracies = [np.float64(0.35019841269841273), np.float64(0.3333333333333333), np.float64(0.4630434782608695), np.float64(0.45917277167277165), np.float64(0.37940519167955983)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.0010416509822748624, optimizer=Adam, weight_decay=1.3352318579368315e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Trial 125, Fold 3: Test Accuracy = 0.5490
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 125, Fold 4: Test Accuracy = 0.3442
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
[I 2025-05-08 17:43:15,644] Trial 125 finished with value: 0.41459635480045104 and parameters: {'ff_dim': 32, 'dropout_rate': 0.13622686447579974, 'embed_dim': 256, 'learning_rate': 0.0006682444449383952, 'weight_decay': 1.3634161356483771e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 125, Fold 5: Test Accuracy = 0.4132
Trial 125: Mean Accuracy = 0.4146, Fold Accuracies = [np.float64(0.4096320346320346), np.float64(0.3569326741996233), np.float64(0.5489734299516909), np.float64(0.344233312983313), np.float64(0.413210322235593)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.00012722362827294128, optimizer=Adam, weight_decay=1.0684032324570051e-05, batch_size=16,factor=1
Trial 126, Fold 1: Test Accuracy = 0.4058
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 126, Fold 2: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 126, Fold 3: Test Accuracy = 0.3333
Trial 127, Fold 1: Test Accuracy = 0.4948
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 127, Fold 2: Test Accuracy = 0.3611
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 126, Fold 4: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
[I 2025-05-08 17:46:59,501] Trial 126 finished with value: 0.3478354978354978 and parameters: {'ff_dim': 32, 'dropout_rate': 0.14798268553961197, 'embed_dim': 256, 'learning_rate': 0.0010416509822748624, 'weight_decay': 1.3352318579368315e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 126, Fold 5: Test Accuracy = 0.3333
Trial 126: Mean Accuracy = 0.3478, Fold Accuracies = [np.float64(0.4058441558441559), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.00027867322034616786, optimizer=Adam, weight_decay=1.013501659830204e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 127, Fold 3: Test Accuracy = 0.5781
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 128, Fold 1: Test Accuracy = 0.4398
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 127, Fold 4: Test Accuracy = 0.4374
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 128, Fold 2: Test Accuracy = 0.4164
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
[I 2025-05-08 17:50:16,803] Trial 127 finished with value: 0.4333401380428927 and parameters: {'ff_dim': 32, 'dropout_rate': 0.14698355455930384, 'embed_dim': 256, 'learning_rate': 0.00012722362827294128, 'weight_decay': 1.0684032324570051e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 127, Fold 5: Test Accuracy = 0.2953
Trial 127: Mean Accuracy = 0.4333, Fold Accuracies = [np.float64(0.49476911976911975), np.float64(0.36111111111111116), np.float64(0.5780797101449275), np.float64(0.4374109686609686), np.float64(0.2953297805283365)]
Hyperparameters: num_heads=2, num_transformer_blocks=4, learning_rate=0.00026205664800667977, optimizer=Adam, weight_decay=2.380692119388364e-05, batch_size=16,factor=1
Trial 128, Fold 3: Test Accuracy = 0.4409
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 129, Fold 1: Test Accuracy = 0.4650
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 129, Fold 2: Test Accuracy = 0.3983
Trial 128, Fold 4: Test Accuracy = 0.4455
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 129, Fold 3: Test Accuracy = 0.5410
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
[I 2025-05-08 17:53:25,182] Trial 128 finished with value: 0.43155661437161097 and parameters: {'ff_dim': 256, 'dropout_rate': 0.12253219466011614, 'embed_dim': 256, 'learning_rate': 0.00027867322034616786, 'weight_decay': 1.013501659830204e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 128, Fold 5: Test Accuracy = 0.4152
Trial 128: Mean Accuracy = 0.4316, Fold Accuracies = [np.float64(0.43975468975468973), np.float64(0.416411644695543), np.float64(0.44088164251207734), np.float64(0.4455382580382581), np.float64(0.4151968368574867)]
Hyperparameters: num_heads=2, num_transformer_blocks=4, learning_rate=0.00037781017387242776, optimizer=Adam, weight_decay=1.937577268286199e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 130, Fold 1: Test Accuracy = 0.4352
Trial 129, Fold 4: Test Accuracy = 0.4190
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 130, Fold 2: Test Accuracy = 0.4707
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
[I 2025-05-08 17:55:48,576] Trial 129 finished with value: 0.43784651903317917 and parameters: {'ff_dim': 256, 'dropout_rate': 0.12275086656314146, 'embed_dim': 128, 'learning_rate': 0.00026205664800667977, 'weight_decay': 2.380692119388364e-05, 'batch_size': 16, 'num_heads': 2, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 129, Fold 5: Test Accuracy = 0.3660
Trial 129: Mean Accuracy = 0.4378, Fold Accuracies = [np.float64(0.4650072150072149), np.float64(0.3983050847457627), np.float64(0.5410024154589372), np.float64(0.41895604395604397), np.float64(0.3659618359979371)]
Hyperparameters: num_heads=2, num_transformer_blocks=2, learning_rate=0.0005174788395537326, optimizer=Adam, weight_decay=2.8347067733533366e-05, batch_size=16,factor=1
Trial 130, Fold 3: Test Accuracy = 0.5346
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
Trial 131, Fold 1: Test Accuracy = 0.4532
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 130, Fold 4: Test Accuracy = 0.3873
Trial 131, Fold 2: Test Accuracy = 0.3441
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 131, Fold 3: Test Accuracy = 0.4110
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
[I 2025-05-08 17:59:54,283] Trial 130 finished with value: 0.442419494994414 and parameters: {'ff_dim': 256, 'dropout_rate': 0.139526837249099, 'embed_dim': 128, 'learning_rate': 0.00037781017387242776, 'weight_decay': 1.937577268286199e-05, 'batch_size': 16, 'num_heads': 2, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 130, Fold 5: Test Accuracy = 0.3843
Trial 130: Mean Accuracy = 0.4424, Fold Accuracies = [np.float64(0.4351551226551227), np.float64(0.47069209039548027), np.float64(0.5346014492753622), np.float64(0.3873499185999186), np.float64(0.38429889404618645)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.00017291563573121376, optimizer=Adam, weight_decay=2.5464561923458518e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 131, Fold 4: Test Accuracy = 0.4807
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 132, Fold 1: Test Accuracy = 0.3773
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
[I 2025-05-08 18:01:23,595] Trial 131 finished with value: 0.4180145903370468 and parameters: {'ff_dim': 256, 'dropout_rate': 0.1398133514876796, 'embed_dim': 128, 'learning_rate': 0.0005174788395537326, 'weight_decay': 2.8347067733533366e-05, 'batch_size': 16, 'num_heads': 2, 'num_transformer_blocks': 2}. Best is trial 55 with value: 0.48925222855532075.
Trial 131, Fold 5: Test Accuracy = 0.4011
Trial 131: Mean Accuracy = 0.4180, Fold Accuracies = [np.float64(0.45319264069264076), np.float64(0.34407041222012974), np.float64(0.4110205314009661), np.float64(0.4806547619047619), np.float64(0.40113460546673546)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.0001906004651179784, optimizer=Adam, weight_decay=2.835881994085139e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 132, Fold 2: Test Accuracy = 0.3608
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
Trial 133, Fold 1: Test Accuracy = 0.4424
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 132, Fold 3: Test Accuracy = 0.4879
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 132, Fold 4: Test Accuracy = 0.4343
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
Trial 133, Fold 2: Test Accuracy = 0.4883
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Trial 133, Fold 3: Test Accuracy = 0.5627
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 28
[I 2025-05-08 18:06:53,337] Trial 132 finished with value: 0.40557294534798416 and parameters: {'ff_dim': 32, 'dropout_rate': 0.11520780834721664, 'embed_dim': 256, 'learning_rate': 0.00017291563573121376, 'weight_decay': 2.5464561923458518e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 132, Fold 5: Test Accuracy = 0.3676
Trial 132: Mean Accuracy = 0.4056, Fold Accuracies = [np.float64(0.37725468975468973), np.float64(0.3608037769407826), np.float64(0.4878623188405798), np.float64(0.43432030932030924), np.float64(0.3676236318835597)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.0002047565520206037, optimizer=Adam, weight_decay=5.343889083988827e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 134, Fold 1: Test Accuracy = 0.3956
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 29
Trial 133, Fold 4: Test Accuracy = 0.4691
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 134, Fold 2: Test Accuracy = 0.4242
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
[I 2025-05-08 18:09:15,153] Trial 133 finished with value: 0.46812112365368225 and parameters: {'ff_dim': 32, 'dropout_rate': 0.11078129246378766, 'embed_dim': 256, 'learning_rate': 0.0001906004651179784, 'weight_decay': 2.835881994085139e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 133, Fold 5: Test Accuracy = 0.3781
Trial 133: Mean Accuracy = 0.4681, Fold Accuracies = [np.float64(0.44237012987012986), np.float64(0.4882820673781126), np.float64(0.5626811594202898), np.float64(0.4691315628815629), np.float64(0.37814069871831607)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=9.90463245645307e-05, optimizer=Adam, weight_decay=2.009184898813317e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
Trial 134, Fold 3: Test Accuracy = 0.6064
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 29
Trial 135, Fold 1: Test Accuracy = 0.4903
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 134, Fold 4: Test Accuracy = 0.4779
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 135, Fold 2: Test Accuracy = 0.4231
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
[I 2025-05-08 18:13:31,177] Trial 134 finished with value: 0.46761449153639073 and parameters: {'ff_dim': 32, 'dropout_rate': 0.16294007305844424, 'embed_dim': 256, 'learning_rate': 0.0002047565520206037, 'weight_decay': 5.343889083988827e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 134, Fold 5: Test Accuracy = 0.4340
Trial 134: Mean Accuracy = 0.4676, Fold Accuracies = [np.float64(0.3955627705627706), np.float64(0.4241996233521657), np.float64(0.6063707729468599), np.float64(0.4779202279202279), np.float64(0.43401906289992936)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.00013727166706271318, optimizer=Adam, weight_decay=4.3761821630761484e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 28
Trial 135, Fold 3: Test Accuracy = 0.5848
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 136, Fold 1: Test Accuracy = 0.5382
Trial 135, Fold 4: Test Accuracy = 0.4822
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 136, Fold 2: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 28
[I 2025-05-08 18:17:36,848] Trial 135 finished with value: 0.47344438890971585 and parameters: {'ff_dim': 32, 'dropout_rate': 0.10685113408919525, 'embed_dim': 256, 'learning_rate': 9.90463245645307e-05, 'weight_decay': 2.009184898813317e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 135, Fold 5: Test Accuracy = 0.3868
Trial 135: Mean Accuracy = 0.4734, Fold Accuracies = [np.float64(0.49034992784992787), np.float64(0.423081450094162), np.float64(0.5847524154589372), np.float64(0.4822064509564509), np.float64(0.3868317001891009)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.00010078557417024133, optimizer=Adam, weight_decay=5.134061555223157e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
Trial 136, Fold 3: Test Accuracy = 0.5684
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 137, Fold 1: Test Accuracy = 0.4121
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 136, Fold 4: Test Accuracy = 0.4234
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 137, Fold 2: Test Accuracy = 0.4850
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
[I 2025-05-08 18:19:35,653] Trial 136 finished with value: 0.4562018103991499 and parameters: {'ff_dim': 32, 'dropout_rate': 0.10051073393185228, 'embed_dim': 256, 'learning_rate': 0.00013727166706271318, 'weight_decay': 4.3761821630761484e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 136, Fold 5: Test Accuracy = 0.4177
Trial 136: Mean Accuracy = 0.4562, Fold Accuracies = [np.float64(0.5382395382395382), np.float64(0.3333333333333333), np.float64(0.5683574879227052), np.float64(0.4233948921448922), np.float64(0.4176838003552805)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=8.968435655825341e-05, optimizer=Adam, weight_decay=5.211271702623497e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Trial 137, Fold 3: Test Accuracy = 0.5903
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Trial 138, Fold 1: Test Accuracy = 0.4717
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 137, Fold 4: Test Accuracy = 0.4878
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Trial 138, Fold 2: Test Accuracy = 0.4114
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
[I 2025-05-08 18:23:02,761] Trial 137 finished with value: 0.4659997825606245 and parameters: {'ff_dim': 32, 'dropout_rate': 0.10826577072287852, 'embed_dim': 256, 'learning_rate': 0.00010078557417024133, 'weight_decay': 5.134061555223157e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 137, Fold 5: Test Accuracy = 0.3548
Trial 137: Mean Accuracy = 0.4660, Fold Accuracies = [np.float64(0.4120670995670996), np.float64(0.48499947687800793), np.float64(0.5903381642512078), np.float64(0.48784086284086287), np.float64(0.35475330926594467)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=7.801412505249694e-05, optimizer=Adam, weight_decay=5.279922319425718e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 138, Fold 3: Test Accuracy = 0.5620
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 139, Fold 1: Test Accuracy = 0.4196
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 138, Fold 4: Test Accuracy = 0.4494
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 139, Fold 2: Test Accuracy = 0.4322
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
[I 2025-05-08 18:25:33,960] Trial 138 finished with value: 0.4587638191092336 and parameters: {'ff_dim': 32, 'dropout_rate': 0.10867604990725539, 'embed_dim': 256, 'learning_rate': 8.968435655825341e-05, 'weight_decay': 5.211271702623497e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 138, Fold 5: Test Accuracy = 0.3994
Trial 138: Mean Accuracy = 0.4588, Fold Accuracies = [np.float64(0.4716810966810967), np.float64(0.41135043942247335), np.float64(0.5620169082125605), np.float64(0.44936660561660563), np.float64(0.39940404561343196)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=8.780732625491955e-05, optimizer=Adam, weight_decay=6.0001091511354135e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 139, Fold 3: Test Accuracy = 0.5299
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 140, Fold 1: Test Accuracy = 0.4066
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
Trial 140, Fold 2: Test Accuracy = 0.3718
Trial 139, Fold 4: Test Accuracy = 0.4838
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
[I 2025-05-08 18:29:34,182] Trial 139 finished with value: 0.44437223597039727 and parameters: {'ff_dim': 32, 'dropout_rate': 0.11300303742767752, 'embed_dim': 256, 'learning_rate': 7.801412505249694e-05, 'weight_decay': 5.279922319425718e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 139, Fold 5: Test Accuracy = 0.3565
Trial 139: Mean Accuracy = 0.4444, Fold Accuracies = [np.float64(0.4195526695526695), np.float64(0.43218377275580666), np.float64(0.5298611111111111), np.float64(0.4837835775335775), np.float64(0.3564800488988214)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=9.911192476850188e-05, optimizer=Adam, weight_decay=5.498471869294269e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
Trial 140, Fold 3: Test Accuracy = 0.5846
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Trial 141, Fold 1: Test Accuracy = 0.4379
Trial 140, Fold 4: Test Accuracy = 0.4447
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 141, Fold 2: Test Accuracy = 0.3472
[I 2025-05-08 18:32:01,534] Trial 140 finished with value: 0.44336980827667904 and parameters: {'ff_dim': 32, 'dropout_rate': 0.10159724396964188, 'embed_dim': 256, 'learning_rate': 8.780732625491955e-05, 'weight_decay': 6.0001091511354135e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 140, Fold 5: Test Accuracy = 0.4091
Trial 140: Mean Accuracy = 0.4434, Fold Accuracies = [np.float64(0.4065656565656566), np.float64(0.3718416509730069), np.float64(0.5846316425120773), np.float64(0.4446606634106634), np.float64(0.4091494279219911)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.00011561907939717509, optimizer=Adam, weight_decay=5.1242981095075246e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 142, Fold 1: Test Accuracy = 0.3641
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 141, Fold 3: Test Accuracy = 0.5881
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 142, Fold 2: Test Accuracy = 0.3794
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 141, Fold 4: Test Accuracy = 0.4386
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 142, Fold 3: Test Accuracy = 0.6224
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 142, Fold 4: Test Accuracy = 0.4364
[I 2025-05-08 18:36:12,200] Trial 141 finished with value: 0.43081390328309965 and parameters: {'ff_dim': 32, 'dropout_rate': 0.10780364173896691, 'embed_dim': 256, 'learning_rate': 9.911192476850188e-05, 'weight_decay': 5.498471869294269e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 141, Fold 5: Test Accuracy = 0.3423
Trial 141: Mean Accuracy = 0.4308, Fold Accuracies = [np.float64(0.4378607503607504), np.float64(0.34722222222222215), np.float64(0.5881340579710145), np.float64(0.43856837606837606), np.float64(0.34228410979313506)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.00015500371597677146, optimizer=Adam, weight_decay=3.178515437877325e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
[I 2025-05-08 18:38:04,639] Trial 142 finished with value: 0.4543846503946405 and parameters: {'ff_dim': 32, 'dropout_rate': 0.1069097306361653, 'embed_dim': 256, 'learning_rate': 0.00011561907939717509, 'weight_decay': 5.1242981095075246e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 142, Fold 5: Test Accuracy = 0.4697
Trial 142: Mean Accuracy = 0.4544, Fold Accuracies = [np.float64(0.36408730158730157), np.float64(0.3793680686336054), np.float64(0.6223731884057971), np.float64(0.43636803011803016), np.float64(0.4697266632284683)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.00033841016885249815, optimizer=Adam, weight_decay=7.295948615763165e-05, batch_size=16,factor=1
Trial 143, Fold 1: Test Accuracy = 0.4810
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 144, Fold 1: Test Accuracy = 0.4081
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
Trial 143, Fold 2: Test Accuracy = 0.4038
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 144, Fold 2: Test Accuracy = 0.3757
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 143, Fold 3: Test Accuracy = 0.5485
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 144, Fold 3: Test Accuracy = 0.4959
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
Trial 143, Fold 4: Test Accuracy = 0.4342
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 144, Fold 4: Test Accuracy = 0.4335
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
[I 2025-05-08 18:43:33,338] Trial 143 finished with value: 0.45984006470799893 and parameters: {'ff_dim': 32, 'dropout_rate': 0.1088133948964034, 'embed_dim': 256, 'learning_rate': 0.00015500371597677146, 'weight_decay': 3.178515437877325e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 143, Fold 5: Test Accuracy = 0.4318
Trial 143: Mean Accuracy = 0.4598, Fold Accuracies = [np.float64(0.48097041847041844), np.float64(0.40383056078677554), np.float64(0.5484601449275363), np.float64(0.43415496540496545), np.float64(0.4317842339502989)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.00015478212668687514, optimizer=Adam, weight_decay=7.640743302004911e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
[I 2025-05-08 18:45:07,921] Trial 144 finished with value: 0.4404475775529697 and parameters: {'ff_dim': 32, 'dropout_rate': 0.11463700728525023, 'embed_dim': 256, 'learning_rate': 0.00033841016885249815, 'weight_decay': 7.295948615763165e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 144, Fold 5: Test Accuracy = 0.4890
Trial 144: Mean Accuracy = 0.4404, Fold Accuracies = [np.float64(0.4080988455988456), np.float64(0.37570621468926557), np.float64(0.4958937198067633), np.float64(0.4334935897435898), np.float64(0.48904551792638434)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=6.71608196869512e-05, optimizer=Adam, weight_decay=3.32207929295013e-05, batch_size=16,factor=1
Trial 145, Fold 1: Test Accuracy = 0.4444
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 146, Fold 1: Test Accuracy = 0.4970
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 145, Fold 2: Test Accuracy = 0.3917
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 146, Fold 2: Test Accuracy = 0.4480
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 146, Fold 3: Test Accuracy = 0.5766
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
Trial 145, Fold 3: Test Accuracy = 0.5026
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 146, Fold 4: Test Accuracy = 0.4679
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 145, Fold 4: Test Accuracy = 0.4702
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
[I 2025-05-08 18:50:38,307] Trial 146 finished with value: 0.47102816654979324 and parameters: {'ff_dim': 32, 'dropout_rate': 0.10582107079843503, 'embed_dim': 256, 'learning_rate': 6.71608196869512e-05, 'weight_decay': 3.32207929295013e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 146, Fold 5: Test Accuracy = 0.3656
Trial 146: Mean Accuracy = 0.4710, Fold Accuracies = [np.float64(0.49702380952380953), np.float64(0.4480343691148776), np.float64(0.5766304347826087), np.float64(0.4678724053724053), np.float64(0.36557981395526523)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=3.295721258544256e-05, optimizer=Adam, weight_decay=3.508671989205821e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
[I 2025-05-08 18:50:46,040] Trial 145 finished with value: 0.4359000399863394 and parameters: {'ff_dim': 32, 'dropout_rate': 0.1104269712688753, 'embed_dim': 256, 'learning_rate': 0.00015478212668687514, 'weight_decay': 7.640743302004911e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 145, Fold 5: Test Accuracy = 0.3707
Trial 145: Mean Accuracy = 0.4359, Fold Accuracies = [np.float64(0.44435425685425683), np.float64(0.39171374764595107), np.float64(0.502566425120773), np.float64(0.4701745014245014), np.float64(0.37069126888621473)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=6.364980476642986e-05, optimizer=Adam, weight_decay=3.516766799661881e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
Trial 148, Fold 1: Test Accuracy = 0.4537
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 28
Trial 147, Fold 1: Test Accuracy = 0.4683
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 147, Fold 2: Test Accuracy = 0.3503
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 29
Trial 148, Fold 2: Test Accuracy = 0.4151
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 147, Fold 3: Test Accuracy = 0.4728
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 148, Fold 3: Test Accuracy = 0.4176
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 29
Trial 147, Fold 4: Test Accuracy = 0.5055
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 148, Fold 4: Test Accuracy = 0.3964
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
[I 2025-05-08 18:58:11,763] Trial 147 finished with value: 0.44222860516614126 and parameters: {'ff_dim': 32, 'dropout_rate': 0.11870198003715761, 'embed_dim': 256, 'learning_rate': 3.295721258544256e-05, 'weight_decay': 3.508671989205821e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 147, Fold 5: Test Accuracy = 0.4142
Trial 147: Mean Accuracy = 0.4422, Fold Accuracies = [np.float64(0.46834415584415584), np.float64(0.3502628688010044), np.float64(0.47279589371980674), np.float64(0.5054945054945056), np.float64(0.4142456019712337)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=6.318482175400584e-05, optimizer=Adam, weight_decay=4.2115306430151496e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
[I 2025-05-08 18:58:36,447] Trial 148 finished with value: 0.4272108456940714 and parameters: {'ff_dim': 32, 'dropout_rate': 0.11827166813680696, 'embed_dim': 256, 'learning_rate': 6.364980476642986e-05, 'weight_decay': 3.516766799661881e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 148, Fold 5: Test Accuracy = 0.4533
Trial 148: Mean Accuracy = 0.4272, Fold Accuracies = [np.float64(0.4537337662337662), np.float64(0.41509730069052103), np.float64(0.4175724637681159), np.float64(0.39635480260480255), np.float64(0.45329589517315155)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.0004854545016211346, optimizer=Adam, weight_decay=2.9996324262421383e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 149, Fold 1: Test Accuracy = 0.3818
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
Trial 150, Fold 1: Test Accuracy = 0.4658
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 149, Fold 2: Test Accuracy = 0.4260
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 29
Trial 150, Fold 2: Test Accuracy = 0.4247
Trial 149, Fold 3: Test Accuracy = 0.5257
Trial 150, Fold 3: Test Accuracy = 0.3868
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
Trial 149, Fold 4: Test Accuracy = 0.4989
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 28
[I 2025-05-08 19:06:55,139] Trial 149 finished with value: 0.46333319350120633 and parameters: {'ff_dim': 32, 'dropout_rate': 0.10556731914063681, 'embed_dim': 256, 'learning_rate': 6.318482175400584e-05, 'weight_decay': 4.2115306430151496e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 149, Fold 5: Test Accuracy = 0.4844
Trial 149: Mean Accuracy = 0.4633, Fold Accuracies = [np.float64(0.3817640692640693), np.float64(0.42599785519983263), np.float64(0.5256944444444445), np.float64(0.49885531135531136), np.float64(0.4843542872423739)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.00015525256911280537, optimizer=Adam, weight_decay=3.149880823421316e-05, batch_size=16,factor=1
Trial 150, Fold 4: Test Accuracy = 0.4306
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 28
Trial 151, Fold 1: Test Accuracy = 0.4596
[I 2025-05-08 19:09:03,915] Trial 150 finished with value: 0.4133762107570466 and parameters: {'ff_dim': 32, 'dropout_rate': 0.10496002217586696, 'embed_dim': 256, 'learning_rate': 0.0004854545016211346, 'weight_decay': 2.9996324262421383e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 150, Fold 5: Test Accuracy = 0.3590
Trial 150: Mean Accuracy = 0.4134, Fold Accuracies = [np.float64(0.4658189033189033), np.float64(0.42467043314500946), np.float64(0.38680555555555557), np.float64(0.43061914936914936), np.float64(0.35896701239661527)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.00015449641056570007, optimizer=Adam, weight_decay=4.4755629208270794e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
Trial 151, Fold 2: Test Accuracy = 0.5029
Trial 152, Fold 1: Test Accuracy = 0.4398
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 152, Fold 2: Test Accuracy = 0.3935
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 151, Fold 3: Test Accuracy = 0.5402
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 152, Fold 3: Test Accuracy = 0.5697
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 151, Fold 4: Test Accuracy = 0.4651
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
[I 2025-05-08 19:14:48,301] Trial 151 finished with value: 0.48841131030459195 and parameters: {'ff_dim': 32, 'dropout_rate': 0.1069229904003147, 'embed_dim': 256, 'learning_rate': 0.00015525256911280537, 'weight_decay': 3.149880823421316e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 151, Fold 5: Test Accuracy = 0.4743
Trial 151: Mean Accuracy = 0.4884, Fold Accuracies = [np.float64(0.4595959595959596), np.float64(0.502942561205273), np.float64(0.5401570048309178), np.float64(0.4650615588115588), np.float64(0.47429946707925047)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=1.948986182715497e-06, optimizer=Adam, weight_decay=3.856525029680085e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
Trial 152, Fold 4: Test Accuracy = 0.5127
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 153, Fold 1: Test Accuracy = 0.4250
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
Trial 153, Fold 2: Test Accuracy = 0.3916
[I 2025-05-08 19:16:42,083] Trial 152 finished with value: 0.4681558309471958 and parameters: {'ff_dim': 32, 'dropout_rate': 0.10502884125073231, 'embed_dim': 256, 'learning_rate': 0.00015449641056570007, 'weight_decay': 4.4755629208270794e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 152, Fold 5: Test Accuracy = 0.4251
Trial 152: Mean Accuracy = 0.4682, Fold Accuracies = [np.float64(0.43975468975468973), np.float64(0.393544674618121), np.float64(0.5696557971014493), np.float64(0.512706043956044), np.float64(0.4251179493056749)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=7.020768921425609e-05, optimizer=Adam, weight_decay=4.322443379757115e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 153, Fold 3: Test Accuracy = 0.4488
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 154, Fold 1: Test Accuracy = 0.5010
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 154, Fold 2: Test Accuracy = 0.3779
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
Trial 153, Fold 4: Test Accuracy = 0.3336
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 154, Fold 3: Test Accuracy = 0.5707
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
[I 2025-05-08 19:20:58,065] Trial 153 finished with value: 0.40205932890109713 and parameters: {'ff_dim': 32, 'dropout_rate': 0.10457078720957821, 'embed_dim': 256, 'learning_rate': 1.948986182715497e-06, 'weight_decay': 3.856525029680085e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 153, Fold 5: Test Accuracy = 0.4114
Trial 153: Mean Accuracy = 0.4021, Fold Accuracies = [np.float64(0.424963924963925), np.float64(0.39155027202343584), np.float64(0.44876207729468603), np.float64(0.33357498982498984), np.float64(0.41144538039844897)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=6.402449743448898e-05, optimizer=Adam, weight_decay=4.612137630757636e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 154, Fold 4: Test Accuracy = 0.4151
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 155, Fold 1: Test Accuracy = 0.4623
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
[I 2025-05-08 19:22:10,999] Trial 154 finished with value: 0.4551881638516123 and parameters: {'ff_dim': 32, 'dropout_rate': 0.10331208049129875, 'embed_dim': 256, 'learning_rate': 7.020768921425609e-05, 'weight_decay': 4.322443379757115e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 154, Fold 5: Test Accuracy = 0.4113
Trial 154: Mean Accuracy = 0.4552, Fold Accuracies = [np.float64(0.5009920634920635), np.float64(0.3778837099811676), np.float64(0.5707427536231884), np.float64(0.4150641025641026), np.float64(0.4112581895975398)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.0001934803401682673, optimizer=Adam, weight_decay=4.501123320544216e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 155, Fold 2: Test Accuracy = 0.4567
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 156, Fold 1: Test Accuracy = 0.4194
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 156, Fold 2: Test Accuracy = 0.4381
Trial 155, Fold 3: Test Accuracy = 0.5730
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 155, Fold 4: Test Accuracy = 0.4484
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
Trial 156, Fold 3: Test Accuracy = 0.5314
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
[I 2025-05-08 19:26:48,309] Trial 155 finished with value: 0.4713632484261968 and parameters: {'ff_dim': 32, 'dropout_rate': 0.11199383973284731, 'embed_dim': 256, 'learning_rate': 6.402449743448898e-05, 'weight_decay': 4.612137630757636e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 155, Fold 5: Test Accuracy = 0.4164
Trial 155: Mean Accuracy = 0.4714, Fold Accuracies = [np.float64(0.46230158730158727), np.float64(0.45665280393387736), np.float64(0.5730374396135266), np.float64(0.4483745421245422), np.float64(0.41644986915745036)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=5.355407130780646e-05, optimizer=Adam, weight_decay=4.628548236826748e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Trial 157, Fold 1: Test Accuracy = 0.4524
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 29
Trial 156, Fold 4: Test Accuracy = 0.5202
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
[I 2025-05-08 19:29:57,727] Trial 156 finished with value: 0.459106582035564 and parameters: {'ff_dim': 32, 'dropout_rate': 0.11106040921254377, 'embed_dim': 256, 'learning_rate': 0.0001934803401682673, 'weight_decay': 4.501123320544216e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 156, Fold 5: Test Accuracy = 0.3864
Trial 156: Mean Accuracy = 0.4591, Fold Accuracies = [np.float64(0.41937229437229434), np.float64(0.43813428541535887), np.float64(0.5314009661835749), np.float64(0.5202482702482703), np.float64(0.38637709395832137)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=5.801616541151001e-05, optimizer=Adam, weight_decay=4.217430921474785e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 28
Trial 157, Fold 2: Test Accuracy = 0.4031
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Trial 158, Fold 1: Test Accuracy = 0.5130
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
Trial 157, Fold 3: Test Accuracy = 0.5242
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 157, Fold 4: Test Accuracy = 0.4732
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
Trial 158, Fold 2: Test Accuracy = 0.4216
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 158, Fold 3: Test Accuracy = 0.4930
[I 2025-05-08 19:35:10,731] Trial 157 finished with value: 0.45366449732548275 and parameters: {'ff_dim': 32, 'dropout_rate': 0.11390159665753458, 'embed_dim': 256, 'learning_rate': 5.355407130780646e-05, 'weight_decay': 4.628548236826748e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 157, Fold 5: Test Accuracy = 0.4155
Trial 157: Mean Accuracy = 0.4537, Fold Accuracies = [np.float64(0.4523809523809524), np.float64(0.4030654948734045), np.float64(0.5241847826086956), np.float64(0.47322700447700444), np.float64(0.415464252287357)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=3.3898729465237705e-05, optimizer=Adam, weight_decay=6.489335560701247e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
Trial 158, Fold 4: Test Accuracy = 0.4551
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 159, Fold 1: Test Accuracy = 0.5069
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
[I 2025-05-08 19:37:21,272] Trial 158 finished with value: 0.45482461025176535 and parameters: {'ff_dim': 32, 'dropout_rate': 0.11929131036038858, 'embed_dim': 256, 'learning_rate': 5.801616541151001e-05, 'weight_decay': 4.217430921474785e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 158, Fold 5: Test Accuracy = 0.3914
Trial 158: Mean Accuracy = 0.4548, Fold Accuracies = [np.float64(0.512987012987013), np.float64(0.42164286461602846), np.float64(0.4930253623188406), np.float64(0.45509004884004883), np.float64(0.3913777624968961)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=2.953847340338769e-05, optimizer=Adam, weight_decay=6.529392049754687e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
Trial 159, Fold 2: Test Accuracy = 0.4005
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 29
Trial 160, Fold 1: Test Accuracy = 0.4225
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
Trial 159, Fold 3: Test Accuracy = 0.4634
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Trial 160, Fold 2: Test Accuracy = 0.4037
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 159, Fold 4: Test Accuracy = 0.4546
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
[I 2025-05-08 19:42:47,437] Trial 159 finished with value: 0.430714968463323 and parameters: {'ff_dim': 32, 'dropout_rate': 0.12030433734415222, 'embed_dim': 256, 'learning_rate': 3.3898729465237705e-05, 'weight_decay': 6.489335560701247e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 159, Fold 5: Test Accuracy = 0.3282
Trial 159: Mean Accuracy = 0.4307, Fold Accuracies = [np.float64(0.5068542568542568), np.float64(0.4005218141870684), np.float64(0.4634057971014493), np.float64(0.45459401709401703), np.float64(0.32819895707982344)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=9.857852366372015e-06, optimizer=Adam, weight_decay=3.284385036725988e-05, batch_size=16,factor=1
Trial 160, Fold 3: Test Accuracy = 0.4171
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 161, Fold 1: Test Accuracy = 0.5223
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 160, Fold 4: Test Accuracy = 0.4677
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
[I 2025-05-08 19:45:22,659] Trial 160 finished with value: 0.4220306699998754 and parameters: {'ff_dim': 32, 'dropout_rate': 0.11641499938695983, 'embed_dim': 256, 'learning_rate': 2.953847340338769e-05, 'weight_decay': 6.529392049754687e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 160, Fold 5: Test Accuracy = 0.3991
Trial 160: Mean Accuracy = 0.4220, Fold Accuracies = [np.float64(0.42252886002886), np.float64(0.40365400711445903), np.float64(0.41714975845410623), np.float64(0.4677452177452177), np.float64(0.399075506656734)]
Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=0.00012283085592948748, optimizer=Adam, weight_decay=0.0002861396171280814, batch_size=32,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
Trial 161, Fold 2: Test Accuracy = 0.4831
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
Trial 161, Fold 3: Test Accuracy = 0.5673
Trial 162, Fold 1: Test Accuracy = 0.5106
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 162, Fold 2: Test Accuracy = 0.4469
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 161, Fold 4: Test Accuracy = 0.4389
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 162, Fold 3: Test Accuracy = 0.4097
[I 2025-05-08 19:50:16,210] Trial 161 finished with value: 0.4734690980352421 and parameters: {'ff_dim': 32, 'dropout_rate': 0.10512863514845083, 'embed_dim': 256, 'learning_rate': 9.857852366372015e-06, 'weight_decay': 3.284385036725988e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 161, Fold 5: Test Accuracy = 0.3558
Trial 161: Mean Accuracy = 0.4735, Fold Accuracies = [np.float64(0.5222763347763347), np.float64(0.48307700355722955), np.float64(0.5673007246376812), np.float64(0.4389372201872202), np.float64(0.3557542070177449)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=1.0380383459073248e-05, optimizer=Adam, weight_decay=2.997648711819375e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 162, Fold 4: Test Accuracy = 0.3886
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 163, Fold 1: Test Accuracy = 0.3902
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
[I 2025-05-08 19:51:40,507] Trial 162 finished with value: 0.43370828236772374 and parameters: {'ff_dim': 32, 'dropout_rate': 0.10078024955269355, 'embed_dim': 256, 'learning_rate': 0.00012283085592948748, 'weight_decay': 0.0002861396171280814, 'batch_size': 32, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 162, Fold 5: Test Accuracy = 0.4126
Trial 162: Mean Accuracy = 0.4337, Fold Accuracies = [np.float64(0.5106421356421357), np.float64(0.4469358129315757), np.float64(0.40972222222222227), np.float64(0.3886345136345137), np.float64(0.41260672740817145)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=9.033774604747859e-06, optimizer=Adam, weight_decay=3.501765700050517e-05, batch_size=16,factor=1
Trial 163, Fold 2: Test Accuracy = 0.4614
Trial 164, Fold 1: Test Accuracy = 0.4223
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 164, Fold 2: Test Accuracy = 0.4086
Trial 163, Fold 3: Test Accuracy = 0.4848
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 164, Fold 3: Test Accuracy = 0.5038
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 163, Fold 4: Test Accuracy = 0.4379
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
Trial 164, Fold 4: Test Accuracy = 0.4374
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
[I 2025-05-08 19:57:59,131] Trial 163 finished with value: 0.435912771012549 and parameters: {'ff_dim': 32, 'dropout_rate': 0.1009528099814952, 'embed_dim': 256, 'learning_rate': 1.0380383459073248e-05, 'weight_decay': 2.997648711819375e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 163, Fold 5: Test Accuracy = 0.4052
Trial 163: Mean Accuracy = 0.4359, Fold Accuracies = [np.float64(0.3902417027417027), np.float64(0.46138705796191676), np.float64(0.48475241545893727), np.float64(0.4379451566951567), np.float64(0.4052375222050313)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.00010292936352621429, optimizer=Adam, weight_decay=3.5576705809468366e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
[I 2025-05-08 19:58:31,048] Trial 164 finished with value: 0.4388577806492126 and parameters: {'ff_dim': 32, 'dropout_rate': 0.10537825496294509, 'embed_dim': 256, 'learning_rate': 9.033774604747859e-06, 'weight_decay': 3.501765700050517e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 164, Fold 5: Test Accuracy = 0.4221
Trial 164: Mean Accuracy = 0.4389, Fold Accuracies = [np.float64(0.42234848484848486), np.float64(0.40863020506382086), np.float64(0.5038043478260869), np.float64(0.4373982498982499), np.float64(0.4221076156094206)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=8.902018441039158e-05, optimizer=Adam, weight_decay=3.768959138070643e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 165, Fold 1: Test Accuracy = 0.4761
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 166, Fold 1: Test Accuracy = 0.4329
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 29
Trial 165, Fold 2: Test Accuracy = 0.4112
Trial 166, Fold 2: Test Accuracy = 0.4711
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
Trial 165, Fold 3: Test Accuracy = 0.5811
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Trial 165, Fold 4: Test Accuracy = 0.3916
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
Trial 166, Fold 3: Test Accuracy = 0.4915
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 166, Fold 4: Test Accuracy = 0.4863
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
[I 2025-05-08 20:05:05,434] Trial 165 finished with value: 0.43984030832794696 and parameters: {'ff_dim': 32, 'dropout_rate': 0.10599315078709044, 'embed_dim': 256, 'learning_rate': 0.00010292936352621429, 'weight_decay': 3.5576705809468366e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 165, Fold 5: Test Accuracy = 0.3393
Trial 165: Mean Accuracy = 0.4398, Fold Accuracies = [np.float64(0.4761002886002886), np.float64(0.41115426867545507), np.float64(0.5810688405797101), np.float64(0.3915852665852666), np.float64(0.3392928771990144)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=1.399679829134871e-05, optimizer=Adam, weight_decay=8.477218504157037e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 167, Fold 1: Test Accuracy = 0.4242
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
[I 2025-05-08 20:06:28,504] Trial 166 finished with value: 0.4478817459241534 and parameters: {'ff_dim': 32, 'dropout_rate': 0.11135599574257327, 'embed_dim': 256, 'learning_rate': 8.902018441039158e-05, 'weight_decay': 3.768959138070643e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 166, Fold 5: Test Accuracy = 0.3576
Trial 166: Mean Accuracy = 0.4479, Fold Accuracies = [np.float64(0.4329004329004329), np.float64(0.4711040489642184), np.float64(0.49151570048309173), np.float64(0.48628917378917386), np.float64(0.35759937348385)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=2.099742671217826e-05, optimizer=Adam, weight_decay=2.029022273730934e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 167, Fold 2: Test Accuracy = 0.4671
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 167, Fold 3: Test Accuracy = 0.5085
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
Trial 168, Fold 1: Test Accuracy = 0.4634
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 167, Fold 4: Test Accuracy = 0.3796
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
Trial 168, Fold 2: Test Accuracy = 0.4538
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
[I 2025-05-08 20:10:35,085] Trial 167 finished with value: 0.4409235239574848 and parameters: {'ff_dim': 32, 'dropout_rate': 0.10947446241090131, 'embed_dim': 256, 'learning_rate': 1.399679829134871e-05, 'weight_decay': 8.477218504157037e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 167, Fold 5: Test Accuracy = 0.4252
Trial 167: Mean Accuracy = 0.4409, Fold Accuracies = [np.float64(0.4241522366522366), np.float64(0.4671217827997489), np.float64(0.5085144927536233), np.float64(0.3796041921041921), np.float64(0.4252249154776231)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=6.40200867396579e-06, optimizer=Adam, weight_decay=2.1055331568341818e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 168, Fold 3: Test Accuracy = 0.5102
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 169, Fold 1: Test Accuracy = 0.5625
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 168, Fold 4: Test Accuracy = 0.4261
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
Trial 169, Fold 2: Test Accuracy = 0.3865
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
[I 2025-05-08 20:14:11,351] Trial 168 finished with value: 0.43904777357068675 and parameters: {'ff_dim': 32, 'dropout_rate': 0.11210687630746034, 'embed_dim': 512, 'learning_rate': 2.099742671217826e-05, 'weight_decay': 2.029022273730934e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 168, Fold 5: Test Accuracy = 0.3417
Trial 168: Mean Accuracy = 0.4390, Fold Accuracies = [np.float64(0.4633838383838384), np.float64(0.4538279451768152), np.float64(0.5101751207729468), np.float64(0.42612942612942617), np.float64(0.3417225373904074)]
Hyperparameters: num_heads=4, num_transformer_blocks=2, learning_rate=7.798516703767077e-06, optimizer=Adam, weight_decay=0.00013426837844611228, batch_size=16,factor=1
Trial 169, Fold 3: Test Accuracy = 0.4783
Trial 170, Fold 1: Test Accuracy = 0.4138
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 169, Fold 4: Test Accuracy = 0.4596
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
Trial 170, Fold 2: Test Accuracy = 0.3500
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 170, Fold 3: Test Accuracy = 0.4512
[I 2025-05-08 20:19:21,031] Trial 169 finished with value: 0.4470670974641927 and parameters: {'ff_dim': 32, 'dropout_rate': 0.12709725357024484, 'embed_dim': 256, 'learning_rate': 6.40200867396579e-06, 'weight_decay': 2.1055331568341818e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 169, Fold 5: Test Accuracy = 0.3485
Trial 169: Mean Accuracy = 0.4471, Fold Accuracies = [np.float64(0.5625), np.float64(0.3864956057752668), np.float64(0.4782910628019324), np.float64(0.4595797720797721), np.float64(0.34846904666399253)]
Hyperparameters: num_heads=4, num_transformer_blocks=2, learning_rate=0.00015539934731333648, optimizer=Adam, weight_decay=2.7155879076937393e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 170, Fold 4: Test Accuracy = 0.3643
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 171, Fold 1: Test Accuracy = 0.4210
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
[I 2025-05-08 20:21:28,024] Trial 170 finished with value: 0.3855342898003098 and parameters: {'ff_dim': 512, 'dropout_rate': 0.12574866893247358, 'embed_dim': 256, 'learning_rate': 7.798516703767077e-06, 'weight_decay': 0.00013426837844611228, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 2}. Best is trial 55 with value: 0.48925222855532075.
Trial 170, Fold 5: Test Accuracy = 0.3483
Trial 170: Mean Accuracy = 0.3855, Fold Accuracies = [np.float64(0.4137806637806638), np.float64(0.35004708097928433), np.float64(0.451237922705314), np.float64(0.364278083028083), np.float64(0.34832769850820383)]
Hyperparameters: num_heads=4, num_transformer_blocks=1, learning_rate=0.00032021546717484015, optimizer=Adam, weight_decay=5.07977405699601e-05, batch_size=32,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 171, Fold 2: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Trial 172, Fold 1: Test Accuracy = 0.4751
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 171, Fold 3: Test Accuracy = 0.4384
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Trial 172, Fold 2: Test Accuracy = 0.3046
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 171, Fold 4: Test Accuracy = 0.4477
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
Trial 172, Fold 3: Test Accuracy = 0.4792
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
[I 2025-05-08 20:25:49,560] Trial 171 finished with value: 0.407016289553764 and parameters: {'ff_dim': 512, 'dropout_rate': 0.22996573118557498, 'embed_dim': 256, 'learning_rate': 0.00015539934731333648, 'weight_decay': 2.7155879076937393e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 2}. Best is trial 55 with value: 0.48925222855532075.
Trial 171, Fold 5: Test Accuracy = 0.3946
Trial 171: Mean Accuracy = 0.4070, Fold Accuracies = [np.float64(0.42099567099567103), np.float64(0.3333333333333333), np.float64(0.43843599033816427), np.float64(0.4477258852258852), np.float64(0.3945905678757664)]
Hyperparameters: num_heads=4, num_transformer_blocks=1, learning_rate=3.95239497818799e-06, optimizer=Adam, weight_decay=4.876027292561351e-05, batch_size=32,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 172, Fold 4: Test Accuracy = 0.3443
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 173, Fold 1: Test Accuracy = 0.4097
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
[I 2025-05-08 20:27:48,069] Trial 172 finished with value: 0.399871469692382 and parameters: {'ff_dim': 128, 'dropout_rate': 0.10726309185698414, 'embed_dim': 256, 'learning_rate': 0.00032021546717484015, 'weight_decay': 5.07977405699601e-05, 'batch_size': 32, 'num_heads': 4, 'num_transformer_blocks': 1}. Best is trial 55 with value: 0.48925222855532075.
Trial 172, Fold 5: Test Accuracy = 0.3962
Trial 172: Mean Accuracy = 0.3999, Fold Accuracies = [np.float64(0.47510822510822504), np.float64(0.3046073969449676), np.float64(0.4791968599033816), np.float64(0.34428418803418803), np.float64(0.3961606784711478)]
Hyperparameters: num_heads=4, num_transformer_blocks=1, learning_rate=0.00019709021694578794, optimizer=Adam, weight_decay=1.1847995907671474e-06, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
Trial 173, Fold 2: Test Accuracy = 0.4113
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 174, Fold 1: Test Accuracy = 0.4731
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
Trial 173, Fold 3: Test Accuracy = 0.5457
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 28
Trial 174, Fold 2: Test Accuracy = 0.4331
Trial 173, Fold 4: Test Accuracy = 0.4362
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
Trial 174, Fold 3: Test Accuracy = 0.5031
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 174, Fold 4: Test Accuracy = 0.3702
[I 2025-05-08 20:33:55,420] Trial 173 finished with value: 0.4321058437077162 and parameters: {'ff_dim': 128, 'dropout_rate': 0.10445907516200907, 'embed_dim': 256, 'learning_rate': 3.95239497818799e-06, 'weight_decay': 4.876027292561351e-05, 'batch_size': 32, 'num_heads': 4, 'num_transformer_blocks': 1}. Best is trial 55 with value: 0.48925222855532075.
Trial 173, Fold 5: Test Accuracy = 0.3576
Trial 173: Mean Accuracy = 0.4321, Fold Accuracies = [np.float64(0.40972222222222215), np.float64(0.41127197112366604), np.float64(0.5457125603864734), np.float64(0.43617724867724866), np.float64(0.35764521612897066)]
Hyperparameters: num_heads=4, num_transformer_blocks=1, learning_rate=0.00023119891160679535, optimizer=Adam, weight_decay=5.608829202278783e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
[I 2025-05-08 20:34:19,347] Trial 174 finished with value: 0.4307613319760234 and parameters: {'ff_dim': 32, 'dropout_rate': 0.11444826138107943, 'embed_dim': 256, 'learning_rate': 0.00019709021694578794, 'weight_decay': 1.1847995907671474e-06, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 1}. Best is trial 55 with value: 0.48925222855532075.
Trial 174, Fold 5: Test Accuracy = 0.3743
Trial 174: Mean Accuracy = 0.4308, Fold Accuracies = [np.float64(0.47312409812409806), np.float64(0.43313847039129527), np.float64(0.5030797101449275), np.float64(0.37020502645502645), np.float64(0.3742593547647699)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.07681915966997724, optimizer=Adam, weight_decay=5.622231752378513e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Trial 176, Fold 1: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
Trial 175, Fold 1: Test Accuracy = 0.4876
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Trial 175, Fold 2: Test Accuracy = 0.3333
Trial 176, Fold 2: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 176, Fold 3: Test Accuracy = 0.3333
Trial 175, Fold 3: Test Accuracy = 0.5398
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Trial 176, Fold 4: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
Trial 175, Fold 4: Test Accuracy = 0.4543
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
[I 2025-05-08 20:40:34,307] Trial 176 finished with value: 0.3333333333333333 and parameters: {'ff_dim': 32, 'dropout_rate': 0.11010797102803759, 'embed_dim': 256, 'learning_rate': 0.07681915966997724, 'weight_decay': 5.622231752378513e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 176, Fold 5: Test Accuracy = 0.3333
Trial 176: Mean Accuracy = 0.3333, Fold Accuracies = [np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.0008411231042340159, optimizer=Adam, weight_decay=4.102429197473303e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
[I 2025-05-08 20:41:42,934] Trial 175 finished with value: 0.43348135341582206 and parameters: {'ff_dim': 32, 'dropout_rate': 0.1334972598048875, 'embed_dim': 256, 'learning_rate': 0.00023119891160679535, 'weight_decay': 5.608829202278783e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 1}. Best is trial 55 with value: 0.48925222855532075.
Trial 175, Fold 5: Test Accuracy = 0.3524
Trial 175: Mean Accuracy = 0.4335, Fold Accuracies = [np.float64(0.4876443001443002), np.float64(0.3333333333333333), np.float64(0.5397644927536231), np.float64(0.454276048026048), np.float64(0.3523885928218058)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=7.927177085290058e-05, optimizer=Adam, weight_decay=4.262416756314942e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
Trial 177, Fold 1: Test Accuracy = 0.4952
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 178, Fold 1: Test Accuracy = 0.4081
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 177, Fold 2: Test Accuracy = 0.3347
Trial 178, Fold 2: Test Accuracy = 0.4959
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
Trial 177, Fold 3: Test Accuracy = 0.5750
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 178, Fold 3: Test Accuracy = 0.5388
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
Trial 177, Fold 4: Test Accuracy = 0.4380
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 178, Fold 4: Test Accuracy = 0.3514
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
[I 2025-05-08 20:47:50,955] Trial 177 finished with value: 0.43431567683421185 and parameters: {'ff_dim': 32, 'dropout_rate': 0.1324779116091337, 'embed_dim': 32, 'learning_rate': 0.0008411231042340159, 'weight_decay': 4.102429197473303e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 177, Fold 5: Test Accuracy = 0.3287
Trial 177: Mean Accuracy = 0.4343, Fold Accuracies = [np.float64(0.49522005772005767), np.float64(0.3346934505126596), np.float64(0.5750000000000001), np.float64(0.4379960317460318), np.float64(0.3286688441923099)]
Hyperparameters: num_heads=8, num_transformer_blocks=32, learning_rate=7.427784918183151e-05, optimizer=Adam, weight_decay=3.0760332040608255e-05, batch_size=16,factor=1
[I 2025-05-08 20:48:45,629] Trial 178 finished with value: 0.42647170422399283 and parameters: {'ff_dim': 32, 'dropout_rate': 0.10262776377030045, 'embed_dim': 32, 'learning_rate': 7.927177085290058e-05, 'weight_decay': 4.262416756314942e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 178, Fold 5: Test Accuracy = 0.3382
Trial 178: Mean Accuracy = 0.4265, Fold Accuracies = [np.float64(0.4080988455988456), np.float64(0.4959392655367232), np.float64(0.538768115942029), np.float64(0.35135582010582006), np.float64(0.33819647393654617)]
Hyperparameters: num_heads=8, num_transformer_blocks=4, learning_rate=4.0598248704988556e-05, optimizer=Adam, weight_decay=3.0714739055233784e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 179, Fold 1: Test Accuracy = 0.4625
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
Trial 180, Fold 1: Test Accuracy = 0.4822
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 179, Fold 2: Test Accuracy = 0.3333
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 179, Fold 3: Test Accuracy = 0.3333
Trial 180, Fold 2: Test Accuracy = 0.4501
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 180, Fold 3: Test Accuracy = 0.4996
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 179, Fold 4: Test Accuracy = 0.4221
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
[I 2025-05-08 20:54:24,941] Trial 179 finished with value: 0.38960668960668954 and parameters: {'ff_dim': 32, 'dropout_rate': 0.1042664417940949, 'embed_dim': 256, 'learning_rate': 7.427784918183151e-05, 'weight_decay': 3.0760332040608255e-05, 'batch_size': 16, 'num_heads': 8, 'num_transformer_blocks': 32}. Best is trial 55 with value: 0.48925222855532075.
Trial 179, Fold 5: Test Accuracy = 0.3968
Trial 179: Mean Accuracy = 0.3896, Fold Accuracies = [np.float64(0.4624819624819625), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.42205942205942204), np.float64(0.3968253968253968)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.0004279585764920331, optimizer=Adam, weight_decay=2.38770316671208e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 180, Fold 4: Test Accuracy = 0.4280
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
[I 2025-05-08 20:55:42,365] Trial 180 finished with value: 0.44205859921109303 and parameters: {'ff_dim': 32, 'dropout_rate': 0.11720222469786838, 'embed_dim': 256, 'learning_rate': 4.0598248704988556e-05, 'weight_decay': 3.0714739055233784e-05, 'batch_size': 16, 'num_heads': 8, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 180, Fold 5: Test Accuracy = 0.3504
Trial 180: Mean Accuracy = 0.4421, Fold Accuracies = [np.float64(0.48223304473304474), np.float64(0.45007454488386694), np.float64(0.4996376811594203), np.float64(0.42796092796092794), np.float64(0.35038679731820527)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.00015701457915942213, optimizer=Adam, weight_decay=2.5321469842206672e-05, batch_size=16,factor=1
Trial 181, Fold 1: Test Accuracy = 0.5072
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 182, Fold 1: Test Accuracy = 0.4555
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
Trial 181, Fold 2: Test Accuracy = 0.3506
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 182, Fold 2: Test Accuracy = 0.5250
Trial 181, Fold 3: Test Accuracy = 0.4153
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 182, Fold 3: Test Accuracy = 0.5019
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
Trial 181, Fold 4: Test Accuracy = 0.5539
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Trial 182, Fold 4: Test Accuracy = 0.5043
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
[I 2025-05-08 21:02:12,009] Trial 181 finished with value: 0.4485149990172528 and parameters: {'ff_dim': 32, 'dropout_rate': 0.12157433644136678, 'embed_dim': 256, 'learning_rate': 0.0004279585764920331, 'weight_decay': 2.38770316671208e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 181, Fold 5: Test Accuracy = 0.4156
Trial 181: Mean Accuracy = 0.4485, Fold Accuracies = [np.float64(0.5072150072150072), np.float64(0.35058982004603473), np.float64(0.4152777777777778), np.float64(0.5539402726902727), np.float64(0.41555211735717146)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.00015719468453279225, optimizer=Adam, weight_decay=3.221569867297894e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
[I 2025-05-08 21:02:57,507] Trial 182 finished with value: 0.4841103677912949 and parameters: {'ff_dim': 32, 'dropout_rate': 0.10945213351235199, 'embed_dim': 256, 'learning_rate': 0.00015701457915942213, 'weight_decay': 2.5321469842206672e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 182, Fold 5: Test Accuracy = 0.4339
Trial 182: Mean Accuracy = 0.4841, Fold Accuracies = [np.float64(0.4555375180375181), np.float64(0.5249529190207157), np.float64(0.5018719806763284), np.float64(0.5042735042735043), np.float64(0.4339159169484079)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.000123323955053571, optimizer=Adam, weight_decay=2.695592191268827e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
Trial 183, Fold 1: Test Accuracy = 0.4752
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
Trial 184, Fold 1: Test Accuracy = 0.4580
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Trial 183, Fold 2: Test Accuracy = 0.4173
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 184, Fold 2: Test Accuracy = 0.3997
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 16
Trial 183, Fold 3: Test Accuracy = 0.4662
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 184, Fold 3: Test Accuracy = 0.5220
Trial 183, Fold 4: Test Accuracy = 0.4469
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
[I 2025-05-08 21:08:27,806] Trial 183 finished with value: 0.4395422801610843 and parameters: {'ff_dim': 32, 'dropout_rate': 0.10033439137123731, 'embed_dim': 256, 'learning_rate': 0.00015719468453279225, 'weight_decay': 3.221569867297894e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 183, Fold 5: Test Accuracy = 0.3921
Trial 183: Mean Accuracy = 0.4395, Fold Accuracies = [np.float64(0.47519841269841273), np.float64(0.41728787403222434), np.float64(0.466243961352657), np.float64(0.4468737281237281), np.float64(0.3921074245983993)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.00011002459269201168, optimizer=Adam, weight_decay=2.6302125189478294e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 184, Fold 4: Test Accuracy = 0.4416
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
Trial 185, Fold 1: Test Accuracy = 0.5133
[I 2025-05-08 21:10:46,279] Trial 184 finished with value: 0.43341814673173457 and parameters: {'ff_dim': 32, 'dropout_rate': 0.108159016443471, 'embed_dim': 256, 'learning_rate': 0.000123323955053571, 'weight_decay': 2.695592191268827e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 184, Fold 5: Test Accuracy = 0.3458
Trial 184: Mean Accuracy = 0.4334, Fold Accuracies = [np.float64(0.4579725829725829), np.float64(0.39971751412429374), np.float64(0.5219504830917875), np.float64(0.4416208791208791), np.float64(0.34582927434912997)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.0003190522102467303, optimizer=Adam, weight_decay=1.5656732781189393e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 185, Fold 2: Test Accuracy = 0.3624
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 186, Fold 1: Test Accuracy = 0.3674
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 185, Fold 3: Test Accuracy = 0.5373
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Trial 185, Fold 4: Test Accuracy = 0.4500
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 186, Fold 2: Test Accuracy = 0.3974
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 186, Fold 3: Test Accuracy = 0.4706
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
[I 2025-05-08 21:14:53,762] Trial 185 finished with value: 0.44934267927942917 and parameters: {'ff_dim': 32, 'dropout_rate': 0.11319260476541866, 'embed_dim': 256, 'learning_rate': 0.00011002459269201168, 'weight_decay': 2.6302125189478294e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 185, Fold 5: Test Accuracy = 0.3838
Trial 185: Mean Accuracy = 0.4493, Fold Accuracies = [np.float64(0.5132575757575757), np.float64(0.36238622096672946), np.float64(0.5372584541062801), np.float64(0.45002798127798127), np.float64(0.38378316428857945)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.0002832941989292919, optimizer=Adam, weight_decay=1.769210075766025e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 187, Fold 1: Test Accuracy = 0.4505
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 187, Fold 2: Test Accuracy = 0.3164
Trial 186, Fold 4: Test Accuracy = 0.4593
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Trial 187, Fold 3: Test Accuracy = 0.4169
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
[I 2025-05-08 21:18:26,061] Trial 186 finished with value: 0.4331092007885113 and parameters: {'ff_dim': 32, 'dropout_rate': 0.11261664592695284, 'embed_dim': 256, 'learning_rate': 0.0003190522102467303, 'weight_decay': 1.5656732781189393e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 186, Fold 5: Test Accuracy = 0.4709
Trial 186: Mean Accuracy = 0.4331, Fold Accuracies = [np.float64(0.36742424242424243), np.float64(0.3973700041849759), np.float64(0.4705917874396135), np.float64(0.4592872405372405), np.float64(0.47087272935648383)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.00024993913263369994, optimizer=Adam, weight_decay=1.8890136065405996e-05, batch_size=32,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 188, Fold 1: Test Accuracy = 0.4494
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 187, Fold 4: Test Accuracy = 0.4720
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 11
Trial 188, Fold 2: Test Accuracy = 0.3823
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
[I 2025-05-08 21:21:15,195] Trial 187 finished with value: 0.41747194048435354 and parameters: {'ff_dim': 32, 'dropout_rate': 0.17736468611357523, 'embed_dim': 256, 'learning_rate': 0.0002832941989292919, 'weight_decay': 1.769210075766025e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 187, Fold 5: Test Accuracy = 0.4315
Trial 187: Mean Accuracy = 0.4175, Fold Accuracies = [np.float64(0.45048701298701294), np.float64(0.31635802469135804), np.float64(0.41693840579710145), np.float64(0.47204415954415957), np.float64(0.4315320994021355)]
Hyperparameters: num_heads=4, num_transformer_blocks=1, learning_rate=0.0006196363462163074, optimizer=Adam, weight_decay=9.714645271681142e-05, batch_size=32,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 188, Fold 3: Test Accuracy = 0.5244
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 189, Fold 1: Test Accuracy = 0.4007
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 188, Fold 4: Test Accuracy = 0.4191
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
[I 2025-05-08 21:23:18,363] Trial 188 finished with value: 0.42337692843140706 and parameters: {'ff_dim': 32, 'dropout_rate': 0.1774330401126977, 'embed_dim': 512, 'learning_rate': 0.00024993913263369994, 'weight_decay': 1.8890136065405996e-05, 'batch_size': 32, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 188, Fold 5: Test Accuracy = 0.3416
Trial 188: Mean Accuracy = 0.4234, Fold Accuracies = [np.float64(0.44940476190476186), np.float64(0.38233024691358025), np.float64(0.5243961352657005), np.float64(0.4191341066341066), np.float64(0.34161939143888603)]
Hyperparameters: num_heads=4, num_transformer_blocks=1, learning_rate=0.0006376194274562781, optimizer=Adam, weight_decay=2.1195155017873256e-06, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
Trial 189, Fold 2: Test Accuracy = 0.3708
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 190, Fold 1: Test Accuracy = 0.4423
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 190, Fold 2: Test Accuracy = 0.4260
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
Trial 189, Fold 3: Test Accuracy = 0.4967
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Trial 189, Fold 4: Test Accuracy = 0.3483
Trial 190, Fold 3: Test Accuracy = 0.5298
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
[I 2025-05-08 21:28:08,352] Trial 189 finished with value: 0.4054205070451079 and parameters: {'ff_dim': 512, 'dropout_rate': 0.15202861401501805, 'embed_dim': 512, 'learning_rate': 0.0006196363462163074, 'weight_decay': 9.714645271681142e-05, 'batch_size': 32, 'num_heads': 4, 'num_transformer_blocks': 1}. Best is trial 55 with value: 0.48925222855532075.
Trial 189, Fold 5: Test Accuracy = 0.4106
Trial 189: Mean Accuracy = 0.4054, Fold Accuracies = [np.float64(0.4007034632034632), np.float64(0.3708477191881146), np.float64(0.4966787439613527), np.float64(0.34829059829059833), np.float64(0.4105820105820106)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.00018228413562916047, optimizer=Adam, weight_decay=2.2367204931040814e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 190, Fold 4: Test Accuracy = 0.4021
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 191, Fold 1: Test Accuracy = 0.4329
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
[I 2025-05-08 21:29:56,020] Trial 190 finished with value: 0.42764625060876754 and parameters: {'ff_dim': 64, 'dropout_rate': 0.29259197525111935, 'embed_dim': 128, 'learning_rate': 0.0006376194274562781, 'weight_decay': 2.1195155017873256e-06, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 1}. Best is trial 55 with value: 0.48925222855532075.
Trial 190, Fold 5: Test Accuracy = 0.3380
Trial 190: Mean Accuracy = 0.4276, Fold Accuracies = [np.float64(0.44227994227994233), np.float64(0.42602401129943507), np.float64(0.5298309178743962), np.float64(0.4021291208791209), np.float64(0.337967260710943)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.00015308490779730575, optimizer=Adam, weight_decay=3.4157769366788484e-05, batch_size=16,factor=1
Trial 191, Fold 2: Test Accuracy = 0.4478
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 192, Fold 1: Test Accuracy = 0.3007
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 192, Fold 2: Test Accuracy = 0.3171
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 191, Fold 3: Test Accuracy = 0.5192
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 13
Trial 191, Fold 4: Test Accuracy = 0.3992
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 25
Trial 192, Fold 3: Test Accuracy = 0.5751
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 192, Fold 4: Test Accuracy = 0.4673
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
[I 2025-05-08 21:34:56,129] Trial 191 finished with value: 0.4473071647159621 and parameters: {'ff_dim': 64, 'dropout_rate': 0.28444574385796556, 'embed_dim': 128, 'learning_rate': 0.00018228413562916047, 'weight_decay': 2.2367204931040814e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 191, Fold 5: Test Accuracy = 0.4374
Trial 191: Mean Accuracy = 0.4473, Fold Accuracies = [np.float64(0.4329004329004329), np.float64(0.44783165934295877), np.float64(0.5192330917874396), np.float64(0.3992165242165242), np.float64(0.4373541153324547)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.00014751981863025368, optimizer=Adam, weight_decay=3.7729420088854535e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 28
[I 2025-05-08 21:36:24,861] Trial 192 finished with value: 0.42281873589968866 and parameters: {'ff_dim': 32, 'dropout_rate': 0.10753752448512195, 'embed_dim': 256, 'learning_rate': 0.00015308490779730575, 'weight_decay': 3.4157769366788484e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 192, Fold 5: Test Accuracy = 0.4538
Trial 192: Mean Accuracy = 0.4228, Fold Accuracies = [np.float64(0.30068542568542567), np.float64(0.31712962962962965), np.float64(0.575090579710145), np.float64(0.4673382173382174), np.float64(0.4538498271350257)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.00014140933209895866, optimizer=Adam, weight_decay=3.812750210394991e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
Trial 193, Fold 1: Test Accuracy = 0.4229
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 193, Fold 2: Test Accuracy = 0.3831
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 26
Trial 194, Fold 1: Test Accuracy = 0.4386
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 193, Fold 3: Test Accuracy = 0.5760
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 194, Fold 2: Test Accuracy = 0.3522
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
Trial 193, Fold 4: Test Accuracy = 0.4672
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 19
Trial 194, Fold 3: Test Accuracy = 0.5757
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
[I 2025-05-08 21:41:27,989] Trial 193 finished with value: 0.4410137880992142 and parameters: {'ff_dim': 32, 'dropout_rate': 0.108181505352398, 'embed_dim': 256, 'learning_rate': 0.00014751981863025368, 'weight_decay': 3.7729420088854535e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 193, Fold 5: Test Accuracy = 0.3559
Trial 193: Mean Accuracy = 0.4410, Fold Accuracies = [np.float64(0.4228896103896103), np.float64(0.38310185185185186), np.float64(0.5759963768115942), np.float64(0.4672237484737485), np.float64(0.35585735296926635)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=9.996182223532689e-05, optimizer=Adam, weight_decay=2.949545230237786e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 194, Fold 4: Test Accuracy = 0.4282
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
Trial 195, Fold 1: Test Accuracy = 0.4745
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
[I 2025-05-08 21:43:17,368] Trial 194 finished with value: 0.44442201525863745 and parameters: {'ff_dim': 32, 'dropout_rate': 0.10774508423744955, 'embed_dim': 256, 'learning_rate': 0.00014140933209895866, 'weight_decay': 3.812750210394991e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 194, Fold 5: Test Accuracy = 0.4275
Trial 194: Mean Accuracy = 0.4444, Fold Accuracies = [np.float64(0.4385822510822511), np.float64(0.35217226407198154), np.float64(0.5756944444444444), np.float64(0.4281517094017094), np.float64(0.4275094072928008)]
Hyperparameters: num_heads=4, num_transformer_blocks=4, learning_rate=0.00010564557723553325, optimizer=Adam, weight_decay=2.934230254577061e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 10
Trial 196, Fold 1: Test Accuracy = 0.4745
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Trial 195, Fold 2: Test Accuracy = 0.5041
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 195, Fold 3: Test Accuracy = 0.4910
Trial 196, Fold 2: Test Accuracy = 0.4169
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 12
Trial 195, Fold 4: Test Accuracy = 0.4666
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
Trial 196, Fold 3: Test Accuracy = 0.5738
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 14
Trial 196, Fold 4: Test Accuracy = 0.4182
[I 2025-05-08 21:48:48,262] Trial 195 finished with value: 0.47005933107136516 and parameters: {'ff_dim': 32, 'dropout_rate': 0.11613919737791197, 'embed_dim': 256, 'learning_rate': 9.996182223532689e-05, 'weight_decay': 2.949545230237786e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 195, Fold 5: Test Accuracy = 0.4141
Trial 195: Mean Accuracy = 0.4701, Fold Accuracies = [np.float64(0.47447691197691194), np.float64(0.5040607344632768), np.float64(0.4910326086956522), np.float64(0.4666259666259666), np.float64(0.41410043359501847)]
Hyperparameters: num_heads=2, num_transformer_blocks=4, learning_rate=9.354580035428095e-05, optimizer=Adam, weight_decay=2.4242132971035634e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 23
[I 2025-05-08 21:49:46,230] Trial 196 finished with value: 0.45538595289880907 and parameters: {'ff_dim': 32, 'dropout_rate': 0.11074236915852584, 'embed_dim': 256, 'learning_rate': 0.00010564557723553325, 'weight_decay': 2.934230254577061e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 196, Fold 5: Test Accuracy = 0.3935
Trial 196: Mean Accuracy = 0.4554, Fold Accuracies = [np.float64(0.47447691197691194), np.float64(0.4169216886377904), np.float64(0.5738224637681159), np.float64(0.4182183557183557), np.float64(0.39349034439287145)]
Hyperparameters: num_heads=2, num_transformer_blocks=4, learning_rate=5.726209095539437e-05, optimizer=Adam, weight_decay=4.566099590369729e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
Trial 197, Fold 1: Test Accuracy = 0.5014
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 18
Trial 198, Fold 1: Test Accuracy = 0.5726
Trial 197, Fold 2: Test Accuracy = 0.4892
Trial 198, Fold 2: Test Accuracy = 0.4446
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Trial 197, Fold 3: Test Accuracy = 0.5408
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 24
Trial 198, Fold 3: Test Accuracy = 0.5600
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 21
Trial 197, Fold 4: Test Accuracy = 0.4144
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
Trial 198, Fold 4: Test Accuracy = 0.5101
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 20
[I 2025-05-08 21:56:24,198] Trial 197 finished with value: 0.4587800188022495 and parameters: {'ff_dim': 32, 'dropout_rate': 0.1163547946139134, 'embed_dim': 256, 'learning_rate': 9.354580035428095e-05, 'weight_decay': 2.4242132971035634e-05, 'batch_size': 16, 'num_heads': 2, 'num_transformer_blocks': 4}. Best is trial 55 with value: 0.48925222855532075.
Trial 197, Fold 5: Test Accuracy = 0.3481
Trial 197: Mean Accuracy = 0.4588, Fold Accuracies = [np.float64(0.5013528138528138), np.float64(0.4891713747645951), np.float64(0.5408212560386473), np.float64(0.4144408831908832), np.float64(0.34811376616430767)]
Hyperparameters: num_heads=4, num_transformer_blocks=32, learning_rate=6.455848583897662e-05, optimizer=Adam, weight_decay=4.4233916879810345e-05, batch_size=16,factor=1
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 22
[I 2025-05-08 21:57:51,513] Trial 198 finished with value: 0.4947411457503975 and parameters: {'ff_dim': 32, 'dropout_rate': 0.11542281673201528, 'embed_dim': 256, 'learning_rate': 5.726209095539437e-05, 'weight_decay': 4.566099590369729e-05, 'batch_size': 16, 'num_heads': 2, 'num_transformer_blocks': 4}. Best is trial 198 with value: 0.4947411457503975.
Trial 198, Fold 5: Test Accuracy = 0.3863
Trial 198: Mean Accuracy = 0.4947, Fold Accuracies = [np.float64(0.57260101010101), np.float64(0.444634076166562), np.float64(0.5600241545893719), np.float64(0.5101114163614163), np.float64(0.3863350715336275)]
Trial 199, Fold 1: Test Accuracy = 0.4079
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 28
Trial 199, Fold 2: Test Accuracy = 0.3319
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 27
Trial 199, Fold 3: Test Accuracy = 0.4741
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 17
Trial 199, Fold 4: Test Accuracy = 0.4393
Divergence detected. Stopping training after 10 epochs.
Early stopping at epoch 15
[I 2025-05-08 22:05:03,030] Trial 199 finished with value: 0.40790475842890583 and parameters: {'ff_dim': 32, 'dropout_rate': 0.10041588106079656, 'embed_dim': 256, 'learning_rate': 6.455848583897662e-05, 'weight_decay': 4.4233916879810345e-05, 'batch_size': 16, 'num_heads': 4, 'num_transformer_blocks': 32}. Best is trial 198 with value: 0.4947411457503975.
Trial 199, Fold 5: Test Accuracy = 0.3863
Trial 199: Mean Accuracy = 0.4079, Fold Accuracies = [np.float64(0.4079184704184704), np.float64(0.3319209039548023), np.float64(0.4740942028985507), np.float64(0.4392933455433455), np.float64(0.38629686932936025)]
Best hyperparameters: {'ff_dim': 32, 'dropout_rate': 0.11542281673201528, 'embed_dim': 256, 'learning_rate': 5.726209095539437e-05, 'weight_decay': 4.566099590369729e-05, 'batch_size': 16, 'num_heads': 2, 'num_transformer_blocks': 4}