{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(to right,rgb(225, 231, 134),rgb(176, 238, 148),rgb(150, 232, 238)); padding: 20px; border-radius: 10px; text-align: center; box-shadow: 0 10px 20px rgba(0,0,0,0.19), 0 6px 6px rgba(0,0,0,0.23);\">\n",
    "    <span style=\"font-family: 'Montserrat', sans-serif; font-weight: 800; font-size: 2.5em; color: white; text-shadow: 2px 2px 4px #000;\">‚ú® 2 CLASS CLASSIFICATION, SAVING THE MODEL , IMPLEMENTING GRADCAM‚ú®</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "\n",
    "from torchinfo import summary\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(to right,rgb(225, 231, 134),rgb(176, 238, 148),rgb(150, 232, 238)); padding: 20px; border-radius: 10px; text-align: center; box-shadow: 0 10px 20px rgba(0,0,0,0.19), 0 6px 6px rgba(0,0,0,0.23);\">\n",
    "    <span style=\"font-family: 'Montserrat', sans-serif; font-weight: 800; font-size: 2.5em; color: white; text-shadow: 2px 2px 4px #000;\">‚ú® LOADING THE SPLIT DATA ARRAYS ‚ú®</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(to right,rgb(225, 231, 134),rgb(176, 238, 148),rgb(150, 232, 238)); padding: 15px; border-radius: 8px; text-align: center; box-shadow: 0 8px 16px rgba(0,0,0,0.19), 0 4px 4px rgba(0,0,0,0.23);\">\n",
    "    <span style=\"font-family: 'Montserrat', sans-serif; font-weight: 700; font-size: 1.2em; color: white; text-shadow: 1px 1px 3px #000;\">üìÅ reminder to change the folder path to your numpy array folder üìÅ</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define the folder path\n",
    "folder_path = r\"D:\\PYTHONIG\\newwindow\\numpy\\NEWDATA\\ARRAYS\\mel\"\n",
    "\n",
    "# Load the numpy files into the respective arrays\n",
    "eeg_fold_1 = np.load(os.path.join(folder_path, 'mel_data_fold_1.npy'))\n",
    "labels_fold_1 = np.load(os.path.join(folder_path, 'mel_labels_fold_1.npy'))\n",
    "patients_fold_1 = np.load(os.path.join(folder_path, 'mel_patients_fold_1.npy'))\n",
    "\n",
    "eeg_fold_2 = np.load(os.path.join(folder_path, 'mel_data_fold_2.npy'))\n",
    "labels_fold_2 = np.load(os.path.join(folder_path, 'mel_labels_fold_2.npy'))\n",
    "patients_fold_2 = np.load(os.path.join(folder_path, 'mel_patients_fold_2.npy'))\n",
    "\n",
    "eeg_fold_3 = np.load(os.path.join(folder_path, 'mel_data_fold_3.npy'))\n",
    "labels_fold_3 = np.load(os.path.join(folder_path, 'mel_labels_fold_3.npy'))\n",
    "patients_fold_3 = np.load(os.path.join(folder_path, 'mel_patients_fold_3.npy'))\n",
    "\n",
    "eeg_fold_4 = np.load(os.path.join(folder_path, 'mel_data_fold_4.npy'))\n",
    "labels_fold_4 = np.load(os.path.join(folder_path, 'mel_labels_fold_4.npy'))\n",
    "patients_fold_4 = np.load(os.path.join(folder_path, 'mel_patients_fold_4.npy'))\n",
    "\n",
    "eeg_fold_5 = np.load(os.path.join(folder_path, 'mel_data_fold_5.npy'))\n",
    "labels_fold_5 = np.load(os.path.join(folder_path, 'mel_labels_fold_5.npy'))\n",
    "patients_fold_5 = np.load(os.path.join(folder_path, 'mel_patients_fold_5.npy'))\n",
    "\n",
    "eeg_folds = [eeg_fold_1, eeg_fold_2, eeg_fold_3, eeg_fold_4, eeg_fold_5]\n",
    "labels_folds = [labels_fold_1, labels_fold_2, labels_fold_3, labels_fold_4, labels_fold_5]\n",
    "patients_folds = [patients_fold_1, patients_fold_2, patients_fold_3, patients_fold_4, patients_fold_5]\n",
    "\n",
    "for i in range(len(eeg_folds)):\n",
    "    eeg_folds[i] = eeg_folds[i].astype(np.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(to right,rgb(225, 231, 134),rgb(176, 238, 148),rgb(150, 232, 238)); padding: 15px; border-radius: 8px; text-align: center; box-shadow: 0 8px 16px rgba(0,0,0,0.19), 0 4px 4px rgba(0,0,0,0.23);\">\n",
    "    <span style=\"font-family: 'Montserrat', sans-serif; font-weight: 700; font-size: 1.2em; color: white; text-shadow: 1px 1px 3px #000;\">converting to 2 class</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(labels_fold_1)):\n",
    "    if (labels_fold_1[i] == 2):\n",
    "        labels_fold_1[i] = 1\n",
    "\n",
    "for i in range (len(labels_fold_2)):\n",
    "    if (labels_fold_2[i] == 2):\n",
    "        labels_fold_2[i] = 1\n",
    "\n",
    "for i in range (len(labels_fold_3)):\n",
    "    if (labels_fold_3[i] == 2):\n",
    "        labels_fold_3[i] = 1\n",
    "\n",
    "for i in range (len(labels_fold_4)):\n",
    "    if (labels_fold_4[i] == 2):\n",
    "        labels_fold_4[i] = 1\n",
    "\n",
    "for i in range (len(labels_fold_5)):\n",
    "    if (labels_fold_5[i] == 2):\n",
    "        labels_fold_5[i] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(to right,rgb(225, 231, 134),rgb(176, 238, 148),rgb(150, 232, 238)); padding: 15px; border-radius: 8px; text-align: center; box-shadow: 0 8px 16px rgba(0,0,0,0.19), 0 4px 4px rgba(0,0,0,0.23);\">\n",
    "    <span style=\"font-family: 'Montserrat', sans-serif; font-weight: 700; font-size: 1.2em; color: white; text-shadow: 1px 1px 3px #000;\">data balancer & early stopping</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_balancer(data, labels, factor):\n",
    "    # Count the number of samples in each class\n",
    "    num_class_0 = np.sum(labels == 0)\n",
    "    num_class_1 = np.sum(labels == 1)\n",
    "\n",
    "\n",
    "    # Find the minimum number of samples across all classes\n",
    "    min_samples = min(num_class_0, num_class_1)\n",
    "\n",
    "    # Calculate the number of samples to take from each class\n",
    "    samples_per_class = min_samples // factor\n",
    "\n",
    "    # Randomly sample 'samples_per_class' from each class\n",
    "    class_0_indices = np.random.choice(np.where(labels == 0)[0], samples_per_class, replace=False)\n",
    "    class_1_indices = np.random.choice(np.where(labels == 1)[0], samples_per_class, replace=False)\n",
    "\n",
    "\n",
    "    # Combine balanced indices\n",
    "    balanced_indices = np.concatenate((class_0_indices, class_1_indices))\n",
    "\n",
    "    # Shuffle the balanced indices\n",
    "    np.random.shuffle(balanced_indices)\n",
    "\n",
    "    # Create balanced training data and labels\n",
    "    balanced_data = data[balanced_indices]\n",
    "    balanced_labels = labels[balanced_indices]\n",
    "\n",
    "    return balanced_data, balanced_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5):\n",
    "        \"\"\"\n",
    "        Initializes the early stopping mechanism based on divergence detection.\n",
    "\n",
    "        Args:\n",
    "            patience (int): Number of consecutive epochs with increasing validation loss\n",
    "                            before stopping.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "        self.best_model_state = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        \"\"\"\n",
    "        Checks if the validation loss is diverging and updates the state accordingly.\n",
    "\n",
    "        Args:\n",
    "            val_loss (float): Current epoch's validation loss.\n",
    "            model (torch.nn.Module): The model being trained.\n",
    "        \"\"\"\n",
    "        if self.best_loss is None or val_loss < self.best_loss:\n",
    "            # Improvement detected\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model_state = model.state_dict()\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            # Validation loss increased\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                print(f\"Divergence detected. Stopping training after {self.counter} epochs.\")\n",
    "                self.early_stop = True\n",
    "\n",
    "    def load_best_model(self, model):\n",
    "        \"\"\"\n",
    "        Restores the model to the state with the lowest validation loss.\n",
    "\n",
    "        Args:\n",
    "            model (torch.nn.Module): The model to restore.\n",
    "        \"\"\"\n",
    "        model.load_state_dict(self.best_model_state)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(to right,rgb(225, 231, 134),rgb(176, 238, 148),rgb(150, 232, 238)); padding: 15px; border-radius: 8px; text-align: center; box-shadow: 0 8px 16px rgba(0,0,0,0.19), 0 4px 4px rgba(0,0,0,0.23);\">\n",
    "    <span style=\"font-family: 'Montserrat', sans-serif; font-weight: 700; font-size: 1.2em; color: white; text-shadow: 1px 1px 3px #000;\">Result plotting</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    precision_recall_curve,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    f1_score,\n",
    "    balanced_accuracy_score,\n",
    "    classification_report,\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "def plot_metrics(labels, predictions, n_classes=2):\n",
    "    \"\"\"\n",
    "    Computes and visualizes classification metrics.\n",
    "\n",
    "    Args:\n",
    "        labels (array-like): True class labels.\n",
    "        predictions (array-like): Probabilities or class predictions.\n",
    "        n_classes (int): Number of classes (default: 2 for binary classification).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert probability predictions to class labels if needed\n",
    "    if predictions.ndim > 1:\n",
    "        predicted_classes = np.argmax(predictions, axis=1)\n",
    "    else:\n",
    "        predicted_classes = predictions\n",
    "\n",
    "    # Compute Confusion Matrix\n",
    "    cm = confusion_matrix(labels, predicted_classes)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', cbar=False)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.show()\n",
    "\n",
    "    # Class-wise Accuracy\n",
    "    print(\"\\nClass-wise Accuracy:\")\n",
    "    class_accuracies = []\n",
    "    for d in range(n_classes):\n",
    "        correct_preds = cm[d][d]\n",
    "        total_true_samples = sum(cm[d])\n",
    "        accuracy = correct_preds / total_true_samples if total_true_samples > 0 else 0\n",
    "        class_accuracies.append(accuracy)\n",
    "        print(f'Class {d}: {correct_preds}/{total_true_samples} ({accuracy:.2%})')\n",
    "\n",
    "    # Precision-Recall Curve & AUPRC\n",
    "    print(\"\\nPrecision-Recall Curve:\")\n",
    "    plt.figure()\n",
    "    \n",
    "    if n_classes == 2:\n",
    "        # Binary classification\n",
    "        precision, recall, _ = precision_recall_curve(labels, predictions[:, 1])\n",
    "        auprc = auc(recall, precision)\n",
    "        plt.plot(recall, precision, label=f'AUPRC = {auprc:.2f}')\n",
    "        avg_auprc = auprc\n",
    "    else:\n",
    "        # Multi-class case\n",
    "        labels_binarized = label_binarize(labels, classes=np.arange(n_classes))\n",
    "        auprcs = []\n",
    "        for class_idx in range(n_classes):\n",
    "            precision, recall, _ = precision_recall_curve(labels_binarized[:, class_idx], predictions[:, class_idx])\n",
    "            auprc = auc(recall, precision)\n",
    "            auprcs.append(auprc)\n",
    "            plt.plot(recall, precision, label=f'Class {class_idx} (AUPRC = {auprc:.2f})')\n",
    "        avg_auprc = np.mean(auprcs)\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # ROC Curve & AUC\n",
    "    print(\"\\nROC Curve:\")\n",
    "    plt.figure()\n",
    "    \n",
    "    if n_classes == 2:\n",
    "        # Binary classification\n",
    "        fpr, tpr, _ = roc_curve(labels, predictions[:, 1])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
    "    else:\n",
    "        # Multi-class case\n",
    "        for class_idx in range(n_classes):\n",
    "            fpr, tpr, _ = roc_curve(labels_binarized[:, class_idx], predictions[:, class_idx])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, label=f'Class {class_idx} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Compute Metrics\n",
    "    f1 = f1_score(labels, predicted_classes, average='macro')\n",
    "    balanced_acc = balanced_accuracy_score(labels, predicted_classes)\n",
    "\n",
    "    print(f\"\\nMean F1 Score: {f1:.4f}\")\n",
    "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
    "    print(f\"Average AUPRC: {avg_auprc:.4f}\")\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(labels, predicted_classes))\n",
    "\n",
    "    return {\n",
    "        \"confusion_matrix\": cm,\n",
    "        \"class_wise_accuracy\": class_accuracies,\n",
    "        \"mean_f1_score\": f1,\n",
    "        \"balanced_accuracy\": balanced_acc,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(to right,rgb(225, 231, 134),rgb(238, 206, 148),rgb(238, 150, 150)); padding: 15px; border-radius: 8px; text-align: center; box-shadow: 0 8px 16px rgba(0,0,0,0.19), 0 4px 4px rgba(0,0,0,0.23);\">\n",
    "    <span style=\"font-family: 'Montserrat', sans-serif; font-weight: 700; font-size: 1.2em; color: white; text-shadow: 1px 1px 3px #000;\">MODEL GOES HERE</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "def patchify(data, n_patches):\n",
    "    n, c, h, w = data.shape\n",
    "    patches = torch.zeros(n, n_patches**2, (c*h*w) // (n_patches**2))\n",
    "    patch_size = h // n_patches\n",
    "    for idx, d in enumerate(data):\n",
    "        for i in range(n_patches):\n",
    "            for j in range(n_patches):\n",
    "                patch = d[:, i*patch_size: (i+1)*patch_size, j*patch_size: (j+1) * patch_size]\n",
    "                patches[idx, i*n_patches + j] = patch.flatten()\n",
    "    return patches\n",
    "\n",
    "def get_positional_embeddings(sequence_length, d):\n",
    "    result = torch.ones(sequence_length, d)\n",
    "    for i in range(sequence_length):\n",
    "        for j in range(d):\n",
    "            result[i][j] = np.sin(i / (10000 ** (j / d))) if j % 2 == 0 else np.cos(i / (10000 ** ((j - 1) / d)))\n",
    "    return result\n",
    "\n",
    "class vit(nn.Module):\n",
    "    def __init__(self, input_size, n_patches, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.chw = input_size\n",
    "        self.n_patches = n_patches\n",
    "        self.patch_size = ((self.chw[1] // n_patches) ** 2) * self.chw[0]\n",
    "        self.linear_mapper = nn.Linear(self.patch_size, hidden_size)\n",
    "        self.class_token = nn.Parameter(torch.rand(1, hidden_size))\n",
    "        self.pos_embed = nn.Parameter(torch.tensor(get_positional_embeddings(self.n_patches ** 2 + 1, hidden_size)))\n",
    "        self.pos_embed.requires_grad = True\n",
    "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
    "\n",
    "        # Transformer encoder layers\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            nn.TransformerEncoderLayer(d_model=hidden_size, nhead=4, batch_first=True)\n",
    "            for _ in range(2)\n",
    "        ])\n",
    "        self.classifier = nn.Sequential(nn.Linear(hidden_size, num_classes))\n",
    "\n",
    "        # For saliency maps\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        self._register_hook = False\n",
    "\n",
    "    def save_gradient(self, grad):\n",
    "        self.gradients = grad\n",
    "\n",
    "    def forward(self, x):\n",
    "        patches = patchify(x, self.n_patches)\n",
    "        \n",
    "        x = self.linear_mapper(patches)\n",
    "        x = torch.stack([torch.vstack((self.class_token, x[i])) for i in range(len(x))])\n",
    "        pos_embed = self.pos_embed.repeat(len(x), 1, 1)\n",
    "        x = x + pos_embed\n",
    "        x = self.layer_norm(x)\n",
    "\n",
    "        # Pass through transformer encoder layers\n",
    "        for idx, layer in enumerate(self.encoder_layers):\n",
    "            x = layer(x)\n",
    "            if idx == len(self.encoder_layers) - 1 and not self._register_hook:\n",
    "                x.register_hook(self.save_gradient)  # Register hook only once\n",
    "                self._register_hook = True\n",
    "            self.activations = x  # Save the latest activations\n",
    "\n",
    "        x = x[:, 0]  # Select CLS token for classification\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def get_activations_gradient(self):\n",
    "        return self.gradients\n",
    "\n",
    "    def get_activations(self):\n",
    "        return self.activations\n",
    "\n",
    "    def set_hook(self, hook_status):\n",
    "        self._register_hook = hook_status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(to right,rgb(225, 231, 134),rgb(238, 206, 148),rgb(238, 150, 150)); padding: 15px; border-radius: 8px; text-align: center; box-shadow: 0 8px 16px rgba(0,0,0,0.19), 0 4px 4px rgba(0,0,0,0.23);\">\n",
    "    <span style=\"font-family: 'Montserrat', sans-serif; font-weight: 700; font-size: 1.2em; color: white; text-shadow: 1px 1px 3px #000;\">Test with demo data & model Summary</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mahesh\\AppData\\Local\\Temp\\ipykernel_15684\\1373862186.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.pos_embed = nn.Parameter(torch.tensor(get_positional_embeddings(self.n_patches ** 2 + 1, hidden_size)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model  = vit(input_size=(20,100,100),n_patches=10,hidden_size=512,num_classes=2)# declare model here\n",
    "randomdata = torch.randn((1,20,100,100))\n",
    "output = model(randomdata)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "vit                                                          52,224\n",
       "‚îú‚îÄLinear: 1-1                                                1,024,512\n",
       "‚îú‚îÄLayerNorm: 1-2                                             1,024\n",
       "‚îú‚îÄModuleList: 1-3                                            --\n",
       "‚îÇ    ‚îî‚îÄTransformerEncoderLayer: 2-1                          --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMultiheadAttention: 3-1                          1,050,624\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 3-2                                      1,050,624\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 3-3                                     --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 3-4                                      1,049,088\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-5                                   1,024\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-6                                   1,024\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 3-7                                     --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 3-8                                     --\n",
       "‚îÇ    ‚îî‚îÄTransformerEncoderLayer: 2-2                          --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMultiheadAttention: 3-9                          1,050,624\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 3-10                                     1,050,624\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 3-11                                    --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 3-12                                     1,049,088\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-13                                  1,024\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-14                                  1,024\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 3-15                                    --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 3-16                                    --\n",
       "‚îú‚îÄSequential: 1-4                                            --\n",
       "‚îÇ    ‚îî‚îÄLinear: 2-3                                           1,026\n",
       "=====================================================================================\n",
       "Total params: 7,383,554\n",
       "Trainable params: 7,383,554\n",
       "Non-trainable params: 0\n",
       "====================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(to right,rgb(225, 231, 134),rgb(238, 206, 148),rgb(238, 150, 150)); padding: 15px; border-radius: 8px; text-align: center; box-shadow: 0 8px 16px rgba(0,0,0,0.19), 0 4px 4px rgba(0,0,0,0.23);\">\n",
    "    <span style=\"font-family: 'Montserrat', sans-serif; font-weight: 700; font-size: 1.2em; color: white; text-shadow: 1px 1px 3px #000;\">Training Code, TRAINING ONLY ONE FOLD, TO SAVE MODEL</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "\n",
    "# Fold indices and other configurations\n",
    "num_folds = 1 # ONLY ONE FOLD\n",
    "fold_indices = [0,1,2,3,4]\n",
    "val_fold_indices = np.roll(fold_indices, 1)\n",
    "\n",
    "test_folds_chosen = []\n",
    "val_folds_chosen = []\n",
    "fold_confusion_matrices = []  # To store confusion matrices for each fold\n",
    "fold_accuracies = []  # To store balanced accuracy for each fold\n",
    "fold_auprcs = []  # To store AUPRC for each fold\n",
    "\n",
    "# Model and training configurations\n",
    "num_classes = 2\n",
    "learning_rate = 0.0001\n",
    "epochs = 1\n",
    "input_shape = (20, 100, 100)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Training loop for cross-validation\n",
    "for fold_idx in range(num_folds):\n",
    "    print(f'Fold No: {fold_idx + 1}')\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    # Initialize model, loss, and optimizer\n",
    "    fold_model = vit(input_size=input_shape,n_patches=10,hidden_size=512,num_classes=2)\n",
    "    fold_model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.3)\n",
    "    optimizer = optim.Adam(fold_model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Split data into train, validation, and test sets\n",
    "    test_fold = fold_indices[fold_idx]\n",
    "    val_fold = val_fold_indices[fold_idx]\n",
    "    train_folds = [fold for fold in fold_indices if fold != test_fold and fold != val_fold]\n",
    "\n",
    "    train_data = np.concatenate([eeg_folds[j] for j in train_folds])\n",
    "    train_labels = np.concatenate([labels_folds[j] for j in train_folds])\n",
    "    train_data = train_data.transpose(0, 3, 1, 2)  # Transpose to match PyTorch input format\n",
    "\n",
    "    test_folds_chosen.append(test_fold)\n",
    "    val_folds_chosen.append(val_fold)\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=10)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        balanced_train_data, balanced_train_labels = data_balancer(train_data, train_labels, factor=1)\n",
    "\n",
    "        train_dataset = TensorDataset(\n",
    "            torch.tensor(balanced_train_data, dtype=torch.float32).to(device),\n",
    "            torch.tensor(balanced_train_labels, dtype=torch.long).to(device)\n",
    "        )\n",
    "        train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "        \n",
    "        fold_model.train()\n",
    "        running_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = fold_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = balanced_accuracy_score(all_labels, all_preds)\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
    "\n",
    "        # Validation loop\n",
    "        val_data = eeg_folds[val_fold].transpose(0, 3, 1, 2)\n",
    "        val_labels = labels_folds[val_fold]\n",
    "        val_dataset = TensorDataset(\n",
    "            torch.tensor(val_data, dtype=torch.float32).to(device),\n",
    "            torch.tensor(val_labels, dtype=torch.long).to(device)\n",
    "        )\n",
    "        val_loader = DataLoader(val_dataset, batch_size=10, shuffle=False)\n",
    "\n",
    "        fold_model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_preds = []\n",
    "        val_labels_list = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_labels in val_loader:\n",
    "                val_outputs = fold_model(val_inputs)\n",
    "                loss = criterion(val_outputs, val_labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, val_batch_preds = torch.max(val_outputs, 1)\n",
    "                val_preds.extend(val_batch_preds.cpu().numpy())\n",
    "                val_labels_list.extend(val_labels.cpu().numpy())\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = balanced_accuracy_score(val_labels_list, val_preds)\n",
    "        print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}')\n",
    "\n",
    "        early_stopping(val_loss, fold_model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    # Load the best model\n",
    "    early_stopping.load_best_model(fold_model)\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc =  val_acc\n",
    "        model_save_path = fr\"D:\\PYTHONIG\\newwindow\\NEW DATA RUNS\\Vit_gradcam\\stft_model_fold_{i+1}_1P.pth\"\n",
    "        torch.save({ 'MEL_model_state_dict': model.state_dict(), 'MEL_optimizer_state_dict': optimizer.state_dict(), 'epoch': epoch}, model_save_path)\n",
    "        print(f'Model for fold {i+1} saved at epoch{epoch +1}')\n",
    "\n",
    "    # Test loop\n",
    "    test_data = eeg_folds[test_fold].transpose(0, 3, 1, 2)\n",
    "    test_labels = labels_folds[test_fold]\n",
    "    test_dataset = TensorDataset(\n",
    "        torch.tensor(test_data, dtype=torch.float32).to(device),\n",
    "        torch.tensor(test_labels, dtype=torch.long).to(device)\n",
    "    )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)\n",
    "\n",
    "    fold_model.eval()\n",
    "    test_probs = []\n",
    "    test_preds = []\n",
    "    test_labels_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_inputs, test_labels in test_loader:\n",
    "            test_outputs = fold_model(test_inputs)\n",
    "            probabilities = torch.softmax(test_outputs, dim=1)\n",
    "            test_probs.extend(probabilities.cpu().numpy())\n",
    "            _, preds = torch.max(probabilities, 1)\n",
    "            test_preds.extend(preds.cpu().numpy())\n",
    "            test_labels_list.extend(test_labels.cpu().numpy())\n",
    "\n",
    "    # Compute metrics\n",
    "    test_acc = balanced_accuracy_score(test_labels_list, test_preds)\n",
    "    fold_accuracies.append(test_acc)\n",
    "\n",
    "    cm = confusion_matrix(test_labels_list, test_preds)\n",
    "    fold_confusion_matrices.append(cm)\n",
    "\n",
    "    test_labels_binarized = test_labels_list\n",
    "    test_auprcs = []\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(test_labels_list, np.array(test_probs)[:, 1])\n",
    "    auprc = auc(recall, precision)\n",
    "    test_auprcs.append(auprc)\n",
    "\n",
    "    mean_test_auprc = np.mean(test_auprcs)\n",
    "    fold_auprcs.append(mean_test_auprc)\n",
    "\n",
    "    print(f'Test Fold {fold_idx + 1}, Mean AUPRC: {mean_test_auprc:.4f}, Balanced Accuracy: {test_acc:.4f}')\n",
    "\n",
    "    # Use the plot_metrics function to visualize metrics\n",
    "    plot_metrics(np.array(test_labels_list), np.array(test_probs), n_classes=num_classes)\n",
    "\n",
    "# Final metrics across all folds\n",
    "average_auprc = np.mean(fold_auprcs)\n",
    "mean_accuracy = np.mean(fold_accuracies)\n",
    "print(f'Accuracy for each fold: {fold_accuracies}')\n",
    "print(f'AUPRC for each fold: {fold_auprcs}')\n",
    "print(f'Average AUPRC across all folds: {average_auprc}')\n",
    "print(f'Average Balanced Accuracy across all folds: {mean_accuracy}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(to right,rgb(225, 231, 134),rgb(238, 206, 148),rgb(238, 150, 150)); padding: 15px; border-radius: 8px; text-align: center; box-shadow: 0 8px 16px rgba(0,0,0,0.19), 0 4px 4px rgba(0,0,0,0.23);\">\n",
    "    <span style=\"font-family: 'Montserrat', sans-serif; font-weight: 700; font-size: 1.2em; color: white; text-shadow: 1px 1px 3px #000;\">GRADCAM FUNCTIONS</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_model(model_path, model_class, device):\n",
    "    model = model_class((20, 100, 100), 25, 512).to(device)  \n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['MEL_model_state_dict'])\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def depatchify(grad_cam, n_patches, image_size):\n",
    "    \"\"\"\n",
    "    Reverse the patchification process to reconstruct the full image Grad-CAM from patch-level scores.\n",
    "    Args:\n",
    "        grad_cam: Grad-CAM heatmap of shape [n_patches^2].\n",
    "        n_patches: Number of patches along each dimension.\n",
    "        image_size: Tuple (H, W) of the original image dimensions.\n",
    "    Returns:\n",
    "        heatmap: Full image heatmap of shape [H, W].\n",
    "    \"\"\"\n",
    "    patch_size = image_size[0] // n_patches\n",
    "    heatmap = np.zeros(image_size)\n",
    "\n",
    "    for i in range(n_patches):\n",
    "        for j in range(n_patches):\n",
    "            patch_idx = i * n_patches + j\n",
    "            patch_value = grad_cam[patch_idx]  # Get Grad-CAM value for this patch\n",
    "            heatmap[i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size] = patch_value\n",
    "\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAM:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def __call__(self, input_tensor, target_class=None):\n",
    "        self.model.eval()\n",
    "        output = self.model(input_tensor)  # Forward pass\n",
    "        if target_class is None:\n",
    "            target_class = output.argmax(dim=-1)  # Predicted class for each batch item\n",
    "            print ('target_class is: ', target_class, target_class.shape)\n",
    "\n",
    "        # Compute gradients for the target clas s\n",
    "        loss = output[:, target_class].sum()\n",
    "        self.model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Get activations and gradients\n",
    "        gradients = self.model.gradients  # Shape: [batch_size, seq_len, hidden_dim]\n",
    "        activations = self.model.activations  # Shape: [batch_size, seq_len, hidden_dim]\n",
    "        # print('gradients shape', gradients[:,1:].sum())\n",
    "        \n",
    "        weights = torch.mean(gradients, dim=1, keepdim=True)  # Mean over sequence length\n",
    "        # print('weights:', weights)\n",
    "        cam = torch.sum(weights * activations, dim=-1).squeeze()  # Weighted sum\n",
    "        # print('cam', cam)\n",
    "        \n",
    "        cam = cam - cam.min()\n",
    "        cam = cam / cam.max()\n",
    "        cam=cam[:,1:]\n",
    "        return cam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gradcam(input_image, grad_cam_heatmap,spectrogram_image, alpha=0.5, cmap='inferno'):\n",
    "    \"\"\"\n",
    "    Plot the input spectrogram with Grad-CAM heatmap overlay.\n",
    "    Args:\n",
    "        input_image: Input spectrogram of shape [H, W].\n",
    "        grad_cam_heatmap: Full Grad-CAM heatmap of shape [H, W].\n",
    "        alpha: Transparency for overlay (0.0 to 1.0).\n",
    "    \"\"\"\n",
    "    Fs = 256  \n",
    "    n_bins = 100\n",
    "    T = 20 \n",
    "    n_time_bins = 100\n",
    "    frequency_axis = np.linspace(0, Fs/2, n_bins)\n",
    "    \n",
    "    time_axis = np.linspace(0, T, n_time_bins)\n",
    "    \n",
    "\n",
    "    normalized_spectrogram_image = (spectrogram_image - spectrogram_image.min()) / (spectrogram_image.max() - spectrogram_image.min())\n",
    "    normalized_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
    "    grad_cam_heatmap = (grad_cam_heatmap - grad_cam_heatmap.min()) / (grad_cam_heatmap.max() - grad_cam_heatmap.min())\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(normalized_spectrogram_image, aspect='auto', origin='lower', extent=[time_axis.min(), time_axis.max(), frequency_axis.min(), frequency_axis.max()],   cmap=cmap)\n",
    "    plt.colorbar() \n",
    "    \n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.title('EEG Time-Frequency Spectrogram')\n",
    "    \n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    # plt.imshow(normalized_image, vmin=0, vmax=1, aspect='auto', origin='lower', extent=[time_axis.min(), time_axis.max(), frequency_axis.min(), frequency_axis.max()],   cmap=cmap)\n",
    "    plt.imshow(grad_cam_heatmap,  interpolation='bilinear', alpha=alpha,aspect='auto', origin='lower', extent=[time_axis.min(), time_axis.max(), frequency_axis.min(), frequency_axis.max()],   cmap=cmap)\n",
    "    plt.title(\"Grad-CAM Visualization\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.imshow(normalized_image, vmin=0, vmax=1, aspect='auto', origin='lower', extent=[time_axis.min(), time_axis.max(), frequency_axis.min(), frequency_axis.max()],   cmap=cmap)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Frequency')\n",
    "    \n",
    "    \n",
    "\n",
    "    # Plot heatmap overlay\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(normalized_image, vmin=0, vmax=1, aspect='auto', origin='lower', extent=[time_axis.min(), time_axis.max(), frequency_axis.min(), frequency_axis.max()],   cmap=cmap)\n",
    "    plt.imshow(grad_cam_heatmap,  interpolation='bilinear', alpha=alpha,aspect='auto', origin='lower', extent=[time_axis.min(), time_axis.max(), frequency_axis.min(), frequency_axis.max()],   cmap=cmap)\n",
    "    \n",
    "    plt.colorbar()\n",
    "    \n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def test_model(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Test the model on the first `num_samples` images and compare predictions with actual labels.\n",
    "    Args:\n",
    "        model: Trained model.\n",
    "        data_loader: DataLoader for the test dataset.\n",
    "        device: Device ('cpu' or 'cuda').\n",
    "        num_samples: Number of samples to test (default is 10).\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    actual_labels = []\n",
    "    predicted_labels = []\n",
    "    images = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs,labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.argmax(outputs, dim=1)  # Get predicted class\n",
    "            actual_labels.extend(labels.cpu().tolist())\n",
    "            predicted_labels.extend(preds.cpu().tolist())\n",
    "            images.extend(inputs.cpu())\n",
    "\n",
    "\n",
    "    # Print results for the first `num_samples` images\n",
    "    print(f\"{'Image':<10}{'Actual Label':<15}{'Predicted Label':<15}\")\n",
    "    for i in range(len(labels)):\n",
    "        print(f\"{i+1:<10}{actual_labels[i]:<15}{predicted_labels[i]:<15}\")\n",
    "\n",
    "    return images, actual_labels, predicted_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_predictions(images, actual_labels, predicted_labels):\n",
    "    \"\"\"\n",
    "    Visualize spectrogram images with actual and predicted labels.\n",
    "    Args:\n",
    "        images: List of spectrogram images.\n",
    "        actual_labels: List of actual labels.\n",
    "        predicted_labels: List of predicted labels.\n",
    "        num_samples: Number of samples to visualize.\n",
    "    \"\"\"\n",
    "    for i in range(len(actual_labels)):\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.imshow(images[i][0], cmap=\"viridis\")  # Assuming single-channel image\n",
    "        plt.title(f\"Actual: {actual_labels[i]}, Predicted: {predicted_labels[i]}\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(to right,rgb(225, 231, 134),rgb(238, 206, 148),rgb(238, 150, 150)); padding: 15px; border-radius: 8px; text-align: center; box-shadow: 0 8px 16px rgba(0,0,0,0.19), 0 4px 4px rgba(0,0,0,0.23);\">\n",
    "    <span style=\"font-family: 'Montserrat', sans-serif; font-weight: 700; font-size: 1.2em; color: white; text-shadow: 1px 1px 3px #000;\">Getting Testing DATA for fold 1</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = eeg_folds[0]\n",
    "test_data= np.transpose(test_data, (0,3,1,2))\n",
    "\n",
    "test_data_tensor = torch.tensor(test_data, dtype=torch.float32).to(device)\n",
    "test_labels_tensor = torch.tensor(labels_folds[0], dtype=torch.long).to(device)\n",
    "test_dataset = TensorDataset(test_data_tensor, test_labels_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(to right,rgb(225, 231, 134),rgb(238, 206, 148),rgb(238, 150, 150)); padding: 15px; border-radius: 8px; text-align: center; box-shadow: 0 8px 16px rgba(0,0,0,0.19), 0 4px 4px rgba(0,0,0,0.23);\">\n",
    "    <span style=\"font-family: 'Montserrat', sans-serif; font-weight: 700; font-size: 1.2em; color: white; text-shadow: 1px 1px 3px #000;\">LOAD SAVED MODEL</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(r\"D:\\PYTHONIG\\newwindow\\GRADCAM\\20patchsize\\model_fold_1_1P.pth\", vit, device) \n",
    "images, actual_labels, predicted_labels = test_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(actual_labels),len(images),len(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(to right,rgb(225, 231, 134),rgb(238, 206, 148),rgb(238, 150, 150)); padding: 15px; border-radius: 8px; text-align: center; box-shadow: 0 8px 16px rgba(0,0,0,0.19), 0 4px 4px rgba(0,0,0,0.23);\">\n",
    "    <span style=\"font-family: 'Montserrat', sans-serif; font-weight: 700; font-size: 1.2em; color: white; text-shadow: 1px 1px 3px #000;\">CLASS 0 PREDICTED 0</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "Fs = 256  \n",
    "n_bins = 100\n",
    "T = 20 \n",
    "n_time_bins = 100\n",
    "frequency_axis = np.linspace(0, Fs/2, n_bins)\n",
    "\n",
    "time_axis = np.linspace(0, T, n_time_bins)\n",
    "\n",
    "image_size = (100, 100)\n",
    "n_patches = model.n_patches\n",
    "patch_size = image_size[0] // n_patches\n",
    "\n",
    "# Instantiate Grad-CAM\n",
    "grad_cam = GradCAM(model)\n",
    "cam = grad_cam(test_data_tensor, target_class=0)  \n",
    "average_heatmap_class_0 = np.zeros(image_size)\n",
    "count_class_0 = 0\n",
    "\n",
    "\n",
    "for idx in range(len(actual_labels)):\n",
    "    if actual_labels[idx] == predicted_labels[idx]:  \n",
    "        cam_batch = cam[idx, :].detach().cpu().numpy()  \n",
    "        heatmap = np.zeros(image_size)\n",
    "        \n",
    "        # Reconstruct the heatmap from patches\n",
    "        for i in range(n_patches):\n",
    "            for j in range(n_patches):\n",
    "                patch_idx = i * n_patches + j\n",
    "                patch_value = cam_batch[patch_idx]  # Get Grad-CAM value for this patch\n",
    "                heatmap[\n",
    "                    i * patch_size: (i + 1) * patch_size,\n",
    "                    j * patch_size: (j + 1) * patch_size\n",
    "                ] = patch_value\n",
    "        \n",
    "        # Accumulate heatmaps for the corresponding class\n",
    "        if actual_labels[idx] == 0:  # True prediction for class 0\n",
    "            average_heatmap_class_0 += heatmap\n",
    "            count_class_0 += 1\n",
    "\n",
    "# Compute average heatmaps\n",
    "if count_class_0 > 0:\n",
    "    average_heatmap_class_0 /= count_class_0\n",
    "\n",
    "\n",
    "# Normalize the average heatmaps (optional, for visualization)\n",
    "average_heatmap_class_0 -= average_heatmap_class_0.min()\n",
    "average_heatmap_class_0 /= average_heatmap_class_0.max()\n",
    "\n",
    "\n",
    "\n",
    "# Final heatmaps\n",
    "print(f\"Class 0: Average heatmap calculated from {count_class_0} true predictions.\")\n",
    "print('count_class_0: ',count_class_0)\n",
    "\n",
    "\n",
    "# Class 0\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.imshow(average_heatmap_class_0,interpolation='bilinear', cmap='viridis',origin='lower', aspect='auto',  extent=[time_axis.min(), time_axis.max(), frequency_axis.min(), frequency_axis.max()])\n",
    "plt.colorbar()\n",
    "plt.title('Average Grad-CAM Heatmap for Class 0')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(to right,rgb(225, 231, 134),rgb(238, 206, 148),rgb(238, 150, 150)); padding: 15px; border-radius: 8px; text-align: center; box-shadow: 0 8px 16px rgba(0,0,0,0.19), 0 4px 4px rgba(0,0,0,0.23);\">\n",
    "    <span style=\"font-family: 'Montserrat', sans-serif; font-weight: 700; font-size: 1.2em; color: white; text-shadow: 1px 1px 3px #000;\">CLASS 1 PREDICTED 1</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_size = (100, 100)\n",
    "n_patches = model.n_patches\n",
    "patch_size = image_size[0] // n_patches\n",
    "\n",
    "# Instantiate Grad-CAM\n",
    "grad_cam = GradCAM(model)\n",
    "cam = grad_cam(test_data_tensor, target_class=1)  # Grad-CAM output, shape: (1058, 25)\n",
    "\n",
    "# Initialize containers for average heatmaps\n",
    "average_heatmap_class_1 = np.zeros(image_size)\n",
    "count_class_1 = 0\n",
    "\n",
    "# Loop through all data points to find true predictions\n",
    "for idx in range(len(actual_labels)):\n",
    "    if actual_labels[idx] == predicted_labels[idx]:  # Check if the prediction is correct\n",
    "        cam_batch = cam[idx, :].detach().cpu().numpy()  # Grad-CAM for the current batch, shape: (25,)\n",
    "        heatmap = np.zeros(image_size)\n",
    "        \n",
    "        # Reconstruct the heatmap from patches\n",
    "        for i in range(n_patches):\n",
    "            for j in range(n_patches):\n",
    "                patch_idx = i * n_patches + j\n",
    "                patch_value = cam_batch[patch_idx]  # Get Grad-CAM value for this patch\n",
    "                heatmap[\n",
    "                    i * patch_size: (i + 1) * patch_size,\n",
    "                    j * patch_size: (j + 1) * patch_size\n",
    "                ] = patch_value\n",
    "        \n",
    "        # Accumulate heatmaps for the corresponding class\n",
    "        if actual_labels[idx] == 1:  # True prediction for class 1\n",
    "            average_heatmap_class_1 += heatmap\n",
    "            count_class_1 += 1\n",
    "\n",
    "# Compute average heatmaps\n",
    "if count_class_1 > 0:\n",
    "    average_heatmap_class_1 /= count_class_1\n",
    "\n",
    "\n",
    "# Normalize the average heatmaps (optional, for visualization)\n",
    "average_heatmap_class_1 -= average_heatmap_class_1.min()\n",
    "average_heatmap_class_1 /= average_heatmap_class_1.max()\n",
    "\n",
    "\n",
    "\n",
    "# Final heatmaps\n",
    "print(f\"Class 1: Average heatmap calculated from {count_class_1} true predictions.\")\n",
    "print('count_class_1: ',count_class_1)\n",
    "\n",
    "\n",
    "# Class 0\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.imshow(average_heatmap_class_1,interpolation='bilinear', cmap='viridis',origin='lower', aspect='auto',  extent=[time_axis.min(), time_axis.max(), frequency_axis.min(), frequency_axis.max()])\n",
    "plt.colorbar()\n",
    "plt.title('Average Grad-CAM Heatmap for Class 1')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(to right,rgb(225, 231, 134),rgb(238, 206, 148),rgb(238, 150, 150)); padding: 15px; border-radius: 8px; text-align: center; box-shadow: 0 8px 16px rgba(0,0,0,0.19), 0 4px 4px rgba(0,0,0,0.23);\">\n",
    "    <span style=\"font-family: 'Montserrat', sans-serif; font-weight: 700; font-size: 1.2em; color: white; text-shadow: 1px 1px 3px #000;\">CLASS 0 PREDICTED 1</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = grad_cam(test_data_tensor, target_class=1)  \n",
    "average_heatmap_actual_0_pred_1 = np.zeros(image_size)\n",
    "count_actual_0_pred_1 = 0\n",
    "\n",
    "for idx in range(len(actual_labels)):\n",
    "    if actual_labels[idx] == 0 and predicted_labels[idx] == 1:  # Actual 0, Predicted 1\n",
    "        cam_batch = cam[idx, :].detach().cpu().numpy()  # Grad-CAM for the current batch, shape: (25,)\n",
    "        heatmap = np.zeros(image_size)\n",
    "        \n",
    "        # Reconstruct the heatmap from patches\n",
    "        for i in range(n_patches):\n",
    "            for j in range(n_patches):\n",
    "                patch_idx = i * n_patches + j\n",
    "                patch_value = cam_batch[patch_idx]  # Get Grad-CAM value for this patch\n",
    "                heatmap[\n",
    "                    i * patch_size: (i + 1) * patch_size,\n",
    "                    j * patch_size: (j + 1) * patch_size\n",
    "                ] = patch_value\n",
    "        \n",
    "        # Accumulate heatmaps for averaging\n",
    "        average_heatmap_actual_0_pred_1 += heatmap\n",
    "        count_actual_0_pred_1 += 1\n",
    "\n",
    "# Normalize the average heatmap if there were misclassified samples\n",
    "if count_actual_0_pred_1 > 0:\n",
    "    average_heatmap_actual_0_pred_1 /= count_actual_0_pred_1\n",
    "    \n",
    "average_heatmap_actual_0_pred_1 -= average_heatmap_actual_0_pred_1.min()\n",
    "average_heatmap_actual_0_pred_1 /= average_heatmap_actual_0_pred_1.max()\n",
    "\n",
    "# Final heatmaps\n",
    "print(f\"Misclassification: Actual 0, Predicted 1 - {count_actual_0_pred_1} samples.\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(average_heatmap_actual_0_pred_1, interpolation='bilinear', cmap='viridis', origin='lower', \n",
    "           aspect='auto', extent=[time_axis.min(), time_axis.max(), frequency_axis.min(), frequency_axis.max()])\n",
    "plt.colorbar()\n",
    "plt.title('Average Grad-CAM: Actual 0, Predicted 1')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(to right,rgb(225, 231, 134),rgb(238, 206, 148),rgb(238, 150, 150)); padding: 15px; border-radius: 8px; text-align: center; box-shadow: 0 8px 16px rgba(0,0,0,0.19), 0 4px 4px rgba(0,0,0,0.23);\">\n",
    "    <span style=\"font-family: 'Montserrat', sans-serif; font-weight: 700; font-size: 1.2em; color: white; text-shadow: 1px 1px 3px #000;\">Class 1 PREDICTED 0</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = grad_cam(test_data_tensor, target_class=0)  \n",
    "average_heatmap_actual_1_pred_0 = np.zeros(image_size)\n",
    "count_actual_1_pred_0 = 0\n",
    "\n",
    "for idx in range(len(actual_labels)):\n",
    "    if actual_labels[idx] == 1 and predicted_labels[idx] == 0:  # Actual 1, Predicted 0\n",
    "        cam_batch = cam[idx, :].detach().cpu().numpy() \n",
    "        heatmap = np.zeros(image_size)\n",
    "        \n",
    "     \n",
    "        for i in range(n_patches):\n",
    "            for j in range(n_patches):\n",
    "                patch_idx = i * n_patches + j\n",
    "                patch_value = cam_batch[patch_idx]  \n",
    "                heatmap[\n",
    "                    i * patch_size: (i + 1) * patch_size,\n",
    "                    j * patch_size: (j + 1) * patch_size\n",
    "                ] = patch_value\n",
    "        \n",
    "      \n",
    "        average_heatmap_actual_1_pred_0 += heatmap\n",
    "        count_actual_1_pred_0 += 1\n",
    "\n",
    "if count_actual_1_pred_0 > 0:\n",
    "    average_heatmap_actual_1_pred_0 /= count_actual_1_pred_0\n",
    "    \n",
    "average_heatmap_actual_1_pred_0 -= average_heatmap_actual_1_pred_0.min()\n",
    "average_heatmap_actual_1_pred_0 /= average_heatmap_actual_1_pred_0.max()\n",
    "\n",
    "\n",
    "print(f\"Misclassification: Actual 1, Predicted 0 - {count_actual_1_pred_0} samples.\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(average_heatmap_actual_1_pred_0, interpolation='bilinear', cmap='viridis', origin='lower', \n",
    "           aspect='auto', extent=[time_axis.min(), time_axis.max(), frequency_axis.min(), frequency_axis.max()])\n",
    "plt.colorbar()\n",
    "plt.title('Average Grad-CAM: Actual 1, Predicted 0')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
